{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LogisticRegression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOdjixlvN8jeADtOtfsts78",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rgvananth/Pytorch_ML/blob/master/LogisticRegression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FkDZIkHa5An",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sR-8bOWb4eo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# HyperParametrs\n",
        "train_batch_size = 100\n",
        "test_batch_size = 10\n",
        "num_classes = 10\n",
        "input_size = 28 * 28\n",
        "learning_rate = 0.001\n",
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "num_epochs = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bt5yfoYUb9VC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data Set Initialization and Data Loader\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(root='../../data', \n",
        "                                           train=True, \n",
        "                                           download=True, \n",
        "                                           transform=transforms.ToTensor())\n",
        "test_dataset = torchvision.datasets.MNIST(root='../../data', \n",
        "                                          train = False, \n",
        "                                          download=True, \n",
        "                                          transform=transforms.ToTensor())\n",
        "\n",
        "train_data_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
        "                                                batch_size=train_batch_size, \n",
        "                                                shuffle=True)\n",
        "\n",
        "test_data_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
        "                                                batch_size=test_batch_size, \n",
        "                                                shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcN1_ezGdbIR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LogisticModel(nn.Module):\n",
        "  def __init__(self, input_size, num_classes):\n",
        "    super(LogisticModel, self).__init__()\n",
        "    self.input_size = input_size\n",
        "    self.num_classes = num_classes\n",
        "    self.linear = nn.Linear(input_size,num_classes)\n",
        "  def forward(self, x):\n",
        "    return self.linear(x)\n",
        "\n",
        "model = LogisticModel(input_size, num_classes).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr= learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g73fhMkkfCNO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9310a036-f38a-4573-c224-4b74b7e40046"
      },
      "source": [
        "for epoch in range(num_epochs):\n",
        "  for i, (images, label) in enumerate(train_data_loader):\n",
        "    inputs = images.reshape(-1, input_size).to(device)\n",
        "    label = label.to(device)\n",
        "\n",
        "    pred = model(inputs)\n",
        "    loss = criterion(pred, label)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (i+1) % 100 == 0:\n",
        "      print('Loss for batch: {} in Epoch : {} is: {}'.format(i+1, epoch, loss))"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss for batch: 100 in Epoch : 0 is: 2.1751182079315186\n",
            "Loss for batch: 200 in Epoch : 0 is: 2.0929079055786133\n",
            "Loss for batch: 300 in Epoch : 0 is: 1.987011432647705\n",
            "Loss for batch: 400 in Epoch : 0 is: 1.9083836078643799\n",
            "Loss for batch: 500 in Epoch : 0 is: 1.834031581878662\n",
            "Loss for batch: 600 in Epoch : 0 is: 1.8041287660598755\n",
            "Loss for batch: 100 in Epoch : 1 is: 1.6758068799972534\n",
            "Loss for batch: 200 in Epoch : 1 is: 1.661238670349121\n",
            "Loss for batch: 300 in Epoch : 1 is: 1.6383405923843384\n",
            "Loss for batch: 400 in Epoch : 1 is: 1.5462212562561035\n",
            "Loss for batch: 500 in Epoch : 1 is: 1.5478471517562866\n",
            "Loss for batch: 600 in Epoch : 1 is: 1.494882345199585\n",
            "Loss for batch: 100 in Epoch : 2 is: 1.4136052131652832\n",
            "Loss for batch: 200 in Epoch : 2 is: 1.4050716161727905\n",
            "Loss for batch: 300 in Epoch : 2 is: 1.3017816543579102\n",
            "Loss for batch: 400 in Epoch : 2 is: 1.3356213569641113\n",
            "Loss for batch: 500 in Epoch : 2 is: 1.2713719606399536\n",
            "Loss for batch: 600 in Epoch : 2 is: 1.243843674659729\n",
            "Loss for batch: 100 in Epoch : 3 is: 1.2001352310180664\n",
            "Loss for batch: 200 in Epoch : 3 is: 1.2068722248077393\n",
            "Loss for batch: 300 in Epoch : 3 is: 1.1506158113479614\n",
            "Loss for batch: 400 in Epoch : 3 is: 1.1108757257461548\n",
            "Loss for batch: 500 in Epoch : 3 is: 1.0050504207611084\n",
            "Loss for batch: 600 in Epoch : 3 is: 1.0919352769851685\n",
            "Loss for batch: 100 in Epoch : 4 is: 1.0318303108215332\n",
            "Loss for batch: 200 in Epoch : 4 is: 1.1504793167114258\n",
            "Loss for batch: 300 in Epoch : 4 is: 1.101340889930725\n",
            "Loss for batch: 400 in Epoch : 4 is: 0.9398491382598877\n",
            "Loss for batch: 500 in Epoch : 4 is: 1.0755505561828613\n",
            "Loss for batch: 600 in Epoch : 4 is: 1.1469324827194214\n",
            "Loss for batch: 100 in Epoch : 5 is: 1.1131775379180908\n",
            "Loss for batch: 200 in Epoch : 5 is: 0.9853573441505432\n",
            "Loss for batch: 300 in Epoch : 5 is: 0.9133708477020264\n",
            "Loss for batch: 400 in Epoch : 5 is: 0.9049590229988098\n",
            "Loss for batch: 500 in Epoch : 5 is: 0.9118804931640625\n",
            "Loss for batch: 600 in Epoch : 5 is: 0.9874870181083679\n",
            "Loss for batch: 100 in Epoch : 6 is: 0.8518602252006531\n",
            "Loss for batch: 200 in Epoch : 6 is: 0.9071990847587585\n",
            "Loss for batch: 300 in Epoch : 6 is: 0.7710772156715393\n",
            "Loss for batch: 400 in Epoch : 6 is: 0.9850735664367676\n",
            "Loss for batch: 500 in Epoch : 6 is: 0.9232123494148254\n",
            "Loss for batch: 600 in Epoch : 6 is: 0.7291150689125061\n",
            "Loss for batch: 100 in Epoch : 7 is: 0.723949134349823\n",
            "Loss for batch: 200 in Epoch : 7 is: 0.8289739489555359\n",
            "Loss for batch: 300 in Epoch : 7 is: 0.8199054002761841\n",
            "Loss for batch: 400 in Epoch : 7 is: 0.7889989614486694\n",
            "Loss for batch: 500 in Epoch : 7 is: 0.887505054473877\n",
            "Loss for batch: 600 in Epoch : 7 is: 0.8746561408042908\n",
            "Loss for batch: 100 in Epoch : 8 is: 0.8231459856033325\n",
            "Loss for batch: 200 in Epoch : 8 is: 0.7453082203865051\n",
            "Loss for batch: 300 in Epoch : 8 is: 0.7856415510177612\n",
            "Loss for batch: 400 in Epoch : 8 is: 0.8317746520042419\n",
            "Loss for batch: 500 in Epoch : 8 is: 0.7866254448890686\n",
            "Loss for batch: 600 in Epoch : 8 is: 0.661844789981842\n",
            "Loss for batch: 100 in Epoch : 9 is: 0.8302236795425415\n",
            "Loss for batch: 200 in Epoch : 9 is: 0.7902911901473999\n",
            "Loss for batch: 300 in Epoch : 9 is: 0.7016230225563049\n",
            "Loss for batch: 400 in Epoch : 9 is: 0.7443673014640808\n",
            "Loss for batch: 500 in Epoch : 9 is: 0.7004926800727844\n",
            "Loss for batch: 600 in Epoch : 9 is: 0.6580327749252319\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xIoqMEXhhcx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "99302195-a024-44b8-b24e-cf5d9250f2ad"
      },
      "source": [
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_data_loader:\n",
        "        images = images.reshape(-1, input_size).to(device)\n",
        "        outputs = model(images).cpu()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum()\n",
        "\n",
        "    print('Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the model on the 10000 test images: 85 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}