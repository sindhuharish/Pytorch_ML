{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_Sentiment_Analysis_Parallel_TPU_Traning.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNfqlghlMefLnF0ln9IWeZ/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rgvananth/Pytorch_ML/blob/master/BERT_Sentiment_Analysis_Parallel_TPU_Traning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REYNhK_qggAR",
        "colab_type": "code",
        "outputId": "7148ccaa-87fc-48fe-e9ec-e0f78bbff3ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 944
        }
      },
      "source": [
        "# Installs PyTorch, PyTorch/XLA, and Torchvision\n",
        "# Copy this cell into your own notebooks to use PyTorch on Cloud TPUs \n",
        "# Warning: this may take a couple minutes to run\n",
        "\n",
        "import os\n",
        "assert os.environ['COLAB_TPU_ADDR'], 'Make sure to select TPU from Edit > Notebook settings > Hardware accelerator'\n",
        "\n",
        "VERSION = \"20200325\"  #@param [\"1.5\" , \"20200325\", \"nightly\"]\n",
        "!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
        "!python pytorch-xla-env-setup.py --version $VERSION"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  3727  100  3727    0     0  41876      0 --:--:-- --:--:-- --:--:-- 41876\n",
            "Updating TPU and VM. This may take around 2 minutes.\n",
            "Updating TPU runtime to pytorch-dev20200325 ...\n",
            "Uninstalling torch-1.4.0:\n",
            "Done updating TPU runtime: <Response [200]>\n",
            "  Successfully uninstalled torch-1.4.0\n",
            "Uninstalling torchvision-0.5.0:\n",
            "  Successfully uninstalled torchvision-0.5.0\n",
            "Copying gs://tpu-pytorch/wheels/torch-nightly+20200325-cp36-cp36m-linux_x86_64.whl...\n",
            "\\ [1 files][ 83.4 MiB/ 83.4 MiB]                                                \n",
            "Operation completed over 1 objects/83.4 MiB.                                     \n",
            "Copying gs://tpu-pytorch/wheels/torch_xla-nightly+20200325-cp36-cp36m-linux_x86_64.whl...\n",
            "- [1 files][114.5 MiB/114.5 MiB]                                                \n",
            "Operation completed over 1 objects/114.5 MiB.                                    \n",
            "Copying gs://tpu-pytorch/wheels/torchvision-nightly+20200325-cp36-cp36m-linux_x86_64.whl...\n",
            "/ [1 files][  2.5 MiB/  2.5 MiB]                                                \n",
            "Operation completed over 1 objects/2.5 MiB.                                      \n",
            "Processing ./torch-nightly+20200325-cp36-cp36m-linux_x86_64.whl\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==nightly+20200325) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==nightly+20200325) (1.18.2)\n",
            "\u001b[31mERROR: fastai 1.0.60 requires torchvision, which is not installed.\u001b[0m\n",
            "Installing collected packages: torch\n",
            "Successfully installed torch-1.5.0a0+d6149a7\n",
            "Processing ./torch_xla-nightly+20200325-cp36-cp36m-linux_x86_64.whl\n",
            "Installing collected packages: torch-xla\n",
            "Successfully installed torch-xla-1.6+e788e5b\n",
            "Processing ./torchvision-nightly+20200325-cp36-cp36m-linux_x86_64.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly+20200325) (1.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly+20200325) (1.18.2)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly+20200325) (7.0.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly+20200325) (1.5.0a0+d6149a7)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchvision==nightly+20200325) (0.16.0)\n",
            "Installing collected packages: torchvision\n",
            "Successfully installed torchvision-0.6.0a0+3c254fb\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  libomp5\n",
            "0 upgraded, 1 newly installed, 0 to remove and 25 not upgraded.\n",
            "Need to get 234 kB of archives.\n",
            "After this operation, 774 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libomp5 amd64 5.0.1-1 [234 kB]\n",
            "Fetched 234 kB in 1s (363 kB/s)\n",
            "Selecting previously unselected package libomp5:amd64.\n",
            "(Reading database ... 133872 files and directories currently installed.)\n",
            "Preparing to unpack .../libomp5_5.0.1-1_amd64.deb ...\n",
            "Unpacking libomp5:amd64 (5.0.1-1) ...\n",
            "Setting up libomp5:amd64 (5.0.1-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmb_e-dEiS5A",
        "colab_type": "code",
        "outputId": "9673bd03-e3cf-48b6-f57d-09f76d7703af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        }
      },
      "source": [
        "! pip install pytorch-pretrained-bert\n",
        "! wget https://github.com/sugi-chan/custom_bert_pipeline/raw/master/IMDB%20Dataset.csv"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-pretrained-bert\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 18.7MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20kB 2.2MB/s eta 0:00:01\r\u001b[K     |████████                        | 30kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 40kB 2.1MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 51kB 2.3MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 61kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 71kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 81kB 3.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 92kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 102kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 112kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 122kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 3.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.12.27)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (4.38.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2019.12.20)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.5.0a0+d6149a7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2.21.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.18.2)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.27 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (1.15.27)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.9.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (0.16.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.27->boto3->pytorch-pretrained-bert) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.27->boto3->pytorch-pretrained-bert) (0.15.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.16.0,>=1.15.27->boto3->pytorch-pretrained-bert) (1.12.0)\n",
            "Installing collected packages: pytorch-pretrained-bert\n",
            "Successfully installed pytorch-pretrained-bert-0.6.2\n",
            "--2020-03-29 04:41:49--  https://github.com/sugi-chan/custom_bert_pipeline/raw/master/IMDB%20Dataset.csv\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/sugi-chan/custom_bert_pipeline/master/IMDB%20Dataset.csv [following]\n",
            "--2020-03-29 04:41:49--  https://raw.githubusercontent.com/sugi-chan/custom_bert_pipeline/master/IMDB%20Dataset.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 66212309 (63M) [text/plain]\n",
            "Saving to: ‘IMDB Dataset.csv’\n",
            "\n",
            "IMDB Dataset.csv    100%[===================>]  63.14M  69.3MB/s    in 0.9s    \n",
            "\n",
            "2020-03-29 04:41:50 (69.3 MB/s) - ‘IMDB Dataset.csv’ saved [66212309/66212309]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Z21XpPqguUS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch_xla.core.xla_model as xm\n",
        "import torch_xla.distributed.xla_multiprocessing as xmp\n",
        "import torch_xla.distributed.parallel_loader as pl\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "import copy\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertConfig, BertModel, BertForMaskedLM\n",
        "import logging\n",
        "logging.basicConfig(level=logging.INFO)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duNP8sE5h3XL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FLAGS = {}\n",
        "FLAGS['batch_size'] = 16\n",
        "FLAGS['num_workers'] = 4\n",
        "FLAGS['num_epochs'] = 9\n",
        "FLAGS['log_steps'] = 20\n",
        "FLAGS['max_seq_length'] = 256\n",
        "FLAGS['learning_rate'] = 0.01\n",
        "FLAGS['log_steps'] = 20\n",
        "FLAGS['metrics_debug'] = False\n",
        "FLAGS['num_cores'] = 8"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJxG5t2tjS-9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "config = BertConfig(vocab_size_or_config_json_file=32000, hidden_size=768, num_hidden_layers=12, num_attention_heads=12, intermediate_size=3072)\n",
        "num_labels = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6U2FDDSjnAb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BertForSequenceClassification(nn.Module):\n",
        "  def __init__(self, num_labels = 1):\n",
        "    super(BertForSequenceClassification, self).__init__()\n",
        "    self.num_labels = num_labels\n",
        "    self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "    self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "    self.classifier = nn.Linear(config.hidden_size, num_labels)\n",
        "    nn.init.xavier_normal_(self.classifier.weight)\n",
        "  def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None):\n",
        "    _,pooled_output = self.bert(input_ids, token_type_ids, attention_mask, output_all_encoded_layers=False)\n",
        "    pooled_output = self.dropout(pooled_output)\n",
        "    logits = self.classifier(pooled_output)\n",
        "    return logits\n",
        "\n",
        "# Custom Data Class Loader\n",
        "class create_dataset(Dataset):\n",
        "  def __init__(self, data):\n",
        "    self.data = data\n",
        "  def __getitem__(self, index):\n",
        "    tokenized_text = tokenizer.tokenize(self.data[0][index])\n",
        "    if len(tokenized_text) > FLAGS['max_seq_length']:\n",
        "      tokenized_text = tokenized_text[:FLAGS['max_seq_length']]\n",
        "    ids_text = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "    padding = [0] * (FLAGS['max_seq_length'] - len(tokenized_text))\n",
        "    ids_text += padding\n",
        "    assert len(ids_text) == FLAGS['max_seq_length']\n",
        "    ids_text = torch.tensor(ids_text)\n",
        "    label = self.data[1][index]\n",
        "    list_of_labels = [torch.from_numpy(np.array(label))]\n",
        "    return ids_text, list_of_labels[0]\n",
        "  def __len__(self):\n",
        "    return len(self.data[0])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IkCN_6pl50U",
        "colab_type": "code",
        "outputId": "3fc5b33a-8376-4308-829d-2305c98c8341",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:pytorch_pretrained_bert.file_utils:https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache, downloading to /tmp/tmp2066v4we\n",
            "100%|██████████| 231508/231508 [00:00<00:00, 2678735.77B/s]\n",
            "INFO:pytorch_pretrained_bert.file_utils:copying /tmp/tmp2066v4we to cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "INFO:pytorch_pretrained_bert.file_utils:creating metadata file for /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "INFO:pytorch_pretrained_bert.file_utils:removing temp file /tmp/tmp2066v4we\n",
            "INFO:pytorch_pretrained_bert.tokenization:loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbdaYSsll_Kb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_classifier():\n",
        "  import pandas as pd\n",
        "  data = pd.read_csv('IMDB Dataset.csv')\n",
        "  X = data['review']\n",
        "  Y = data['sentiment']\n",
        "  x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.10, random_state=42)\n",
        "  x_train = x_train.values.tolist()\n",
        "  x_test = x_test.values.tolist()\n",
        "  y_train = pd.get_dummies(y_train).values.tolist()\n",
        "  y_test = pd.get_dummies(y_test).values.tolist()\n",
        "  train_lists = [x_train, y_train]\n",
        "  test_lists = [x_test, y_test]\n",
        "  train_dataset = create_dataset(train_lists)\n",
        "  test_dataset = create_dataset(test_lists)\n",
        "\n",
        "  train_sampler = torch.utils.data.DistributedSampler(train_dataset, num_replicas=xm.xrt_world_size(), rank = xm.get_ordinal(), shuffle=True)\n",
        "  test_sampler = torch.utils.data.DistributedSampler(test_dataset, num_replicas=xm.xrt_world_size(), rank=xm.get_ordinal(), shuffle=False)\n",
        "  train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=FLAGS['batch_size'], sampler=train_sampler, num_workers=FLAGS['num_workers'], drop_last=True)\n",
        "  test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=FLAGS['batch_size'], sampler=test_sampler, shuffle=False, num_workers=FLAGS['num_workers'], drop_last=True)\n",
        "\n",
        "  data_loaders_dict = {'train': train_loader, 'val': test_loader}\n",
        "  data_set_sizes = {'train': len(train_lists[0]), 'val': len(test_lists[0])}\n",
        "  device = xm.xla_device()\n",
        "  model = BertForSequenceClassification(num_labels).to(device)\n",
        "  lr_classifier = 0.001\n",
        "  lr_bert = 0.00001\n",
        "  optimizer = torch.optim.Adam([\n",
        "      {\"params\": model.bert.parameters(), \"lr\": lr_bert},\n",
        "      {\"params\": model.classifier.parameters(), \"lr\": lr_classifier},\n",
        "      ])\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer=optimizer, step_size=3, gamma=0.1)\n",
        "\n",
        "  def train_loop_fn(loader):\n",
        "    tracker = xm.RateTracker()\n",
        "    model.train()\n",
        "    for x, (data, target) in enumerate(loader):\n",
        "      optimizer.zero_grad()\n",
        "      outputs = model(data)\n",
        "      outputs = F.softmax(outputs, dim=1)\n",
        "      loss = criterion(outputs, torch.max(target.float(), 1)[1])\n",
        "      loss.backward()\n",
        "      xm.optimizer_step(optimizer)\n",
        "      tracker.add(FLAGS['batch_size'])\n",
        "      if x % FLAGS['log_steps'] == 0:\n",
        "        print('[xla:{}]({}) Loss={:.5f} Rate={:.2f} GlobalRate={:.2f} Time={}'.format(\n",
        "              xm.get_ordinal(), x, loss.item(), tracker.rate(),\n",
        "              tracker.global_rate(), time.asctime()), flush=True)\n",
        "  def test_loop_fn(loader):\n",
        "    total_samples =0\n",
        "    correct = 0\n",
        "    model.eval()\n",
        "    data, target = None, None\n",
        "    for data, target in loader:\n",
        "      outputs = model(data)\n",
        "      outputs = F.softmax(outputs, dim=1)\n",
        "      correct += torch.sum(torch.max(outputs, 1)[1] == torch.max(target, 1)[1])\n",
        "      total_samples += data.size(0)\n",
        "    xm.master_print('Sizes: {}, {}'.format(outputs.shape, target.shape))\n",
        "    accuracy = 100.0 * correct / total_samples\n",
        "    print('[xla:{}] Accuracy={:.2f}%'.format(\n",
        "          xm.get_ordinal(), accuracy), flush=True)\n",
        "    \n",
        "    return accuracy, model\n",
        "\n",
        "  for epoch in range(FLAGS['num_epochs']+1):\n",
        "    para_loader = pl.ParallelLoader(train_loader, [device])\n",
        "    train_loop_fn(para_loader.per_device_loader(device))\n",
        "    xm.master_print('Finished Training epoch {}'.format(epoch))\n",
        "\n",
        "    para_loader = pl.ParallelLoader(test_loader, [device])\n",
        "    accuracy, model = test_loop_fn(para_loader.per_device_loader(device))\n",
        "    if FLAGS['metrics_debug']:\n",
        "        xm.master_print(met.metrics_report(), flush=True)\n",
        "\n",
        "  return accuracy, model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BX-bxVLDnOAx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _map_fn(rank, flags):\n",
        "  global FLAGS\n",
        "  FLAGS = FLAGS\n",
        "  torch.set_default_tensor_type('torch.FloatTensor')\n",
        "  accuracy, model = train_classifier()\n",
        "  xm.save(model.state_dict(), 'checkpoint-1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoY-1EiEnfLo",
        "colab_type": "code",
        "outputId": "b27682d4-5824-4046-c373-28856aaf1b77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "xmp.spawn(_map_fn, args=(FLAGS,), nprocs=FLAGS['num_cores'], start_method='fork')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:pytorch_pretrained_bert.file_utils:https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz not found in cache, downloading to /tmp/tmp59bq3_m0\n",
            "  0%|          | 261120/407873900 [00:00<02:56, 2313370.45B/s]INFO:pytorch_pretrained_bert.file_utils:https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz not found in cache, downloading to /tmp/tmpafwyndu0\n",
            "  1%|          | 2183168/407873900 [00:00<02:09, 3142693.30B/s]INFO:pytorch_pretrained_bert.file_utils:https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz not found in cache, downloading to /tmp/tmpfez0m7h9\n",
            "  2%|▏         | 7311360/407873900 [00:00<01:31, 4374664.67B/s]INFO:pytorch_pretrained_bert.file_utils:https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz not found in cache, downloading to /tmp/tmpjfncrdtg\n",
            "  1%|          | 2488320/407873900 [00:00<01:54, 3525391.29B/s]INFO:pytorch_pretrained_bert.file_utils:https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz not found in cache, downloading to /tmp/tmp_1byo_ch\n",
            " 12%|█▏        | 50262016/407873900 [00:00<00:13, 27056551.59B/s]INFO:pytorch_pretrained_bert.file_utils:https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz not found in cache, downloading to /tmp/tmp_vpq4yyb\n",
            " 81%|████████▏ | 332152832/407873900 [00:05<00:01, 38060126.67B/s]INFO:pytorch_pretrained_bert.file_utils:https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz not found in cache, downloading to /tmp/tmp_1jelctv\n",
            "  4%|▍         | 18022400/407873900 [00:00<00:47, 8220367.10B/s]INFO:pytorch_pretrained_bert.file_utils:https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz not found in cache, downloading to /tmp/tmpfhk9mvt0\n",
            "100%|██████████| 407873900/407873900 [00:08<00:00, 49999714.46B/s]\n",
            "INFO:pytorch_pretrained_bert.file_utils:copying /tmp/tmp59bq3_m0 to cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
            "100%|██████████| 407873900/407873900 [00:13<00:00, 30799046.26B/s]\n",
            " 82%|████████▏ | 335349760/407873900 [00:12<00:11, 6311037.75B/s]INFO:pytorch_pretrained_bert.file_utils:copying /tmp/tmpfez0m7h9 to cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
            "100%|██████████| 407873900/407873900 [00:13<00:00, 30038298.61B/s]\n",
            "INFO:pytorch_pretrained_bert.file_utils:copying /tmp/tmpafwyndu0 to cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
            "100%|██████████| 407873900/407873900 [00:15<00:00, 26269366.16B/s]\n",
            "INFO:pytorch_pretrained_bert.file_utils:copying /tmp/tmpjfncrdtg to cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
            "100%|██████████| 407873900/407873900 [00:16<00:00, 25173178.45B/s]\n",
            "INFO:pytorch_pretrained_bert.file_utils:copying /tmp/tmp_1byo_ch to cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
            "100%|██████████| 407873900/407873900 [00:22<00:00, 17959328.97B/s]\n",
            "INFO:pytorch_pretrained_bert.file_utils:copying /tmp/tmp_vpq4yyb to cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
            "100%|██████████| 407873900/407873900 [00:30<00:00, 13285236.49B/s]\n",
            "INFO:pytorch_pretrained_bert.file_utils:copying /tmp/tmp_1jelctv to cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
            "100%|██████████| 407873900/407873900 [00:30<00:00, 13194446.54B/s]\n",
            "INFO:pytorch_pretrained_bert.file_utils:copying /tmp/tmpfhk9mvt0 to cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
            "INFO:pytorch_pretrained_bert.file_utils:creating metadata file for /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
            "INFO:pytorch_pretrained_bert.file_utils:removing temp file /tmp/tmpafwyndu0\n",
            "INFO:pytorch_pretrained_bert.file_utils:creating metadata file for /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
            "INFO:pytorch_pretrained_bert.file_utils:removing temp file /tmp/tmp59bq3_m0\n",
            "INFO:pytorch_pretrained_bert.modeling:loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
            "INFO:pytorch_pretrained_bert.modeling:extracting archive file /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmp1a91rumw\n",
            "INFO:pytorch_pretrained_bert.modeling:loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
            "INFO:pytorch_pretrained_bert.modeling:extracting archive file /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpckn5b0lh\n",
            "INFO:pytorch_pretrained_bert.file_utils:creating metadata file for /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
            "INFO:pytorch_pretrained_bert.file_utils:creating metadata file for /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
            "INFO:pytorch_pretrained_bert.file_utils:creating metadata file for /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
            "INFO:pytorch_pretrained_bert.file_utils:creating metadata file for /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
            "INFO:pytorch_pretrained_bert.file_utils:creating metadata file for /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
            "INFO:pytorch_pretrained_bert.file_utils:creating metadata file for /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
            "INFO:pytorch_pretrained_bert.file_utils:removing temp file /tmp/tmpfez0m7h9\n",
            "INFO:pytorch_pretrained_bert.file_utils:removing temp file /tmp/tmp_1byo_ch\n",
            "INFO:pytorch_pretrained_bert.modeling:loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
            "INFO:pytorch_pretrained_bert.modeling:loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
            "INFO:pytorch_pretrained_bert.modeling:extracting archive file /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpx_raj1nq\n",
            "INFO:pytorch_pretrained_bert.modeling:extracting archive file /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpsr9m6ye8\n",
            "INFO:pytorch_pretrained_bert.file_utils:removing temp file /tmp/tmpjfncrdtg\n",
            "INFO:pytorch_pretrained_bert.file_utils:removing temp file /tmp/tmp_vpq4yyb\n",
            "INFO:pytorch_pretrained_bert.file_utils:removing temp file /tmp/tmp_1jelctv\n",
            "INFO:pytorch_pretrained_bert.file_utils:removing temp file /tmp/tmpfhk9mvt0\n",
            "INFO:pytorch_pretrained_bert.modeling:loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
            "INFO:pytorch_pretrained_bert.modeling:loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
            "INFO:pytorch_pretrained_bert.modeling:extracting archive file /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpj4uzzk27\n",
            "INFO:pytorch_pretrained_bert.modeling:extracting archive file /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpr3sv607e\n",
            "INFO:pytorch_pretrained_bert.modeling:loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
            "INFO:pytorch_pretrained_bert.modeling:loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
            "INFO:pytorch_pretrained_bert.modeling:extracting archive file /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpiin_i1hz\n",
            "INFO:pytorch_pretrained_bert.modeling:extracting archive file /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmp3gm0lm_t\n",
            "INFO:pytorch_pretrained_bert.modeling:Model config {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "INFO:pytorch_pretrained_bert.modeling:Model config {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[xla:0](0) Loss=0.70844 Rate=1.93 GlobalRate=1.93 Time=Sun Mar 29 04:43:30 2020\n",
            "[xla:1](0) Loss=0.67006 Rate=1.97 GlobalRate=1.97 Time=Sun Mar 29 04:43:31 2020\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:pytorch_pretrained_bert.modeling:Model config {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "INFO:pytorch_pretrained_bert.modeling:Model config {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "INFO:pytorch_pretrained_bert.modeling:Model config {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "INFO:pytorch_pretrained_bert.modeling:Model config {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[xla:7](0) Loss=0.72617 Rate=16.67 GlobalRate=16.67 Time=Sun Mar 29 04:43:44 2020\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:pytorch_pretrained_bert.modeling:Model config {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[xla:2](0) Loss=0.62905 Rate=15.02 GlobalRate=15.02 Time=Sun Mar 29 04:43:45 2020\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:pytorch_pretrained_bert.modeling:Model config {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[xla:4](0) Loss=0.74437 Rate=17.29 GlobalRate=17.29 Time=Sun Mar 29 04:43:50 2020\n",
            "[xla:5](0) Loss=0.68545 Rate=17.50 GlobalRate=17.50 Time=Sun Mar 29 04:43:53 2020\n",
            "[xla:3](0) Loss=0.72875 Rate=16.31 GlobalRate=16.31 Time=Sun Mar 29 04:43:53 2020\n",
            "[xla:6](0) Loss=0.62283 Rate=16.33 GlobalRate=16.33 Time=Sun Mar 29 04:43:53 2020\n",
            "[xla:7](20) Loss=0.61256 Rate=11.57 GlobalRate=8.37 Time=Sun Mar 29 04:44:24 2020\n",
            "[xla:1](20) Loss=0.62954 Rate=4.41 GlobalRate=5.49 Time=Sun Mar 29 04:44:24 2020\n",
            "[xla:4](20) Loss=0.62431 Rate=12.57 GlobalRate=9.63 Time=Sun Mar 29 04:44:24 2020\n",
            "[xla:5](20) Loss=0.65622 Rate=13.22 GlobalRate=10.57 Time=Sun Mar 29 04:44:24 2020\n",
            "[xla:6](20) Loss=0.69933 Rate=12.79 GlobalRate=10.61 Time=Sun Mar 29 04:44:24 2020\n",
            "[xla:3](20) Loss=0.75257 Rate=12.77 GlobalRate=10.60 Time=Sun Mar 29 04:44:24 2020\n",
            "[xla:2](20) Loss=0.59280 Rate=10.94 GlobalRate=8.40 Time=Sun Mar 29 04:44:24 2020\n",
            "[xla:0](20) Loss=0.69883 Rate=4.39 GlobalRate=5.47 Time=Sun Mar 29 04:44:24 2020\n",
            "[xla:1](40) Loss=0.52647 Rate=37.38 GlobalRate=9.85 Time=Sun Mar 29 04:44:29 2020\n",
            "[xla:6](40) Loss=0.61495 Rate=40.72 GlobalRate=17.70 Time=Sun Mar 29 04:44:29 2020\n",
            "[xla:3](40) Loss=0.58294 Rate=40.72 GlobalRate=17.69 Time=Sun Mar 29 04:44:29 2020\n",
            "[xla:4](40) Loss=0.58781 Rate=40.63 GlobalRate=16.28 Time=Sun Mar 29 04:44:29 2020\n",
            "[xla:5](40) Loss=0.48345 Rate=40.89 GlobalRate=17.64 Time=Sun Mar 29 04:44:29 2020\n",
            "[xla:7](40) Loss=0.48847 Rate=40.22 GlobalRate=14.41 Time=Sun Mar 29 04:44:29 2020\n",
            "[xla:0](40) Loss=0.59595 Rate=37.33 GlobalRate=9.82 Time=Sun Mar 29 04:44:29 2020\n",
            "[xla:2](40) Loss=0.45961 Rate=39.94 GlobalRate=14.45 Time=Sun Mar 29 04:44:29 2020\n",
            "[xla:2](60) Loss=0.55720 Rate=52.34 GlobalRate=19.26 Time=Sun Mar 29 04:44:34 2020\n",
            "[xla:5](60) Loss=0.52710 Rate=52.62 GlobalRate=22.97 Time=Sun Mar 29 04:44:34 2020\n",
            "[xla:1](60) Loss=0.46191 Rate=51.20 GlobalRate=13.58 Time=Sun Mar 29 04:44:34 2020\n",
            "[xla:0](60) Loss=0.60236 Rate=51.27 GlobalRate=13.54 Time=Sun Mar 29 04:44:34 2020\n",
            "[xla:7](60) Loss=0.48895 Rate=52.35 GlobalRate=19.21 Time=Sun Mar 29 04:44:34 2020\n",
            "[xla:3](60) Loss=0.40477 Rate=52.53 GlobalRate=23.03 Time=Sun Mar 29 04:44:34 2020\n",
            "[xla:4](60) Loss=0.39842 Rate=52.50 GlobalRate=21.41 Time=Sun Mar 29 04:44:34 2020\n",
            "[xla:6](60) Loss=0.44518 Rate=52.53 GlobalRate=23.04 Time=Sun Mar 29 04:44:34 2020\n",
            "[xla:3](80) Loss=0.41534 Rate=57.09 GlobalRate=27.17 Time=Sun Mar 29 04:44:40 2020\n",
            "[xla:5](80) Loss=0.56832 Rate=57.10 GlobalRate=27.11 Time=Sun Mar 29 04:44:40 2020\n",
            "[xla:0](80) Loss=0.45091 Rate=56.57 GlobalRate=16.74 Time=Sun Mar 29 04:44:40 2020\n",
            "[xla:4](80) Loss=0.43655 Rate=57.04 GlobalRate=25.46 Time=Sun Mar 29 04:44:40 2020\n",
            "[xla:6](80) Loss=0.48029 Rate=57.05 GlobalRate=27.17 Time=Sun Mar 29 04:44:40 2020\n",
            "[xla:2](80) Loss=0.43429 Rate=56.95 GlobalRate=23.14 Time=Sun Mar 29 04:44:40 2020\n",
            "[xla:1](80) Loss=0.36547 Rate=56.51 GlobalRate=16.78 Time=Sun Mar 29 04:44:40 2020\n",
            "[xla:7](80) Loss=0.53201 Rate=56.98 GlobalRate=23.08 Time=Sun Mar 29 04:44:40 2020\n",
            "[xla:4](100) Loss=0.43665 Rate=59.32 GlobalRate=28.77 Time=Sun Mar 29 04:44:45 2020\n",
            "[xla:6](100) Loss=0.43544 Rate=59.31 GlobalRate=30.52 Time=Sun Mar 29 04:44:45 2020\n",
            "[xla:2](100) Loss=0.48255 Rate=59.27 GlobalRate=26.37 Time=Sun Mar 29 04:44:45 2020\n",
            "[xla:1](100) Loss=0.39245 Rate=59.07 GlobalRate=19.59 Time=Sun Mar 29 04:44:45 2020\n",
            "[xla:5](100) Loss=0.39498 Rate=59.28 GlobalRate=30.45 Time=Sun Mar 29 04:44:45 2020\n",
            "[xla:3](100) Loss=0.40039 Rate=59.26 GlobalRate=30.50 Time=Sun Mar 29 04:44:45 2020\n",
            "[xla:0](100) Loss=0.40442 Rate=58.98 GlobalRate=19.54 Time=Sun Mar 29 04:44:45 2020\n",
            "[xla:7](100) Loss=0.46991 Rate=59.17 GlobalRate=26.31 Time=Sun Mar 29 04:44:45 2020\n",
            "[xla:6](120) Loss=0.40410 Rate=60.31 GlobalRate=33.26 Time=Sun Mar 29 04:44:50 2020\n",
            "[xla:1](120) Loss=0.44282 Rate=60.24 GlobalRate=22.07 Time=Sun Mar 29 04:44:50 2020\n",
            "[xla:3](120) Loss=0.40064 Rate=60.32 GlobalRate=33.25 Time=Sun Mar 29 04:44:50 2020\n",
            "[xla:2](120) Loss=0.38037 Rate=60.29 GlobalRate=29.10 Time=Sun Mar 29 04:44:50 2020\n",
            "[xla:0](120) Loss=0.32348 Rate=60.26 GlobalRate=22.02 Time=Sun Mar 29 04:44:50 2020\n",
            "[xla:4](120) Loss=0.48793 Rate=60.27 GlobalRate=31.52 Time=Sun Mar 29 04:44:50 2020\n",
            "[xla:7](120) Loss=0.43245 Rate=60.33 GlobalRate=29.04 Time=Sun Mar 29 04:44:50 2020\n",
            "[xla:5](120) Loss=0.45965 Rate=60.29 GlobalRate=33.19 Time=Sun Mar 29 04:44:50 2020\n",
            "[xla:5](140) Loss=0.49175 Rate=60.52 GlobalRate=35.47 Time=Sun Mar 29 04:44:55 2020\n",
            "[xla:4](140) Loss=0.42257 Rate=60.49 GlobalRate=33.82 Time=Sun Mar 29 04:44:55 2020\n",
            "[xla:6](140) Loss=0.47889 Rate=60.47 GlobalRate=35.54 Time=Sun Mar 29 04:44:55 2020\n",
            "[xla:3](140) Loss=0.61488 Rate=60.48 GlobalRate=35.52 Time=Sun Mar 29 04:44:55 2020\n",
            "[xla:0](140) Loss=0.46178 Rate=60.48 GlobalRate=24.20 Time=Sun Mar 29 04:44:55 2020\n",
            "[xla:2](140) Loss=0.34529 Rate=60.47 GlobalRate=31.42 Time=Sun Mar 29 04:44:55 2020\n",
            "[xla:7](140) Loss=0.54488 Rate=60.47 GlobalRate=31.36 Time=Sun Mar 29 04:44:55 2020\n",
            "[xla:1](140) Loss=0.62699 Rate=60.39 GlobalRate=24.25 Time=Sun Mar 29 04:44:55 2020\n",
            "[xla:2](160) Loss=0.31949 Rate=61.41 GlobalRate=33.47 Time=Sun Mar 29 04:45:01 2020\n",
            "[xla:3](160) Loss=0.43888 Rate=61.41 GlobalRate=37.52 Time=Sun Mar 29 04:45:01 2020\n",
            "[xla:0](160) Loss=0.37717 Rate=61.41 GlobalRate=26.19 Time=Sun Mar 29 04:45:01 2020\n",
            "[xla:1](160) Loss=0.41876 Rate=61.43 GlobalRate=26.24 Time=Sun Mar 29 04:45:01 2020\n",
            "[xla:6](160) Loss=0.39504 Rate=61.40 GlobalRate=37.53 Time=Sun Mar 29 04:45:01 2020\n",
            "[xla:5](160) Loss=0.44840 Rate=61.40 GlobalRate=37.46 Time=Sun Mar 29 04:45:01 2020\n",
            "[xla:7](160) Loss=0.39302 Rate=61.45 GlobalRate=33.41 Time=Sun Mar 29 04:45:01 2020\n",
            "[xla:4](160) Loss=0.42212 Rate=61.38 GlobalRate=35.84 Time=Sun Mar 29 04:45:01 2020\n",
            "[xla:7](180) Loss=0.41951 Rate=61.72 GlobalRate=35.20 Time=Sun Mar 29 04:45:06 2020\n",
            "[xla:1](180) Loss=0.43411 Rate=61.71 GlobalRate=28.02 Time=Sun Mar 29 04:45:06 2020\n",
            "[xla:5](180) Loss=0.34582 Rate=61.69 GlobalRate=39.17 Time=Sun Mar 29 04:45:06 2020\n",
            "[xla:0](180) Loss=0.31673 Rate=61.70 GlobalRate=27.97 Time=Sun Mar 29 04:45:06 2020\n",
            "[xla:3](180) Loss=0.33607 Rate=61.70 GlobalRate=39.22 Time=Sun Mar 29 04:45:06 2020\n",
            "[xla:4](180) Loss=0.45407 Rate=61.71 GlobalRate=37.59 Time=Sun Mar 29 04:45:06 2020\n",
            "[xla:6](180) Loss=0.67484 Rate=61.67 GlobalRate=39.23 Time=Sun Mar 29 04:45:06 2020\n",
            "[xla:2](180) Loss=0.43754 Rate=61.66 GlobalRate=35.25 Time=Sun Mar 29 04:45:06 2020\n",
            "[xla:4](200) Loss=0.39502 Rate=61.76 GlobalRate=39.12 Time=Sun Mar 29 04:45:11 2020\n",
            "[xla:6](200) Loss=0.51782 Rate=61.77 GlobalRate=40.71 Time=Sun Mar 29 04:45:11 2020\n",
            "[xla:5](200) Loss=0.37965 Rate=61.74 GlobalRate=40.65 Time=Sun Mar 29 04:45:11 2020\n",
            "[xla:7](200) Loss=0.34001 Rate=61.74 GlobalRate=36.78 Time=Sun Mar 29 04:45:11 2020\n",
            "[xla:1](200) Loss=0.46782 Rate=61.72 GlobalRate=29.63 Time=Sun Mar 29 04:45:11 2020\n",
            "[xla:3](200) Loss=0.41662 Rate=61.71 GlobalRate=40.70 Time=Sun Mar 29 04:45:11 2020\n",
            "[xla:2](200) Loss=0.43466 Rate=61.66 GlobalRate=36.82 Time=Sun Mar 29 04:45:11 2020\n",
            "[xla:0](200) Loss=0.37905 Rate=61.63 GlobalRate=29.57 Time=Sun Mar 29 04:45:11 2020\n",
            "[xla:6](220) Loss=0.43859 Rate=61.45 GlobalRate=41.99 Time=Sun Mar 29 04:45:16 2020\n",
            "[xla:3](220) Loss=0.33668 Rate=61.47 GlobalRate=41.98 Time=Sun Mar 29 04:45:16 2020\n",
            "[xla:0](220) Loss=0.31679 Rate=61.51 GlobalRate=31.03 Time=Sun Mar 29 04:45:16 2020\n",
            "[xla:5](220) Loss=0.40031 Rate=61.44 GlobalRate=41.93 Time=Sun Mar 29 04:45:16 2020\n",
            "[xla:7](220) Loss=0.35982 Rate=61.46 GlobalRate=38.16 Time=Sun Mar 29 04:45:16 2020\n",
            "[xla:4](220) Loss=0.47332 Rate=61.45 GlobalRate=40.44 Time=Sun Mar 29 04:45:16 2020\n",
            "[xla:1](220) Loss=0.36997 Rate=61.46 GlobalRate=31.09 Time=Sun Mar 29 04:45:16 2020\n",
            "[xla:2](220) Loss=0.40324 Rate=61.49 GlobalRate=38.21 Time=Sun Mar 29 04:45:16 2020\n",
            "[xla:2](240) Loss=0.31430 Rate=61.25 GlobalRate=39.43 Time=Sun Mar 29 04:45:21 2020\n",
            "[xla:4](240) Loss=0.44663 Rate=61.21 GlobalRate=41.61 Time=Sun Mar 29 04:45:21 2020\n",
            "[xla:3](240) Loss=0.32254 Rate=61.21 GlobalRate=43.09 Time=Sun Mar 29 04:45:21 2020\n",
            "[xla:5](240) Loss=0.52412 Rate=61.20 GlobalRate=43.04 Time=Sun Mar 29 04:45:21 2020\n",
            "[xla:1](240) Loss=0.39827 Rate=61.21 GlobalRate=32.41 Time=Sun Mar 29 04:45:21 2020\n",
            "[xla:0](240) Loss=0.37832 Rate=61.22 GlobalRate=32.35 Time=Sun Mar 29 04:45:21 2020\n",
            "[xla:6](240) Loss=0.46671 Rate=61.18 GlobalRate=43.10 Time=Sun Mar 29 04:45:21 2020\n",
            "[xla:7](240) Loss=0.39930 Rate=61.18 GlobalRate=39.38 Time=Sun Mar 29 04:45:21 2020\n",
            "[xla:1](260) Loss=0.50321 Rate=61.55 GlobalRate=33.63 Time=Sun Mar 29 04:45:27 2020\n",
            "[xla:3](260) Loss=0.54223 Rate=61.55 GlobalRate=44.12 Time=Sun Mar 29 04:45:27 2020\n",
            "[xla:6](260) Loss=0.32252 Rate=61.56 GlobalRate=44.12 Time=Sun Mar 29 04:45:27 2020\n",
            "[xla:7](260) Loss=0.39998 Rate=61.56 GlobalRate=40.51 Time=Sun Mar 29 04:45:27 2020\n",
            "[xla:4](260) Loss=0.35609 Rate=61.51 GlobalRate=42.67 Time=Sun Mar 29 04:45:27 2020\n",
            "[xla:5](260) Loss=0.50305 Rate=61.52 GlobalRate=44.07 Time=Sun Mar 29 04:45:27 2020\n",
            "[xla:0](260) Loss=0.46836 Rate=61.44 GlobalRate=33.57 Time=Sun Mar 29 04:45:27 2020\n",
            "[xla:2](260) Loss=0.33754 Rate=61.43 GlobalRate=40.55 Time=Sun Mar 29 04:45:27 2020\n",
            "[xla:5](280) Loss=0.43686 Rate=61.03 GlobalRate=44.94 Time=Sun Mar 29 04:45:32 2020\n",
            "[xla:4](280) Loss=0.37068 Rate=61.02 GlobalRate=43.59 Time=Sun Mar 29 04:45:32 2020\n",
            "[xla:7](280) Loss=0.37139 Rate=61.01 GlobalRate=41.49 Time=Sun Mar 29 04:45:32 2020\n",
            "[xla:2](280) Loss=0.50838 Rate=61.06 GlobalRate=41.53 Time=Sun Mar 29 04:45:32 2020\n",
            "[xla:6](280) Loss=0.56427 Rate=60.95 GlobalRate=44.99 Time=Sun Mar 29 04:45:32 2020\n",
            "[xla:0](280) Loss=0.35259 Rate=61.01 GlobalRate=34.68 Time=Sun Mar 29 04:45:32 2020\n",
            "[xla:1](280) Loss=0.36702 Rate=60.90 GlobalRate=34.73 Time=Sun Mar 29 04:45:32 2020\n",
            "[xla:3](280) Loss=0.38413 Rate=60.90 GlobalRate=44.98 Time=Sun Mar 29 04:45:32 2020\n",
            "[xla:7](300) Loss=0.54076 Rate=61.12 GlobalRate=42.40 Time=Sun Mar 29 04:45:37 2020\n",
            "[xla:3](300) Loss=0.32657 Rate=61.19 GlobalRate=45.79 Time=Sun Mar 29 04:45:37 2020\n",
            "[xla:2](300) Loss=0.32192 Rate=61.16 GlobalRate=42.44 Time=Sun Mar 29 04:45:37 2020\n",
            "[xla:5](300) Loss=0.31810 Rate=61.12 GlobalRate=45.75 Time=Sun Mar 29 04:45:37 2020\n",
            "[xla:6](300) Loss=0.36084 Rate=61.15 GlobalRate=45.80 Time=Sun Mar 29 04:45:37 2020\n",
            "[xla:4](300) Loss=0.49278 Rate=61.11 GlobalRate=44.44 Time=Sun Mar 29 04:45:37 2020\n",
            "[xla:1](300) Loss=0.34083 Rate=61.08 GlobalRate=35.76 Time=Sun Mar 29 04:45:37 2020\n",
            "[xla:0](300) Loss=0.36091 Rate=61.09 GlobalRate=35.70 Time=Sun Mar 29 04:45:37 2020\n",
            "[xla:3](320) Loss=0.45591 Rate=61.20 GlobalRate=46.52 Time=Sun Mar 29 04:45:42 2020\n",
            "[xla:1](320) Loss=0.38602 Rate=61.27 GlobalRate=36.71 Time=Sun Mar 29 04:45:42 2020\n",
            "[xla:2](320) Loss=0.49717 Rate=61.20 GlobalRate=43.27 Time=Sun Mar 29 04:45:42 2020\n",
            "[xla:0](320) Loss=0.33653 Rate=61.26 GlobalRate=36.66 Time=Sun Mar 29 04:45:42 2020\n",
            "[xla:6](320) Loss=0.43816 Rate=61.19 GlobalRate=46.53 Time=Sun Mar 29 04:45:42 2020\n",
            "[xla:5](320) Loss=0.48734 Rate=61.17 GlobalRate=46.48 Time=Sun Mar 29 04:45:42 2020\n",
            "[xla:7](320) Loss=0.35864 Rate=61.17 GlobalRate=43.22 Time=Sun Mar 29 04:45:42 2020\n",
            "[xla:4](320) Loss=0.51259 Rate=61.17 GlobalRate=45.21 Time=Sun Mar 29 04:45:42 2020\n",
            "[xla:3](340) Loss=0.41254 Rate=61.55 GlobalRate=47.21 Time=Sun Mar 29 04:45:47 2020\n",
            "[xla:6](340) Loss=0.32663 Rate=61.55 GlobalRate=47.22 Time=Sun Mar 29 04:45:47 2020\n",
            "[xla:4](340) Loss=0.39057 Rate=61.55 GlobalRate=45.94 Time=Sun Mar 29 04:45:47 2020\n",
            "[xla:1](340) Loss=0.47681 Rate=61.57 GlobalRate=37.61 Time=Sun Mar 29 04:45:47 2020\n",
            "[xla:0](340) Loss=0.43903 Rate=61.57 GlobalRate=37.55 Time=Sun Mar 29 04:45:47 2020\n",
            "[xla:5](340) Loss=0.34437 Rate=61.54 GlobalRate=47.17 Time=Sun Mar 29 04:45:47 2020\n",
            "[xla:2](340) Loss=0.48285 Rate=61.54 GlobalRate=44.04 Time=Sun Mar 29 04:45:47 2020\n",
            "[xla:7](340) Loss=0.47093 Rate=61.54 GlobalRate=44.00 Time=Sun Mar 29 04:45:47 2020\n",
            "Finished Training epoch 0\n",
            "Sizes: torch.Size([16, 2]), torch.Size([16, 2])\n",
            "[xla:0] Accuracy=88.46%\n",
            "[xla:7] Accuracy=89.42%\n",
            "[xla:2] Accuracy=91.03%\n",
            "[xla:6] Accuracy=91.99%\n",
            "[xla:3] Accuracy=90.87%\n",
            "[xla:5] Accuracy=91.99%\n",
            "[xla:4] Accuracy=90.38%\n",
            "[xla:1] Accuracy=89.10%\n",
            "[xla:3](0) Loss=0.40163 Rate=18.54 GlobalRate=18.54 Time=Sun Mar 29 04:46:07 2020\n",
            "[xla:5](0) Loss=0.54170 Rate=18.02 GlobalRate=18.02 Time=Sun Mar 29 04:46:07 2020\n",
            "[xla:1](0) Loss=0.59837 Rate=17.97 GlobalRate=17.97 Time=Sun Mar 29 04:46:07 2020\n",
            "[xla:7](0) Loss=0.37286 Rate=17.17 GlobalRate=17.16 Time=Sun Mar 29 04:46:07 2020\n",
            "[xla:4](0) Loss=0.42891 Rate=17.10 GlobalRate=17.10 Time=Sun Mar 29 04:46:07 2020\n",
            "[xla:2](0) Loss=0.50054 Rate=16.96 GlobalRate=16.96 Time=Sun Mar 29 04:46:07 2020\n",
            "[xla:6](0) Loss=0.37676 Rate=17.17 GlobalRate=17.17 Time=Sun Mar 29 04:46:07 2020\n",
            "[xla:0](0) Loss=0.35485 Rate=16.25 GlobalRate=16.25 Time=Sun Mar 29 04:46:07 2020\n",
            "[xla:0](20) Loss=0.31981 Rate=42.66 GlobalRate=53.38 Time=Sun Mar 29 04:46:12 2020\n",
            "[xla:4](20) Loss=0.37105 Rate=42.68 GlobalRate=53.39 Time=Sun Mar 29 04:46:12 2020\n",
            "[xla:1](20) Loss=0.31463 Rate=42.83 GlobalRate=53.53 Time=Sun Mar 29 04:46:12 2020\n",
            "[xla:3](20) Loss=0.50837 Rate=42.76 GlobalRate=53.37 Time=Sun Mar 29 04:46:12 2020\n",
            "[xla:7](20) Loss=0.36932 Rate=42.66 GlobalRate=53.37 Time=Sun Mar 29 04:46:12 2020\n",
            "[xla:5](20) Loss=0.43684 Rate=42.72 GlobalRate=53.38 Time=Sun Mar 29 04:46:12 2020\n",
            "[xla:2](20) Loss=0.36854 Rate=42.66 GlobalRate=53.37 Time=Sun Mar 29 04:46:12 2020\n",
            "[xla:6](20) Loss=0.36242 Rate=42.82 GlobalRate=53.57 Time=Sun Mar 29 04:46:12 2020\n",
            "[xla:3](40) Loss=0.50306 Rate=53.48 GlobalRate=56.68 Time=Sun Mar 29 04:46:18 2020\n",
            "[xla:6](40) Loss=0.39392 Rate=53.51 GlobalRate=56.80 Time=Sun Mar 29 04:46:18 2020\n",
            "[xla:4](40) Loss=0.37588 Rate=53.44 GlobalRate=56.69 Time=Sun Mar 29 04:46:18 2020\n",
            "[xla:5](40) Loss=0.37711 Rate=53.46 GlobalRate=56.68 Time=Sun Mar 29 04:46:18 2020\n",
            "[xla:2](40) Loss=0.34409 Rate=53.34 GlobalRate=56.61 Time=Sun Mar 29 04:46:18 2020\n",
            "[xla:0](40) Loss=0.46374 Rate=53.34 GlobalRate=56.61 Time=Sun Mar 29 04:46:18 2020\n",
            "[xla:7](40) Loss=0.33657 Rate=53.32 GlobalRate=56.59 Time=Sun Mar 29 04:46:18 2020\n",
            "[xla:1](40) Loss=0.53361 Rate=53.38 GlobalRate=56.68 Time=Sun Mar 29 04:46:18 2020\n",
            "[xla:2](60) Loss=0.34050 Rate=57.85 GlobalRate=57.93 Time=Sun Mar 29 04:46:23 2020\n",
            "[xla:4](60) Loss=0.45148 Rate=57.79 GlobalRate=57.94 Time=Sun Mar 29 04:46:23 2020\n",
            "[xla:3](60) Loss=0.35619 Rate=57.81 GlobalRate=57.94 Time=Sun Mar 29 04:46:23 2020\n",
            "[xla:1](60) Loss=0.43299 Rate=57.89 GlobalRate=58.00 Time=Sun Mar 29 04:46:23 2020\n",
            "[xla:5](60) Loss=0.43777 Rate=57.80 GlobalRate=57.93 Time=Sun Mar 29 04:46:23 2020\n",
            "[xla:6](60) Loss=0.33670 Rate=57.81 GlobalRate=58.01 Time=Sun Mar 29 04:46:23 2020\n",
            "[xla:0](60) Loss=0.52936 Rate=57.74 GlobalRate=57.89 Time=Sun Mar 29 04:46:23 2020\n",
            "[xla:7](60) Loss=0.49519 Rate=57.75 GlobalRate=57.87 Time=Sun Mar 29 04:46:23 2020\n",
            "[xla:0](80) Loss=0.37176 Rate=59.68 GlobalRate=58.62 Time=Sun Mar 29 04:46:28 2020\n",
            "[xla:6](80) Loss=0.46903 Rate=59.61 GlobalRate=58.68 Time=Sun Mar 29 04:46:28 2020\n",
            "[xla:5](80) Loss=0.47917 Rate=59.60 GlobalRate=58.62 Time=Sun Mar 29 04:46:28 2020\n",
            "[xla:4](80) Loss=0.31388 Rate=59.59 GlobalRate=58.62 Time=Sun Mar 29 04:46:28 2020\n",
            "[xla:3](80) Loss=0.37560 Rate=59.60 GlobalRate=58.62 Time=Sun Mar 29 04:46:28 2020\n",
            "[xla:1](80) Loss=0.31358 Rate=59.61 GlobalRate=58.65 Time=Sun Mar 29 04:46:28 2020\n",
            "[xla:7](80) Loss=0.40348 Rate=59.59 GlobalRate=58.58 Time=Sun Mar 29 04:46:28 2020\n",
            "[xla:2](80) Loss=0.33194 Rate=59.51 GlobalRate=58.57 Time=Sun Mar 29 04:46:28 2020\n",
            "[xla:0](100) Loss=0.37593 Rate=60.75 GlobalRate=59.16 Time=Sun Mar 29 04:46:33 2020\n",
            "[xla:2](100) Loss=0.43728 Rate=60.80 GlobalRate=59.16 Time=Sun Mar 29 04:46:33 2020\n",
            "[xla:6](100) Loss=0.35540 Rate=60.72 GlobalRate=59.21 Time=Sun Mar 29 04:46:33 2020\n",
            "[xla:7](100) Loss=0.37684 Rate=60.83 GlobalRate=59.16 Time=Sun Mar 29 04:46:33 2020\n",
            "[xla:4](100) Loss=0.31892 Rate=60.71 GlobalRate=59.16 Time=Sun Mar 29 04:46:33 2020\n",
            "[xla:1](100) Loss=0.31339 Rate=60.75 GlobalRate=59.20 Time=Sun Mar 29 04:46:33 2020\n",
            "[xla:5](100) Loss=0.33352 Rate=60.71 GlobalRate=59.16 Time=Sun Mar 29 04:46:33 2020\n",
            "[xla:3](100) Loss=0.36107 Rate=60.72 GlobalRate=59.16 Time=Sun Mar 29 04:46:33 2020\n",
            "[xla:6](120) Loss=0.37787 Rate=61.63 GlobalRate=59.69 Time=Sun Mar 29 04:46:39 2020\n",
            "[xla:5](120) Loss=0.34362 Rate=61.64 GlobalRate=59.65 Time=Sun Mar 29 04:46:39 2020\n",
            "[xla:0](120) Loss=0.33321 Rate=61.64 GlobalRate=59.65 Time=Sun Mar 29 04:46:39 2020\n",
            "[xla:3](120) Loss=0.37564 Rate=61.63 GlobalRate=59.65 Time=Sun Mar 29 04:46:39 2020\n",
            "[xla:4](120) Loss=0.32131 Rate=61.63 GlobalRate=59.65 Time=Sun Mar 29 04:46:39 2020\n",
            "[xla:1](120) Loss=0.37376 Rate=61.64 GlobalRate=59.68 Time=Sun Mar 29 04:46:39 2020\n",
            "[xla:7](120) Loss=0.44369 Rate=61.56 GlobalRate=59.62 Time=Sun Mar 29 04:46:39 2020\n",
            "[xla:2](120) Loss=0.32939 Rate=61.52 GlobalRate=59.61 Time=Sun Mar 29 04:46:39 2020\n",
            "[xla:5](140) Loss=0.34997 Rate=61.82 GlobalRate=59.96 Time=Sun Mar 29 04:46:44 2020\n",
            "[xla:1](140) Loss=0.59996 Rate=61.83 GlobalRate=59.99 Time=Sun Mar 29 04:46:44 2020\n",
            "[xla:2](140) Loss=0.37518 Rate=61.91 GlobalRate=59.96 Time=Sun Mar 29 04:46:44 2020\n",
            "[xla:4](140) Loss=0.37579 Rate=61.82 GlobalRate=59.96 Time=Sun Mar 29 04:46:44 2020\n",
            "[xla:7](140) Loss=0.46340 Rate=61.89 GlobalRate=59.96 Time=Sun Mar 29 04:46:44 2020\n",
            "[xla:3](140) Loss=0.52214 Rate=61.81 GlobalRate=59.96 Time=Sun Mar 29 04:46:44 2020\n",
            "[xla:6](140) Loss=0.32071 Rate=61.75 GlobalRate=59.98 Time=Sun Mar 29 04:46:44 2020\n",
            "[xla:0](140) Loss=0.37371 Rate=61.76 GlobalRate=59.95 Time=Sun Mar 29 04:46:44 2020\n",
            "[xla:6](160) Loss=0.35722 Rate=61.61 GlobalRate=60.17 Time=Sun Mar 29 04:46:49 2020\n",
            "[xla:0](160) Loss=0.37603 Rate=61.61 GlobalRate=60.14 Time=Sun Mar 29 04:46:49 2020\n",
            "[xla:5](160) Loss=0.45993 Rate=61.56 GlobalRate=60.14 Time=Sun Mar 29 04:46:49 2020\n",
            "[xla:7](160) Loss=0.37208 Rate=61.59 GlobalRate=60.13 Time=Sun Mar 29 04:46:49 2020\n",
            "[xla:1](160) Loss=0.38812 Rate=61.55 GlobalRate=60.16 Time=Sun Mar 29 04:46:49 2020\n",
            "[xla:3](160) Loss=0.37647 Rate=61.55 GlobalRate=60.13 Time=Sun Mar 29 04:46:49 2020\n",
            "[xla:4](160) Loss=0.37595 Rate=61.48 GlobalRate=60.12 Time=Sun Mar 29 04:46:49 2020\n",
            "[xla:2](160) Loss=0.31776 Rate=61.51 GlobalRate=60.12 Time=Sun Mar 29 04:46:49 2020\n",
            "[xla:7](180) Loss=0.37322 Rate=61.96 GlobalRate=60.36 Time=Sun Mar 29 04:46:54 2020\n",
            "[xla:2](180) Loss=0.37941 Rate=62.01 GlobalRate=60.36 Time=Sun Mar 29 04:46:54 2020\n",
            "[xla:3](180) Loss=0.31433 Rate=61.94 GlobalRate=60.35 Time=Sun Mar 29 04:46:54 2020\n",
            "[xla:0](180) Loss=0.31363 Rate=61.94 GlobalRate=60.36 Time=Sun Mar 29 04:46:54 2020\n",
            "[xla:5](180) Loss=0.31342 Rate=61.93 GlobalRate=60.36 Time=Sun Mar 29 04:46:54 2020\n",
            "[xla:6](180) Loss=0.66389 Rate=61.95 GlobalRate=60.38 Time=Sun Mar 29 04:46:54 2020\n",
            "[xla:4](180) Loss=0.37074 Rate=61.99 GlobalRate=60.36 Time=Sun Mar 29 04:46:54 2020\n",
            "[xla:1](180) Loss=0.41648 Rate=61.94 GlobalRate=60.38 Time=Sun Mar 29 04:46:54 2020\n",
            "[xla:4](200) Loss=0.38279 Rate=61.76 GlobalRate=60.48 Time=Sun Mar 29 04:46:59 2020\n",
            "[xla:6](200) Loss=0.40474 Rate=61.73 GlobalRate=60.50 Time=Sun Mar 29 04:46:59 2020\n",
            "[xla:1](200) Loss=0.43862 Rate=61.74 GlobalRate=60.50 Time=Sun Mar 29 04:46:59 2020\n",
            "[xla:3](200) Loss=0.34351 Rate=61.73 GlobalRate=60.48 Time=Sun Mar 29 04:46:59 2020\n",
            "[xla:0](200) Loss=0.38032 Rate=61.73 GlobalRate=60.48 Time=Sun Mar 29 04:46:59 2020\n",
            "[xla:5](200) Loss=0.31340 Rate=61.72 GlobalRate=60.48 Time=Sun Mar 29 04:46:59 2020\n",
            "[xla:7](200) Loss=0.31590 Rate=61.73 GlobalRate=60.48 Time=Sun Mar 29 04:46:59 2020\n",
            "[xla:2](200) Loss=0.48718 Rate=61.74 GlobalRate=60.47 Time=Sun Mar 29 04:46:59 2020\n",
            "[xla:0](220) Loss=0.31476 Rate=62.08 GlobalRate=60.64 Time=Sun Mar 29 04:47:04 2020\n",
            "[xla:2](220) Loss=0.31644 Rate=62.09 GlobalRate=60.64 Time=Sun Mar 29 04:47:04 2020\n",
            "[xla:6](220) Loss=0.44121 Rate=62.07 GlobalRate=60.66 Time=Sun Mar 29 04:47:04 2020\n",
            "[xla:1](220) Loss=0.42818 Rate=62.07 GlobalRate=60.66 Time=Sun Mar 29 04:47:04 2020\n",
            "[xla:4](220) Loss=0.45414 Rate=62.08 GlobalRate=60.64 Time=Sun Mar 29 04:47:04 2020\n",
            "[xla:7](220) Loss=0.31378 Rate=62.07 GlobalRate=60.64 Time=Sun Mar 29 04:47:04 2020\n",
            "[xla:3](220) Loss=0.33163 Rate=62.07 GlobalRate=60.64 Time=Sun Mar 29 04:47:04 2020\n",
            "[xla:5](220) Loss=0.46609 Rate=62.05 GlobalRate=60.63 Time=Sun Mar 29 04:47:04 2020\n",
            "[xla:6](240) Loss=0.31449 Rate=61.90 GlobalRate=60.75 Time=Sun Mar 29 04:47:10 2020\n",
            "[xla:3](240) Loss=0.31365 Rate=61.90 GlobalRate=60.73 Time=Sun Mar 29 04:47:10 2020\n",
            "[xla:2](240) Loss=0.31515 Rate=61.90 GlobalRate=60.73 Time=Sun Mar 29 04:47:10 2020\n",
            "[xla:4](240) Loss=0.40886 Rate=61.89 GlobalRate=60.73 Time=Sun Mar 29 04:47:10 2020\n",
            "[xla:1](240) Loss=0.37581 Rate=61.89 GlobalRate=60.75 Time=Sun Mar 29 04:47:10 2020\n",
            "[xla:0](240) Loss=0.36186 Rate=61.89 GlobalRate=60.73 Time=Sun Mar 29 04:47:10 2020\n",
            "[xla:5](240) Loss=0.47349 Rate=61.91 GlobalRate=60.73 Time=Sun Mar 29 04:47:10 2020\n",
            "[xla:7](240) Loss=0.36763 Rate=61.89 GlobalRate=60.73 Time=Sun Mar 29 04:47:10 2020\n",
            "[xla:4](260) Loss=0.31395 Rate=61.29 GlobalRate=60.74 Time=Sun Mar 29 04:47:15 2020\n",
            "[xla:5](260) Loss=0.36726 Rate=61.29 GlobalRate=60.74 Time=Sun Mar 29 04:47:15 2020\n",
            "[xla:1](260) Loss=0.50705 Rate=61.29 GlobalRate=60.76 Time=Sun Mar 29 04:47:15 2020\n",
            "[xla:3](260) Loss=0.43859 Rate=61.28 GlobalRate=60.74 Time=Sun Mar 29 04:47:15 2020\n",
            "[xla:6](260) Loss=0.31640 Rate=61.28 GlobalRate=60.76 Time=Sun Mar 29 04:47:15 2020\n",
            "[xla:2](260) Loss=0.31352 Rate=61.28 GlobalRate=60.74 Time=Sun Mar 29 04:47:15 2020\n",
            "[xla:0](260) Loss=0.34277 Rate=61.18 GlobalRate=60.73 Time=Sun Mar 29 04:47:15 2020\n",
            "[xla:7](260) Loss=0.38024 Rate=61.18 GlobalRate=60.73 Time=Sun Mar 29 04:47:15 2020\n",
            "[xla:2](280) Loss=0.43884 Rate=61.23 GlobalRate=60.77 Time=Sun Mar 29 04:47:20 2020\n",
            "[xla:4](280) Loss=0.36553 Rate=61.23 GlobalRate=60.77 Time=Sun Mar 29 04:47:20 2020\n",
            "[xla:6](280) Loss=0.47921 Rate=61.22 GlobalRate=60.79 Time=Sun Mar 29 04:47:20 2020\n",
            "[xla:5](280) Loss=0.43625 Rate=61.23 GlobalRate=60.77 Time=Sun Mar 29 04:47:20 2020\n",
            "[xla:1](280) Loss=0.32147 Rate=61.22 GlobalRate=60.79 Time=Sun Mar 29 04:47:20 2020\n",
            "[xla:0](280) Loss=0.40606 Rate=61.29 GlobalRate=60.77 Time=Sun Mar 29 04:47:20 2020\n",
            "[xla:3](280) Loss=0.31413 Rate=61.22 GlobalRate=60.77 Time=Sun Mar 29 04:47:20 2020\n",
            "[xla:7](280) Loss=0.33699 Rate=61.29 GlobalRate=60.77 Time=Sun Mar 29 04:47:20 2020\n",
            "[xla:6](300) Loss=0.42377 Rate=60.47 GlobalRate=60.74 Time=Sun Mar 29 04:47:25 2020\n",
            "[xla:0](300) Loss=0.32577 Rate=60.50 GlobalRate=60.72 Time=Sun Mar 29 04:47:25 2020\n",
            "[xla:3](300) Loss=0.32704 Rate=60.47 GlobalRate=60.72 Time=Sun Mar 29 04:47:25 2020\n",
            "[xla:4](300) Loss=0.45025 Rate=60.46 GlobalRate=60.72 Time=Sun Mar 29 04:47:25 2020\n",
            "[xla:1](300) Loss=0.39748 Rate=60.38 GlobalRate=60.72 Time=Sun Mar 29 04:47:25 2020\n",
            "[xla:7](300) Loss=0.43849 Rate=60.41 GlobalRate=60.71 Time=Sun Mar 29 04:47:25 2020\n",
            "[xla:5](300) Loss=0.32596 Rate=60.38 GlobalRate=60.71 Time=Sun Mar 29 04:47:25 2020\n",
            "[xla:2](300) Loss=0.31357 Rate=60.38 GlobalRate=60.71 Time=Sun Mar 29 04:47:25 2020\n",
            "[xla:3](320) Loss=0.54372 Rate=60.75 GlobalRate=60.73 Time=Sun Mar 29 04:47:31 2020\n",
            "[xla:1](320) Loss=0.44265 Rate=60.81 GlobalRate=60.74 Time=Sun Mar 29 04:47:31 2020\n",
            "[xla:0](320) Loss=0.37351 Rate=60.76 GlobalRate=60.73 Time=Sun Mar 29 04:47:31 2020\n",
            "[xla:4](320) Loss=0.48722 Rate=60.75 GlobalRate=60.73 Time=Sun Mar 29 04:47:31 2020\n",
            "[xla:6](320) Loss=0.49984 Rate=60.74 GlobalRate=60.75 Time=Sun Mar 29 04:47:31 2020\n",
            "[xla:2](320) Loss=0.43442 Rate=60.80 GlobalRate=60.73 Time=Sun Mar 29 04:47:31 2020\n",
            "[xla:5](320) Loss=0.43889 Rate=60.80 GlobalRate=60.73 Time=Sun Mar 29 04:47:31 2020\n",
            "[xla:7](320) Loss=0.35816 Rate=60.81 GlobalRate=60.73 Time=Sun Mar 29 04:47:31 2020\n",
            "[xla:6](340) Loss=0.31329 Rate=61.41 GlobalRate=60.81 Time=Sun Mar 29 04:47:36 2020\n",
            "[xla:4](340) Loss=0.38275 Rate=61.40 GlobalRate=60.80 Time=Sun Mar 29 04:47:36 2020\n",
            "[xla:2](340) Loss=0.46275 Rate=61.43 GlobalRate=60.79 Time=Sun Mar 29 04:47:36 2020\n",
            "[xla:1](340) Loss=0.40469 Rate=61.42 GlobalRate=60.81 Time=Sun Mar 29 04:47:36 2020\n",
            "[xla:5](340) Loss=0.32115 Rate=61.42 GlobalRate=60.79 Time=Sun Mar 29 04:47:36 2020\n",
            "[xla:3](340) Loss=0.37795 Rate=61.38 GlobalRate=60.79 Time=Sun Mar 29 04:47:36 2020\n",
            "[xla:7](340) Loss=0.44754 Rate=61.34 GlobalRate=60.79 Time=Sun Mar 29 04:47:36 2020\n",
            "[xla:0](340) Loss=0.42546 Rate=61.30 GlobalRate=60.79 Time=Sun Mar 29 04:47:36 2020\n",
            "Finished Training epoch 1\n",
            "Sizes: torch.Size([16, 2]), torch.Size([16, 2])\n",
            "[xla:5] Accuracy=91.35%\n",
            "[xla:4] Accuracy=90.38%\n",
            "[xla:3] Accuracy=90.71%\n",
            "[xla:0] Accuracy=89.26%\n",
            "[xla:1] Accuracy=89.90%\n",
            "[xla:7] Accuracy=90.06%\n",
            "[xla:6] Accuracy=91.35%\n",
            "[xla:2] Accuracy=90.87%\n",
            "[xla:5](0) Loss=0.50723 Rate=16.40 GlobalRate=16.40 Time=Sun Mar 29 04:47:44 2020\n",
            "[xla:3](0) Loss=0.37515 Rate=16.06 GlobalRate=16.06 Time=Sun Mar 29 04:47:44 2020\n",
            "[xla:4](0) Loss=0.39143 Rate=15.88 GlobalRate=15.88 Time=Sun Mar 29 04:47:44 2020\n",
            "[xla:0](0) Loss=0.31371 Rate=16.69 GlobalRate=16.69 Time=Sun Mar 29 04:47:44 2020\n",
            "[xla:1](0) Loss=0.55497 Rate=15.98 GlobalRate=15.98 Time=Sun Mar 29 04:47:44 2020\n",
            "[xla:2](0) Loss=0.49111 Rate=17.61 GlobalRate=17.61 Time=Sun Mar 29 04:47:44 2020\n",
            "[xla:6](0) Loss=0.37658 Rate=17.50 GlobalRate=17.50 Time=Sun Mar 29 04:47:44 2020\n",
            "[xla:7](0) Loss=0.36887 Rate=14.75 GlobalRate=14.74 Time=Sun Mar 29 04:47:44 2020\n",
            "[xla:2](20) Loss=0.37182 Rate=42.65 GlobalRate=53.32 Time=Sun Mar 29 04:47:50 2020\n",
            "[xla:6](20) Loss=0.31423 Rate=42.86 GlobalRate=53.60 Time=Sun Mar 29 04:47:50 2020\n",
            "[xla:0](20) Loss=0.31335 Rate=41.93 GlobalRate=52.46 Time=Sun Mar 29 04:47:50 2020\n",
            "[xla:7](20) Loss=0.37326 Rate=42.07 GlobalRate=52.56 Time=Sun Mar 29 04:47:50 2020\n",
            "[xla:3](20) Loss=0.43878 Rate=41.66 GlobalRate=52.13 Time=Sun Mar 29 04:47:50 2020\n",
            "[xla:5](20) Loss=0.48971 Rate=41.43 GlobalRate=51.84 Time=Sun Mar 29 04:47:50 2020\n",
            "[xla:4](20) Loss=0.37565 Rate=41.50 GlobalRate=51.93 Time=Sun Mar 29 04:47:50 2020\n",
            "[xla:1](20) Loss=0.31328 Rate=41.87 GlobalRate=52.39 Time=Sun Mar 29 04:47:50 2020\n",
            "[xla:1](40) Loss=0.49539 Rate=53.62 GlobalRate=56.45 Time=Sun Mar 29 04:47:55 2020\n",
            "[xla:5](40) Loss=0.37628 Rate=53.34 GlobalRate=56.05 Time=Sun Mar 29 04:47:55 2020\n",
            "[xla:4](40) Loss=0.37577 Rate=53.46 GlobalRate=56.17 Time=Sun Mar 29 04:47:55 2020\n",
            "[xla:2](40) Loss=0.31348 Rate=53.82 GlobalRate=56.92 Time=Sun Mar 29 04:47:55 2020\n",
            "[xla:6](40) Loss=0.31833 Rate=53.90 GlobalRate=57.09 Time=Sun Mar 29 04:47:55 2020\n",
            "[xla:7](40) Loss=0.31390 Rate=53.59 GlobalRate=56.48 Time=Sun Mar 29 04:47:55 2020\n",
            "[xla:3](40) Loss=0.50118 Rate=53.33 GlobalRate=56.15 Time=Sun Mar 29 04:47:55 2020\n",
            "[xla:0](40) Loss=0.44366 Rate=53.43 GlobalRate=56.35 Time=Sun Mar 29 04:47:55 2020\n",
            "[xla:6](60) Loss=0.36578 Rate=58.71 GlobalRate=58.58 Time=Sun Mar 29 04:48:00 2020\n",
            "[xla:0](60) Loss=0.43832 Rate=58.62 GlobalRate=58.11 Time=Sun Mar 29 04:48:00 2020\n",
            "[xla:5](60) Loss=0.36180 Rate=58.48 GlobalRate=57.85 Time=Sun Mar 29 04:48:00 2020\n",
            "[xla:3](60) Loss=0.37439 Rate=58.57 GlobalRate=57.96 Time=Sun Mar 29 04:48:00 2020\n",
            "[xla:1](60) Loss=0.38148 Rate=58.58 GlobalRate=58.13 Time=Sun Mar 29 04:48:00 2020\n",
            "[xla:4](60) Loss=0.37636 Rate=58.52 GlobalRate=57.93 Time=Sun Mar 29 04:48:00 2020\n",
            "[xla:2](60) Loss=0.38692 Rate=58.66 GlobalRate=58.46 Time=Sun Mar 29 04:48:00 2020\n",
            "[xla:7](60) Loss=0.37739 Rate=58.55 GlobalRate=58.13 Time=Sun Mar 29 04:48:00 2020\n",
            "[xla:6](80) Loss=0.41733 Rate=60.45 GlobalRate=59.30 Time=Sun Mar 29 04:48:05 2020\n",
            "[xla:4](80) Loss=0.31341 Rate=60.39 GlobalRate=58.80 Time=Sun Mar 29 04:48:05 2020\n",
            "[xla:1](80) Loss=0.31341 Rate=60.41 GlobalRate=58.95 Time=Sun Mar 29 04:48:05 2020\n",
            "[xla:7](80) Loss=0.37631 Rate=60.41 GlobalRate=58.97 Time=Sun Mar 29 04:48:05 2020\n",
            "[xla:2](80) Loss=0.31515 Rate=60.44 GlobalRate=59.21 Time=Sun Mar 29 04:48:05 2020\n",
            "[xla:0](80) Loss=0.37463 Rate=60.41 GlobalRate=58.93 Time=Sun Mar 29 04:48:05 2020\n",
            "[xla:5](80) Loss=0.39187 Rate=60.34 GlobalRate=58.72 Time=Sun Mar 29 04:48:05 2020\n",
            "[xla:3](80) Loss=0.31577 Rate=60.37 GlobalRate=58.82 Time=Sun Mar 29 04:48:05 2020\n",
            "[xla:1](100) Loss=0.31327 Rate=61.49 GlobalRate=59.57 Time=Sun Mar 29 04:48:11 2020\n",
            "[xla:4](100) Loss=0.40155 Rate=61.48 GlobalRate=59.45 Time=Sun Mar 29 04:48:11 2020\n",
            "[xla:0](100) Loss=0.32429 Rate=61.50 GlobalRate=59.55 Time=Sun Mar 29 04:48:11 2020\n",
            "[xla:2](100) Loss=0.37609 Rate=61.50 GlobalRate=59.78 Time=Sun Mar 29 04:48:11 2020\n",
            "[xla:6](100) Loss=0.31340 Rate=61.49 GlobalRate=59.85 Time=Sun Mar 29 04:48:11 2020\n",
            "[xla:5](100) Loss=0.31402 Rate=61.47 GlobalRate=59.39 Time=Sun Mar 29 04:48:11 2020\n",
            "[xla:7](100) Loss=0.37391 Rate=61.48 GlobalRate=59.58 Time=Sun Mar 29 04:48:11 2020\n",
            "[xla:3](100) Loss=0.31361 Rate=61.49 GlobalRate=59.46 Time=Sun Mar 29 04:48:11 2020\n",
            "[xla:5](120) Loss=0.31450 Rate=61.29 GlobalRate=59.67 Time=Sun Mar 29 04:48:16 2020\n",
            "[xla:4](120) Loss=0.35541 Rate=61.28 GlobalRate=59.72 Time=Sun Mar 29 04:48:16 2020\n",
            "[xla:1](120) Loss=0.37637 Rate=61.28 GlobalRate=59.83 Time=Sun Mar 29 04:48:16 2020\n",
            "[xla:0](120) Loss=0.33591 Rate=61.29 GlobalRate=59.81 Time=Sun Mar 29 04:48:16 2020\n",
            "[xla:2](120) Loss=0.31340 Rate=61.30 GlobalRate=60.01 Time=Sun Mar 29 04:48:16 2020\n",
            "[xla:3](120) Loss=0.37526 Rate=61.30 GlobalRate=59.74 Time=Sun Mar 29 04:48:16 2020\n",
            "[xla:6](120) Loss=0.31361 Rate=61.29 GlobalRate=60.06 Time=Sun Mar 29 04:48:16 2020\n",
            "[xla:7](120) Loss=0.38035 Rate=61.29 GlobalRate=59.83 Time=Sun Mar 29 04:48:16 2020\n",
            "[xla:1](140) Loss=0.56031 Rate=61.86 GlobalRate=60.16 Time=Sun Mar 29 04:48:21 2020\n",
            "[xla:0](140) Loss=0.32896 Rate=61.87 GlobalRate=60.15 Time=Sun Mar 29 04:48:21 2020\n",
            "[xla:6](140) Loss=0.31493 Rate=61.87 GlobalRate=60.37 Time=Sun Mar 29 04:48:21 2020\n",
            "[xla:5](140) Loss=0.31328 Rate=61.86 GlobalRate=60.03 Time=Sun Mar 29 04:48:21 2020\n",
            "[xla:4](140) Loss=0.37576 Rate=61.85 GlobalRate=60.06 Time=Sun Mar 29 04:48:21 2020\n",
            "[xla:2](140) Loss=0.36079 Rate=61.85 GlobalRate=60.31 Time=Sun Mar 29 04:48:21 2020\n",
            "[xla:3](140) Loss=0.50024 Rate=61.86 GlobalRate=60.08 Time=Sun Mar 29 04:48:21 2020\n",
            "[xla:7](140) Loss=0.37608 Rate=61.86 GlobalRate=60.16 Time=Sun Mar 29 04:48:21 2020\n",
            "[xla:5](160) Loss=0.49767 Rate=62.13 GlobalRate=60.30 Time=Sun Mar 29 04:48:26 2020\n",
            "[xla:0](160) Loss=0.37554 Rate=62.13 GlobalRate=60.41 Time=Sun Mar 29 04:48:26 2020\n",
            "[xla:4](160) Loss=0.33741 Rate=62.13 GlobalRate=60.33 Time=Sun Mar 29 04:48:26 2020\n",
            "[xla:3](160) Loss=0.43568 Rate=62.14 GlobalRate=60.35 Time=Sun Mar 29 04:48:26 2020\n",
            "[xla:1](160) Loss=0.37697 Rate=62.12 GlobalRate=60.42 Time=Sun Mar 29 04:48:26 2020\n",
            "[xla:6](160) Loss=0.37211 Rate=62.13 GlobalRate=60.60 Time=Sun Mar 29 04:48:26 2020\n",
            "[xla:2](160) Loss=0.31342 Rate=62.12 GlobalRate=60.55 Time=Sun Mar 29 04:48:26 2020\n",
            "[xla:7](160) Loss=0.37742 Rate=62.12 GlobalRate=60.42 Time=Sun Mar 29 04:48:26 2020\n",
            "[xla:6](180) Loss=0.58571 Rate=61.37 GlobalRate=60.63 Time=Sun Mar 29 04:48:31 2020\n",
            "[xla:4](180) Loss=0.31349 Rate=61.37 GlobalRate=60.39 Time=Sun Mar 29 04:48:31 2020\n",
            "[xla:0](180) Loss=0.36182 Rate=61.37 GlobalRate=60.46 Time=Sun Mar 29 04:48:31 2020\n",
            "[xla:1](180) Loss=0.31572 Rate=61.37 GlobalRate=60.47 Time=Sun Mar 29 04:48:31 2020\n",
            "[xla:2](180) Loss=0.37572 Rate=61.38 GlobalRate=60.59 Time=Sun Mar 29 04:48:31 2020\n",
            "[xla:5](180) Loss=0.31328 Rate=61.36 GlobalRate=60.36 Time=Sun Mar 29 04:48:31 2020\n",
            "[xla:3](180) Loss=0.31332 Rate=61.37 GlobalRate=60.41 Time=Sun Mar 29 04:48:31 2020\n",
            "[xla:7](180) Loss=0.36937 Rate=61.38 GlobalRate=60.47 Time=Sun Mar 29 04:48:31 2020\n",
            "[xla:5](200) Loss=0.31327 Rate=61.57 GlobalRate=60.49 Time=Sun Mar 29 04:48:36 2020\n",
            "[xla:1](200) Loss=0.43826 Rate=61.57 GlobalRate=60.59 Time=Sun Mar 29 04:48:36 2020\n",
            "[xla:4](200) Loss=0.31327 Rate=61.56 GlobalRate=60.52 Time=Sun Mar 29 04:48:36 2020\n",
            "[xla:3](200) Loss=0.31337 Rate=61.57 GlobalRate=60.53 Time=Sun Mar 29 04:48:36 2020\n",
            "[xla:2](200) Loss=0.43923 Rate=61.57 GlobalRate=60.70 Time=Sun Mar 29 04:48:36 2020\n",
            "[xla:7](200) Loss=0.31612 Rate=61.57 GlobalRate=60.59 Time=Sun Mar 29 04:48:36 2020\n",
            "[xla:6](200) Loss=0.38770 Rate=61.46 GlobalRate=60.72 Time=Sun Mar 29 04:48:36 2020\n",
            "[xla:0](200) Loss=0.37592 Rate=61.46 GlobalRate=60.56 Time=Sun Mar 29 04:48:36 2020\n",
            "[xla:3](220) Loss=0.36376 Rate=61.03 GlobalRate=60.54 Time=Sun Mar 29 04:48:42 2020\n",
            "[xla:6](220) Loss=0.43839 Rate=61.08 GlobalRate=60.73 Time=Sun Mar 29 04:48:42 2020\n",
            "[xla:0](220) Loss=0.31347 Rate=61.09 GlobalRate=60.59 Time=Sun Mar 29 04:48:42 2020\n",
            "[xla:5](220) Loss=0.43825 Rate=61.03 GlobalRate=60.51 Time=Sun Mar 29 04:48:42 2020\n",
            "[xla:2](220) Loss=0.31406 Rate=61.02 GlobalRate=60.69 Time=Sun Mar 29 04:48:42 2020\n",
            "[xla:1](220) Loss=0.37900 Rate=61.02 GlobalRate=60.59 Time=Sun Mar 29 04:48:42 2020\n",
            "[xla:4](220) Loss=0.38182 Rate=61.02 GlobalRate=60.53 Time=Sun Mar 29 04:48:42 2020\n",
            "[xla:7](220) Loss=0.38284 Rate=61.02 GlobalRate=60.60 Time=Sun Mar 29 04:48:42 2020\n",
            "[xla:6](240) Loss=0.39311 Rate=61.50 GlobalRate=60.81 Time=Sun Mar 29 04:48:47 2020\n",
            "[xla:5](240) Loss=0.43827 Rate=61.47 GlobalRate=60.61 Time=Sun Mar 29 04:48:47 2020\n",
            "[xla:4](240) Loss=0.46404 Rate=61.47 GlobalRate=60.63 Time=Sun Mar 29 04:48:47 2020\n",
            "[xla:7](240) Loss=0.37368 Rate=61.48 GlobalRate=60.69 Time=Sun Mar 29 04:48:47 2020\n",
            "[xla:0](240) Loss=0.35184 Rate=61.49 GlobalRate=60.68 Time=Sun Mar 29 04:48:47 2020\n",
            "[xla:1](240) Loss=0.37583 Rate=61.47 GlobalRate=60.69 Time=Sun Mar 29 04:48:47 2020\n",
            "[xla:2](240) Loss=0.31330 Rate=61.47 GlobalRate=60.78 Time=Sun Mar 29 04:48:47 2020\n",
            "[xla:3](240) Loss=0.35494 Rate=61.46 GlobalRate=60.64 Time=Sun Mar 29 04:48:47 2020\n",
            "[xla:7](260) Loss=0.37585 Rate=61.53 GlobalRate=60.76 Time=Sun Mar 29 04:48:52 2020\n",
            "[xla:1](260) Loss=0.43848 Rate=61.53 GlobalRate=60.76 Time=Sun Mar 29 04:48:52 2020\n",
            "[xla:4](260) Loss=0.31758 Rate=61.54 GlobalRate=60.70 Time=Sun Mar 29 04:48:52 2020\n",
            "[xla:3](260) Loss=0.43863 Rate=61.53 GlobalRate=60.71 Time=Sun Mar 29 04:48:52 2020\n",
            "[xla:6](260) Loss=0.31328 Rate=61.54 GlobalRate=60.87 Time=Sun Mar 29 04:48:52 2020\n",
            "[xla:0](260) Loss=0.37656 Rate=61.54 GlobalRate=60.75 Time=Sun Mar 29 04:48:52 2020\n",
            "[xla:5](260) Loss=0.32088 Rate=61.53 GlobalRate=60.68 Time=Sun Mar 29 04:48:52 2020\n",
            "[xla:2](260) Loss=0.31334 Rate=61.53 GlobalRate=60.84 Time=Sun Mar 29 04:48:52 2020\n",
            "[xla:6](280) Loss=0.37596 Rate=61.59 GlobalRate=60.92 Time=Sun Mar 29 04:48:57 2020\n",
            "[xla:5](280) Loss=0.38549 Rate=61.60 GlobalRate=60.75 Time=Sun Mar 29 04:48:57 2020\n",
            "[xla:3](280) Loss=0.36048 Rate=61.59 GlobalRate=60.78 Time=Sun Mar 29 04:48:57 2020\n",
            "[xla:4](280) Loss=0.31355 Rate=61.59 GlobalRate=60.77 Time=Sun Mar 29 04:48:57 2020\n",
            "[xla:7](280) Loss=0.31368 Rate=61.59 GlobalRate=60.82 Time=Sun Mar 29 04:48:57 2020\n",
            "[xla:1](280) Loss=0.31743 Rate=61.58 GlobalRate=60.82 Time=Sun Mar 29 04:48:57 2020\n",
            "[xla:2](280) Loss=0.43637 Rate=61.49 GlobalRate=60.88 Time=Sun Mar 29 04:48:57 2020\n",
            "[xla:0](280) Loss=0.31342 Rate=61.48 GlobalRate=60.80 Time=Sun Mar 29 04:48:57 2020\n",
            "[xla:0](300) Loss=0.31327 Rate=61.58 GlobalRate=60.85 Time=Sun Mar 29 04:49:03 2020\n",
            "[xla:5](300) Loss=0.33793 Rate=61.52 GlobalRate=60.80 Time=Sun Mar 29 04:49:03 2020\n",
            "[xla:1](300) Loss=0.38303 Rate=61.52 GlobalRate=60.86 Time=Sun Mar 29 04:49:03 2020\n",
            "[xla:7](300) Loss=0.43835 Rate=61.51 GlobalRate=60.86 Time=Sun Mar 29 04:49:03 2020\n",
            "[xla:2](300) Loss=0.32889 Rate=61.58 GlobalRate=60.93 Time=Sun Mar 29 04:49:03 2020\n",
            "[xla:6](300) Loss=0.38607 Rate=61.51 GlobalRate=60.96 Time=Sun Mar 29 04:49:03 2020\n",
            "[xla:4](300) Loss=0.52086 Rate=61.41 GlobalRate=60.80 Time=Sun Mar 29 04:49:03 2020\n",
            "[xla:3](300) Loss=0.33195 Rate=61.41 GlobalRate=60.81 Time=Sun Mar 29 04:49:03 2020\n",
            "[xla:4](320) Loss=0.42928 Rate=61.99 GlobalRate=60.90 Time=Sun Mar 29 04:49:08 2020\n",
            "[xla:1](320) Loss=0.32435 Rate=61.92 GlobalRate=60.94 Time=Sun Mar 29 04:49:08 2020\n",
            "[xla:6](320) Loss=0.31653 Rate=61.92 GlobalRate=61.03 Time=Sun Mar 29 04:49:08 2020\n",
            "[xla:0](320) Loss=0.43641 Rate=61.94 GlobalRate=60.94 Time=Sun Mar 29 04:49:08 2020\n",
            "[xla:7](320) Loss=0.32844 Rate=61.92 GlobalRate=60.94 Time=Sun Mar 29 04:49:08 2020\n",
            "[xla:3](320) Loss=0.50056 Rate=61.98 GlobalRate=60.91 Time=Sun Mar 29 04:49:08 2020\n",
            "[xla:2](320) Loss=0.43811 Rate=61.94 GlobalRate=61.01 Time=Sun Mar 29 04:49:08 2020\n",
            "[xla:5](320) Loss=0.44096 Rate=61.91 GlobalRate=60.88 Time=Sun Mar 29 04:49:08 2020\n",
            "[xla:4](340) Loss=0.31328 Rate=61.85 GlobalRate=60.95 Time=Sun Mar 29 04:49:13 2020\n",
            "[xla:1](340) Loss=0.37637 Rate=61.82 GlobalRate=60.99 Time=Sun Mar 29 04:49:13 2020\n",
            "[xla:2](340) Loss=0.43935 Rate=61.83 GlobalRate=61.05 Time=Sun Mar 29 04:49:13 2020\n",
            "[xla:6](340) Loss=0.31327 Rate=61.81 GlobalRate=61.07 Time=Sun Mar 29 04:49:13 2020\n",
            "[xla:0](340) Loss=0.37591 Rate=61.82 GlobalRate=60.98 Time=Sun Mar 29 04:49:13 2020\n",
            "[xla:3](340) Loss=0.37600 Rate=61.84 GlobalRate=60.95 Time=Sun Mar 29 04:49:13 2020\n",
            "[xla:7](340) Loss=0.36704 Rate=61.81 GlobalRate=60.99 Time=Sun Mar 29 04:49:13 2020\n",
            "[xla:5](340) Loss=0.32308 Rate=61.81 GlobalRate=60.93 Time=Sun Mar 29 04:49:13 2020\n",
            "Finished Training epoch 2\n",
            "Sizes: torch.Size([16, 2]), torch.Size([16, 2])\n",
            "[xla:2] Accuracy=90.38%\n",
            "[xla:3] Accuracy=91.03%\n",
            "[xla:4] Accuracy=89.10%\n",
            "[xla:1] Accuracy=88.30%\n",
            "[xla:7] Accuracy=90.22%\n",
            "[xla:5] Accuracy=91.03%\n",
            "[xla:6] Accuracy=89.58%\n",
            "[xla:0] Accuracy=89.74%\n",
            "[xla:2](0) Loss=0.43982 Rate=19.04 GlobalRate=19.04 Time=Sun Mar 29 04:49:21 2020\n",
            "[xla:3](0) Loss=0.35863 Rate=16.35 GlobalRate=16.35 Time=Sun Mar 29 04:49:21 2020\n",
            "[xla:4](0) Loss=0.46641 Rate=16.54 GlobalRate=16.54 Time=Sun Mar 29 04:49:21 2020\n",
            "[xla:1](0) Loss=0.55711 Rate=16.19 GlobalRate=16.19 Time=Sun Mar 29 04:49:21 2020\n",
            "[xla:6](0) Loss=0.39486 Rate=17.16 GlobalRate=17.16 Time=Sun Mar 29 04:49:22 2020\n",
            "[xla:7](0) Loss=0.31526 Rate=13.28 GlobalRate=13.28 Time=Sun Mar 29 04:49:22 2020\n",
            "[xla:0](0) Loss=0.31336 Rate=15.51 GlobalRate=15.51 Time=Sun Mar 29 04:49:22 2020\n",
            "[xla:5](0) Loss=0.45049 Rate=14.43 GlobalRate=14.43 Time=Sun Mar 29 04:49:22 2020\n",
            "[xla:3](20) Loss=0.49227 Rate=40.75 GlobalRate=50.98 Time=Sun Mar 29 04:49:27 2020\n",
            "[xla:1](20) Loss=0.31327 Rate=41.01 GlobalRate=51.32 Time=Sun Mar 29 04:49:27 2020\n",
            "[xla:4](20) Loss=0.37578 Rate=40.90 GlobalRate=51.16 Time=Sun Mar 29 04:49:27 2020\n",
            "[xla:5](20) Loss=0.43828 Rate=42.21 GlobalRate=52.68 Time=Sun Mar 29 04:49:27 2020\n",
            "[xla:6](20) Loss=0.42967 Rate=42.50 GlobalRate=53.16 Time=Sun Mar 29 04:49:27 2020\n",
            "[xla:7](20) Loss=0.40139 Rate=41.13 GlobalRate=51.18 Time=Sun Mar 29 04:49:27 2020\n",
            "[xla:2](20) Loss=0.43510 Rate=40.75 GlobalRate=50.64 Time=Sun Mar 29 04:49:27 2020\n",
            "[xla:0](20) Loss=0.32830 Rate=41.97 GlobalRate=52.50 Time=Sun Mar 29 04:49:27 2020\n",
            "[xla:5](40) Loss=0.43855 Rate=53.22 GlobalRate=56.25 Time=Sun Mar 29 04:49:32 2020\n",
            "[xla:0](40) Loss=0.43826 Rate=53.23 GlobalRate=56.22 Time=Sun Mar 29 04:49:32 2020\n",
            "[xla:1](40) Loss=0.43830 Rate=52.74 GlobalRate=55.44 Time=Sun Mar 29 04:49:32 2020\n",
            "[xla:6](40) Loss=0.31328 Rate=53.33 GlobalRate=56.53 Time=Sun Mar 29 04:49:32 2020\n",
            "[xla:3](40) Loss=0.50077 Rate=52.64 GlobalRate=55.24 Time=Sun Mar 29 04:49:32 2020\n",
            "[xla:2](40) Loss=0.31338 Rate=52.75 GlobalRate=55.11 Time=Sun Mar 29 04:49:32 2020\n",
            "[xla:7](40) Loss=0.31409 Rate=52.79 GlobalRate=55.36 Time=Sun Mar 29 04:49:32 2020\n",
            "[xla:4](40) Loss=0.37576 Rate=52.69 GlobalRate=55.34 Time=Sun Mar 29 04:49:32 2020\n",
            "[xla:1](60) Loss=0.37767 Rate=57.91 GlobalRate=57.25 Time=Sun Mar 29 04:49:37 2020\n",
            "[xla:6](60) Loss=0.31331 Rate=58.15 GlobalRate=58.03 Time=Sun Mar 29 04:49:37 2020\n",
            "[xla:4](60) Loss=0.37578 Rate=57.89 GlobalRate=57.18 Time=Sun Mar 29 04:49:37 2020\n",
            "[xla:2](60) Loss=0.31330 Rate=57.90 GlobalRate=57.01 Time=Sun Mar 29 04:49:37 2020\n",
            "[xla:0](60) Loss=0.43841 Rate=58.09 GlobalRate=57.80 Time=Sun Mar 29 04:49:37 2020\n",
            "[xla:7](60) Loss=0.37581 Rate=57.92 GlobalRate=57.19 Time=Sun Mar 29 04:49:37 2020\n",
            "[xla:5](60) Loss=0.37046 Rate=57.99 GlobalRate=57.78 Time=Sun Mar 29 04:49:38 2020\n",
            "[xla:3](60) Loss=0.31461 Rate=57.76 GlobalRate=57.06 Time=Sun Mar 29 04:49:38 2020\n",
            "[xla:6](80) Loss=0.37597 Rate=60.62 GlobalRate=59.02 Time=Sun Mar 29 04:49:43 2020\n",
            "[xla:2](80) Loss=0.31457 Rate=60.54 GlobalRate=58.23 Time=Sun Mar 29 04:49:43 2020\n",
            "[xla:4](80) Loss=0.37571 Rate=60.52 GlobalRate=58.36 Time=Sun Mar 29 04:49:43 2020\n",
            "[xla:3](80) Loss=0.33779 Rate=60.57 GlobalRate=58.30 Time=Sun Mar 29 04:49:43 2020\n",
            "[xla:1](80) Loss=0.31937 Rate=60.51 GlobalRate=58.41 Time=Sun Mar 29 04:49:43 2020\n",
            "[xla:5](80) Loss=0.34578 Rate=60.66 GlobalRate=58.86 Time=Sun Mar 29 04:49:43 2020\n",
            "[xla:7](80) Loss=0.37607 Rate=60.42 GlobalRate=58.33 Time=Sun Mar 29 04:49:43 2020\n",
            "[xla:0](80) Loss=0.37549 Rate=60.49 GlobalRate=58.81 Time=Sun Mar 29 04:49:43 2020\n",
            "[xla:4](100) Loss=0.31328 Rate=61.33 GlobalRate=59.02 Time=Sun Mar 29 04:49:48 2020\n",
            "[xla:3](100) Loss=0.33032 Rate=61.36 GlobalRate=58.98 Time=Sun Mar 29 04:49:48 2020\n",
            "[xla:5](100) Loss=0.31476 Rate=61.39 GlobalRate=59.44 Time=Sun Mar 29 04:49:48 2020\n",
            "[xla:7](100) Loss=0.37698 Rate=61.40 GlobalRate=59.03 Time=Sun Mar 29 04:49:48 2020\n",
            "[xla:1](100) Loss=0.31327 Rate=61.33 GlobalRate=59.07 Time=Sun Mar 29 04:49:48 2020\n",
            "[xla:2](100) Loss=0.43644 Rate=61.33 GlobalRate=58.91 Time=Sun Mar 29 04:49:48 2020\n",
            "[xla:0](100) Loss=0.37663 Rate=61.43 GlobalRate=59.42 Time=Sun Mar 29 04:49:48 2020\n",
            "[xla:6](100) Loss=0.31327 Rate=61.35 GlobalRate=59.56 Time=Sun Mar 29 04:49:48 2020\n",
            "[xla:1](120) Loss=0.37687 Rate=61.29 GlobalRate=59.42 Time=Sun Mar 29 04:49:53 2020\n",
            "[xla:3](120) Loss=0.37410 Rate=61.29 GlobalRate=59.34 Time=Sun Mar 29 04:49:53 2020\n",
            "[xla:6](120) Loss=0.31328 Rate=61.30 GlobalRate=59.83 Time=Sun Mar 29 04:49:53 2020\n",
            "[xla:5](120) Loss=0.31335 Rate=61.31 GlobalRate=59.73 Time=Sun Mar 29 04:49:53 2020\n",
            "[xla:2](120) Loss=0.31328 Rate=61.28 GlobalRate=59.29 Time=Sun Mar 29 04:49:53 2020\n",
            "[xla:0](120) Loss=0.31328 Rate=61.32 GlobalRate=59.72 Time=Sun Mar 29 04:49:53 2020\n",
            "[xla:4](120) Loss=0.31330 Rate=61.27 GlobalRate=59.38 Time=Sun Mar 29 04:49:53 2020\n",
            "[xla:7](120) Loss=0.43811 Rate=61.31 GlobalRate=59.39 Time=Sun Mar 29 04:49:53 2020\n",
            "[xla:5](140) Loss=0.31327 Rate=61.46 GlobalRate=59.98 Time=Sun Mar 29 04:49:58 2020\n",
            "[xla:4](140) Loss=0.37576 Rate=61.45 GlobalRate=59.68 Time=Sun Mar 29 04:49:58 2020\n",
            "[xla:2](140) Loss=0.31334 Rate=61.45 GlobalRate=59.60 Time=Sun Mar 29 04:49:58 2020\n",
            "[xla:7](140) Loss=0.37659 Rate=61.47 GlobalRate=59.69 Time=Sun Mar 29 04:49:58 2020\n",
            "[xla:0](140) Loss=0.31351 Rate=61.47 GlobalRate=59.97 Time=Sun Mar 29 04:49:58 2020\n",
            "[xla:1](140) Loss=0.49907 Rate=61.44 GlobalRate=59.71 Time=Sun Mar 29 04:49:58 2020\n",
            "[xla:6](140) Loss=0.31329 Rate=61.45 GlobalRate=60.07 Time=Sun Mar 29 04:49:58 2020\n",
            "[xla:3](140) Loss=0.50065 Rate=61.43 GlobalRate=59.64 Time=Sun Mar 29 04:49:58 2020\n",
            "[xla:3](160) Loss=0.37961 Rate=61.32 GlobalRate=59.84 Time=Sun Mar 29 04:50:03 2020\n",
            "[xla:1](160) Loss=0.41651 Rate=61.31 GlobalRate=59.89 Time=Sun Mar 29 04:50:03 2020\n",
            "[xla:5](160) Loss=0.43840 Rate=61.31 GlobalRate=60.13 Time=Sun Mar 29 04:50:03 2020\n",
            "[xla:2](160) Loss=0.31327 Rate=61.30 GlobalRate=59.79 Time=Sun Mar 29 04:50:03 2020\n",
            "[xla:0](160) Loss=0.37576 Rate=61.31 GlobalRate=60.12 Time=Sun Mar 29 04:50:03 2020\n",
            "[xla:4](160) Loss=0.31327 Rate=61.30 GlobalRate=59.86 Time=Sun Mar 29 04:50:03 2020\n",
            "[xla:6](160) Loss=0.35110 Rate=61.31 GlobalRate=60.21 Time=Sun Mar 29 04:50:03 2020\n",
            "[xla:7](160) Loss=0.38778 Rate=61.31 GlobalRate=59.87 Time=Sun Mar 29 04:50:03 2020\n",
            "[xla:5](180) Loss=0.31326 Rate=61.16 GlobalRate=60.23 Time=Sun Mar 29 04:50:09 2020\n",
            "[xla:1](180) Loss=0.36172 Rate=61.16 GlobalRate=60.02 Time=Sun Mar 29 04:50:09 2020\n",
            "[xla:6](180) Loss=0.56326 Rate=61.16 GlobalRate=60.30 Time=Sun Mar 29 04:50:09 2020\n",
            "[xla:7](180) Loss=0.31329 Rate=61.16 GlobalRate=60.00 Time=Sun Mar 29 04:50:09 2020\n",
            "[xla:3](180) Loss=0.31343 Rate=61.15 GlobalRate=59.96 Time=Sun Mar 29 04:50:09 2020\n",
            "[xla:0](180) Loss=0.31327 Rate=61.15 GlobalRate=60.22 Time=Sun Mar 29 04:50:09 2020\n",
            "[xla:4](180) Loss=0.31342 Rate=61.08 GlobalRate=59.98 Time=Sun Mar 29 04:50:09 2020\n",
            "[xla:2](180) Loss=0.37571 Rate=61.07 GlobalRate=59.92 Time=Sun Mar 29 04:50:09 2020\n",
            "[xla:1](200) Loss=0.43826 Rate=61.22 GlobalRate=60.14 Time=Sun Mar 29 04:50:14 2020\n",
            "[xla:7](200) Loss=0.37929 Rate=61.22 GlobalRate=60.12 Time=Sun Mar 29 04:50:14 2020\n",
            "[xla:6](200) Loss=0.37594 Rate=61.22 GlobalRate=60.40 Time=Sun Mar 29 04:50:14 2020\n",
            "[xla:0](200) Loss=0.37579 Rate=61.23 GlobalRate=60.33 Time=Sun Mar 29 04:50:14 2020\n",
            "[xla:4](200) Loss=0.31411 Rate=61.26 GlobalRate=60.12 Time=Sun Mar 29 04:50:14 2020\n",
            "[xla:3](200) Loss=0.31353 Rate=61.23 GlobalRate=60.09 Time=Sun Mar 29 04:50:14 2020\n",
            "[xla:5](200) Loss=0.31354 Rate=61.22 GlobalRate=60.33 Time=Sun Mar 29 04:50:14 2020\n",
            "[xla:2](200) Loss=0.43274 Rate=61.27 GlobalRate=60.06 Time=Sun Mar 29 04:50:14 2020\n",
            "[xla:2](220) Loss=0.31329 Rate=61.12 GlobalRate=60.15 Time=Sun Mar 29 04:50:19 2020\n",
            "[xla:3](220) Loss=0.37151 Rate=61.10 GlobalRate=60.18 Time=Sun Mar 29 04:50:19 2020\n",
            "[xla:4](220) Loss=0.31330 Rate=61.11 GlobalRate=60.20 Time=Sun Mar 29 04:50:19 2020\n",
            "[xla:6](220) Loss=0.44156 Rate=61.09 GlobalRate=60.45 Time=Sun Mar 29 04:50:19 2020\n",
            "[xla:1](220) Loss=0.36003 Rate=61.10 GlobalRate=60.22 Time=Sun Mar 29 04:50:19 2020\n",
            "[xla:0](220) Loss=0.36258 Rate=61.10 GlobalRate=60.39 Time=Sun Mar 29 04:50:19 2020\n",
            "[xla:7](220) Loss=0.35985 Rate=61.09 GlobalRate=60.20 Time=Sun Mar 29 04:50:19 2020\n",
            "[xla:5](220) Loss=0.38578 Rate=61.08 GlobalRate=60.39 Time=Sun Mar 29 04:50:19 2020\n",
            "[xla:3](240) Loss=0.31327 Rate=61.90 GlobalRate=60.36 Time=Sun Mar 29 04:50:24 2020\n",
            "[xla:4](240) Loss=0.37578 Rate=61.91 GlobalRate=60.38 Time=Sun Mar 29 04:50:24 2020\n",
            "[xla:6](240) Loss=0.32252 Rate=61.90 GlobalRate=60.61 Time=Sun Mar 29 04:50:24 2020\n",
            "[xla:1](240) Loss=0.37577 Rate=61.90 GlobalRate=60.40 Time=Sun Mar 29 04:50:24 2020\n",
            "[xla:5](240) Loss=0.41983 Rate=61.91 GlobalRate=60.56 Time=Sun Mar 29 04:50:24 2020\n",
            "[xla:2](240) Loss=0.31327 Rate=61.91 GlobalRate=60.33 Time=Sun Mar 29 04:50:24 2020\n",
            "[xla:0](240) Loss=0.31498 Rate=61.90 GlobalRate=60.55 Time=Sun Mar 29 04:50:24 2020\n",
            "[xla:7](240) Loss=0.31357 Rate=61.89 GlobalRate=60.38 Time=Sun Mar 29 04:50:24 2020\n",
            "[xla:1](260) Loss=0.49002 Rate=61.66 GlobalRate=60.48 Time=Sun Mar 29 04:50:29 2020\n",
            "[xla:3](260) Loss=0.43847 Rate=61.65 GlobalRate=60.44 Time=Sun Mar 29 04:50:29 2020\n",
            "[xla:0](260) Loss=0.32005 Rate=61.64 GlobalRate=60.62 Time=Sun Mar 29 04:50:29 2020\n",
            "[xla:6](260) Loss=0.34171 Rate=61.63 GlobalRate=60.68 Time=Sun Mar 29 04:50:29 2020\n",
            "[xla:2](260) Loss=0.33980 Rate=61.63 GlobalRate=60.41 Time=Sun Mar 29 04:50:29 2020\n",
            "[xla:5](260) Loss=0.31378 Rate=61.63 GlobalRate=60.63 Time=Sun Mar 29 04:50:29 2020\n",
            "[xla:4](260) Loss=0.32795 Rate=61.63 GlobalRate=60.46 Time=Sun Mar 29 04:50:29 2020\n",
            "[xla:7](260) Loss=0.38233 Rate=61.63 GlobalRate=60.46 Time=Sun Mar 29 04:50:29 2020\n",
            "[xla:2](280) Loss=0.47786 Rate=61.93 GlobalRate=60.53 Time=Sun Mar 29 04:50:35 2020\n",
            "[xla:4](280) Loss=0.31395 Rate=61.93 GlobalRate=60.57 Time=Sun Mar 29 04:50:35 2020\n",
            "[xla:1](280) Loss=0.34125 Rate=61.91 GlobalRate=60.59 Time=Sun Mar 29 04:50:35 2020\n",
            "[xla:6](280) Loss=0.41407 Rate=61.92 GlobalRate=60.78 Time=Sun Mar 29 04:50:35 2020\n",
            "[xla:5](280) Loss=0.37599 Rate=61.86 GlobalRate=60.72 Time=Sun Mar 29 04:50:35 2020\n",
            "[xla:3](280) Loss=0.31956 Rate=61.83 GlobalRate=60.55 Time=Sun Mar 29 04:50:35 2020\n",
            "[xla:7](280) Loss=0.37516 Rate=61.84 GlobalRate=60.57 Time=Sun Mar 29 04:50:35 2020\n",
            "[xla:0](280) Loss=0.31334 Rate=61.82 GlobalRate=60.71 Time=Sun Mar 29 04:50:35 2020\n",
            "[xla:1](300) Loss=0.37576 Rate=61.85 GlobalRate=60.67 Time=Sun Mar 29 04:50:40 2020\n",
            "[xla:6](300) Loss=0.31327 Rate=61.86 GlobalRate=60.84 Time=Sun Mar 29 04:50:40 2020\n",
            "[xla:7](300) Loss=0.43826 Rate=61.91 GlobalRate=60.66 Time=Sun Mar 29 04:50:40 2020\n",
            "[xla:3](300) Loss=0.31336 Rate=61.90 GlobalRate=60.64 Time=Sun Mar 29 04:50:40 2020\n",
            "[xla:2](300) Loss=0.31327 Rate=61.85 GlobalRate=60.62 Time=Sun Mar 29 04:50:40 2020\n",
            "[xla:0](300) Loss=0.32561 Rate=61.91 GlobalRate=60.80 Time=Sun Mar 29 04:50:40 2020\n",
            "[xla:4](300) Loss=0.43755 Rate=61.79 GlobalRate=60.65 Time=Sun Mar 29 04:50:40 2020\n",
            "[xla:5](300) Loss=0.31327 Rate=61.82 GlobalRate=60.79 Time=Sun Mar 29 04:50:40 2020\n",
            "[xla:6](320) Loss=0.31345 Rate=61.72 GlobalRate=60.89 Time=Sun Mar 29 04:50:45 2020\n",
            "[xla:3](320) Loss=0.50140 Rate=61.74 GlobalRate=60.70 Time=Sun Mar 29 04:50:45 2020\n",
            "[xla:4](320) Loss=0.37647 Rate=61.76 GlobalRate=60.71 Time=Sun Mar 29 04:50:45 2020\n",
            "[xla:2](320) Loss=0.50062 Rate=61.72 GlobalRate=60.68 Time=Sun Mar 29 04:50:45 2020\n",
            "[xla:7](320) Loss=0.31528 Rate=61.74 GlobalRate=60.72 Time=Sun Mar 29 04:50:45 2020\n",
            "[xla:0](320) Loss=0.39901 Rate=61.73 GlobalRate=60.85 Time=Sun Mar 29 04:50:45 2020\n",
            "[xla:1](320) Loss=0.32561 Rate=61.61 GlobalRate=60.72 Time=Sun Mar 29 04:50:45 2020\n",
            "[xla:5](320) Loss=0.43878 Rate=61.67 GlobalRate=60.84 Time=Sun Mar 29 04:50:45 2020\n",
            "[xla:4](340) Loss=0.31327 Rate=61.64 GlobalRate=60.76 Time=Sun Mar 29 04:50:50 2020\n",
            "[xla:6](340) Loss=0.31600 Rate=61.62 GlobalRate=60.93 Time=Sun Mar 29 04:50:50 2020\n",
            "[xla:3](340) Loss=0.38006 Rate=61.62 GlobalRate=60.75 Time=Sun Mar 29 04:50:50 2020\n",
            "[xla:0](340) Loss=0.37577 Rate=61.63 GlobalRate=60.89 Time=Sun Mar 29 04:50:50 2020\n",
            "[xla:7](340) Loss=0.31330 Rate=61.63 GlobalRate=60.77 Time=Sun Mar 29 04:50:50 2020\n",
            "[xla:2](340) Loss=0.43829 Rate=61.61 GlobalRate=60.73 Time=Sun Mar 29 04:50:50 2020\n",
            "[xla:1](340) Loss=0.40159 Rate=61.65 GlobalRate=60.77 Time=Sun Mar 29 04:50:50 2020\n",
            "[xla:5](340) Loss=0.41741 Rate=61.66 GlobalRate=60.89 Time=Sun Mar 29 04:50:50 2020\n",
            "Finished Training epoch 3\n",
            "Sizes: torch.Size([16, 2]), torch.Size([16, 2])\n",
            "[xla:1] Accuracy=89.10%\n",
            "[xla:0] Accuracy=90.06%\n",
            "[xla:6] Accuracy=91.51%\n",
            "[xla:4] Accuracy=90.22%\n",
            "[xla:2] Accuracy=90.87%\n",
            "[xla:5] Accuracy=91.51%\n",
            "[xla:7] Accuracy=89.90%\n",
            "[xla:3] Accuracy=91.19%\n",
            "[xla:6](0) Loss=0.37576 Rate=18.51 GlobalRate=18.50 Time=Sun Mar 29 04:50:59 2020\n",
            "[xla:3](0) Loss=0.31327 Rate=17.36 GlobalRate=17.36 Time=Sun Mar 29 04:50:59 2020\n",
            "[xla:0](0) Loss=0.36759 Rate=16.59 GlobalRate=16.59 Time=Sun Mar 29 04:50:59 2020\n",
            "[xla:1](0) Loss=0.48862 Rate=16.15 GlobalRate=16.15 Time=Sun Mar 29 04:50:59 2020\n",
            "[xla:4](0) Loss=0.31428 Rate=15.85 GlobalRate=15.85 Time=Sun Mar 29 04:50:59 2020\n",
            "[xla:5](0) Loss=0.50065 Rate=15.87 GlobalRate=15.87 Time=Sun Mar 29 04:50:59 2020\n",
            "[xla:2](0) Loss=0.44922 Rate=15.13 GlobalRate=15.13 Time=Sun Mar 29 04:50:59 2020\n",
            "[xla:7](0) Loss=0.31787 Rate=14.91 GlobalRate=14.91 Time=Sun Mar 29 04:50:59 2020\n",
            "[xla:4](20) Loss=0.37579 Rate=42.81 GlobalRate=53.56 Time=Sun Mar 29 04:51:04 2020\n",
            "[xla:6](20) Loss=0.31395 Rate=42.84 GlobalRate=53.48 Time=Sun Mar 29 04:51:04 2020\n",
            "[xla:5](20) Loss=0.43858 Rate=42.87 GlobalRate=53.62 Time=Sun Mar 29 04:51:04 2020\n",
            "[xla:0](20) Loss=0.31326 Rate=42.73 GlobalRate=53.47 Time=Sun Mar 29 04:51:04 2020\n",
            "[xla:7](20) Loss=0.31327 Rate=42.94 GlobalRate=53.63 Time=Sun Mar 29 04:51:04 2020\n",
            "[xla:3](20) Loss=0.37988 Rate=42.96 GlobalRate=53.74 Time=Sun Mar 29 04:51:04 2020\n",
            "[xla:1](20) Loss=0.31327 Rate=42.56 GlobalRate=53.26 Time=Sun Mar 29 04:51:04 2020\n",
            "[xla:2](20) Loss=0.39224 Rate=42.87 GlobalRate=53.57 Time=Sun Mar 29 04:51:04 2020\n",
            "[xla:6](40) Loss=0.32858 Rate=54.10 GlobalRate=57.16 Time=Sun Mar 29 04:51:09 2020\n",
            "[xla:1](40) Loss=0.43828 Rate=54.00 GlobalRate=57.03 Time=Sun Mar 29 04:51:09 2020\n",
            "[xla:3](40) Loss=0.50076 Rate=54.15 GlobalRate=57.31 Time=Sun Mar 29 04:51:09 2020\n",
            "[xla:4](40) Loss=0.37577 Rate=54.09 GlobalRate=57.20 Time=Sun Mar 29 04:51:09 2020\n",
            "[xla:7](40) Loss=0.32465 Rate=54.14 GlobalRate=57.24 Time=Sun Mar 29 04:51:09 2020\n",
            "[xla:0](40) Loss=0.44071 Rate=54.05 GlobalRate=57.15 Time=Sun Mar 29 04:51:09 2020\n",
            "[xla:5](40) Loss=0.39123 Rate=54.11 GlobalRate=57.24 Time=Sun Mar 29 04:51:09 2020\n",
            "[xla:2](40) Loss=0.31327 Rate=54.13 GlobalRate=57.22 Time=Sun Mar 29 04:51:09 2020\n",
            "[xla:7](60) Loss=0.45165 Rate=58.85 GlobalRate=58.72 Time=Sun Mar 29 04:51:14 2020\n",
            "[xla:0](60) Loss=0.37924 Rate=58.81 GlobalRate=58.65 Time=Sun Mar 29 04:51:14 2020\n",
            "[xla:3](60) Loss=0.31484 Rate=58.85 GlobalRate=58.76 Time=Sun Mar 29 04:51:14 2020\n",
            "[xla:4](60) Loss=0.37514 Rate=58.82 GlobalRate=58.69 Time=Sun Mar 29 04:51:14 2020\n",
            "[xla:5](60) Loss=0.37616 Rate=58.83 GlobalRate=58.71 Time=Sun Mar 29 04:51:14 2020\n",
            "[xla:2](60) Loss=0.34277 Rate=58.83 GlobalRate=58.69 Time=Sun Mar 29 04:51:14 2020\n",
            "[xla:1](60) Loss=0.43845 Rate=58.63 GlobalRate=58.49 Time=Sun Mar 29 04:51:14 2020\n",
            "[xla:6](60) Loss=0.35477 Rate=58.67 GlobalRate=58.58 Time=Sun Mar 29 04:51:14 2020\n",
            "[xla:1](80) Loss=0.31339 Rate=60.67 GlobalRate=59.32 Time=Sun Mar 29 04:51:20 2020\n",
            "[xla:4](80) Loss=0.37577 Rate=60.59 GlobalRate=59.42 Time=Sun Mar 29 04:51:20 2020\n",
            "[xla:3](80) Loss=0.31339 Rate=60.60 GlobalRate=59.48 Time=Sun Mar 29 04:51:20 2020\n",
            "[xla:6](80) Loss=0.37700 Rate=60.68 GlobalRate=59.39 Time=Sun Mar 29 04:51:20 2020\n",
            "[xla:0](80) Loss=0.37580 Rate=60.58 GlobalRate=59.39 Time=Sun Mar 29 04:51:20 2020\n",
            "[xla:2](80) Loss=0.42268 Rate=60.60 GlobalRate=59.43 Time=Sun Mar 29 04:51:20 2020\n",
            "[xla:7](80) Loss=0.37598 Rate=60.59 GlobalRate=59.44 Time=Sun Mar 29 04:51:20 2020\n",
            "[xla:5](80) Loss=0.44207 Rate=60.55 GlobalRate=59.42 Time=Sun Mar 29 04:51:20 2020\n",
            "[xla:4](100) Loss=0.31327 Rate=61.24 GlobalRate=59.85 Time=Sun Mar 29 04:51:25 2020\n",
            "[xla:0](100) Loss=0.31328 Rate=61.24 GlobalRate=59.83 Time=Sun Mar 29 04:51:25 2020\n",
            "[xla:6](100) Loss=0.31327 Rate=61.28 GlobalRate=59.83 Time=Sun Mar 29 04:51:25 2020\n",
            "[xla:7](100) Loss=0.38834 Rate=61.24 GlobalRate=59.87 Time=Sun Mar 29 04:51:25 2020\n",
            "[xla:1](100) Loss=0.31326 Rate=61.26 GlobalRate=59.77 Time=Sun Mar 29 04:51:25 2020\n",
            "[xla:3](100) Loss=0.31329 Rate=61.24 GlobalRate=59.90 Time=Sun Mar 29 04:51:25 2020\n",
            "[xla:5](100) Loss=0.31344 Rate=61.26 GlobalRate=59.87 Time=Sun Mar 29 04:51:25 2020\n",
            "[xla:2](100) Loss=0.43063 Rate=61.24 GlobalRate=59.86 Time=Sun Mar 29 04:51:25 2020\n",
            "[xla:4](120) Loss=0.31328 Rate=61.36 GlobalRate=60.11 Time=Sun Mar 29 04:51:30 2020\n",
            "[xla:5](120) Loss=0.31328 Rate=61.37 GlobalRate=60.12 Time=Sun Mar 29 04:51:30 2020\n",
            "[xla:3](120) Loss=0.37351 Rate=61.36 GlobalRate=60.15 Time=Sun Mar 29 04:51:30 2020\n",
            "[xla:6](120) Loss=0.31368 Rate=61.36 GlobalRate=60.09 Time=Sun Mar 29 04:51:30 2020\n",
            "[xla:1](120) Loss=0.37583 Rate=61.36 GlobalRate=60.04 Time=Sun Mar 29 04:51:30 2020\n",
            "[xla:2](120) Loss=0.31334 Rate=61.36 GlobalRate=60.11 Time=Sun Mar 29 04:51:30 2020\n",
            "[xla:0](120) Loss=0.31330 Rate=61.35 GlobalRate=60.09 Time=Sun Mar 29 04:51:30 2020\n",
            "[xla:7](120) Loss=0.43621 Rate=61.35 GlobalRate=60.12 Time=Sun Mar 29 04:51:30 2020\n",
            "[xla:5](140) Loss=0.31326 Rate=61.41 GlobalRate=60.30 Time=Sun Mar 29 04:51:35 2020\n",
            "[xla:4](140) Loss=0.37577 Rate=61.40 GlobalRate=60.29 Time=Sun Mar 29 04:51:35 2020\n",
            "[xla:2](140) Loss=0.31327 Rate=61.41 GlobalRate=60.30 Time=Sun Mar 29 04:51:35 2020\n",
            "[xla:1](140) Loss=0.44530 Rate=61.41 GlobalRate=60.24 Time=Sun Mar 29 04:51:35 2020\n",
            "[xla:3](140) Loss=0.50711 Rate=61.40 GlobalRate=60.33 Time=Sun Mar 29 04:51:35 2020\n",
            "[xla:6](140) Loss=0.36952 Rate=61.41 GlobalRate=60.28 Time=Sun Mar 29 04:51:35 2020\n",
            "[xla:0](140) Loss=0.31354 Rate=61.40 GlobalRate=60.27 Time=Sun Mar 29 04:51:35 2020\n",
            "[xla:7](140) Loss=0.37729 Rate=61.40 GlobalRate=60.30 Time=Sun Mar 29 04:51:35 2020\n",
            "[xla:7](160) Loss=0.37576 Rate=61.81 GlobalRate=60.52 Time=Sun Mar 29 04:51:40 2020\n",
            "[xla:6](160) Loss=0.31471 Rate=61.81 GlobalRate=60.49 Time=Sun Mar 29 04:51:40 2020\n",
            "[xla:1](160) Loss=0.37502 Rate=61.79 GlobalRate=60.45 Time=Sun Mar 29 04:51:40 2020\n",
            "[xla:4](160) Loss=0.31402 Rate=61.78 GlobalRate=60.50 Time=Sun Mar 29 04:51:40 2020\n",
            "[xla:0](160) Loss=0.37564 Rate=61.79 GlobalRate=60.49 Time=Sun Mar 29 04:51:40 2020\n",
            "[xla:2](160) Loss=0.31333 Rate=61.75 GlobalRate=60.50 Time=Sun Mar 29 04:51:40 2020\n",
            "[xla:5](160) Loss=0.48974 Rate=61.73 GlobalRate=60.50 Time=Sun Mar 29 04:51:40 2020\n",
            "[xla:3](160) Loss=0.37577 Rate=61.73 GlobalRate=60.52 Time=Sun Mar 29 04:51:40 2020\n",
            "[xla:0](180) Loss=0.31329 Rate=61.80 GlobalRate=60.63 Time=Sun Mar 29 04:51:46 2020\n",
            "[xla:3](180) Loss=0.31401 Rate=61.83 GlobalRate=60.67 Time=Sun Mar 29 04:51:46 2020\n",
            "[xla:1](180) Loss=0.36272 Rate=61.79 GlobalRate=60.60 Time=Sun Mar 29 04:51:46 2020\n",
            "[xla:6](180) Loss=0.56327 Rate=61.79 GlobalRate=60.63 Time=Sun Mar 29 04:51:46 2020\n",
            "[xla:4](180) Loss=0.31335 Rate=61.79 GlobalRate=60.64 Time=Sun Mar 29 04:51:46 2020\n",
            "[xla:7](180) Loss=0.33058 Rate=61.79 GlobalRate=60.65 Time=Sun Mar 29 04:51:46 2020\n",
            "[xla:2](180) Loss=0.37563 Rate=61.82 GlobalRate=60.65 Time=Sun Mar 29 04:51:46 2020\n",
            "[xla:5](180) Loss=0.31326 Rate=61.82 GlobalRate=60.65 Time=Sun Mar 29 04:51:46 2020\n",
            "[xla:3](200) Loss=0.31565 Rate=61.78 GlobalRate=60.78 Time=Sun Mar 29 04:51:51 2020\n",
            "[xla:6](200) Loss=0.37922 Rate=61.76 GlobalRate=60.74 Time=Sun Mar 29 04:51:51 2020\n",
            "[xla:1](200) Loss=0.43826 Rate=61.76 GlobalRate=60.71 Time=Sun Mar 29 04:51:51 2020\n",
            "[xla:2](200) Loss=0.33294 Rate=61.77 GlobalRate=60.76 Time=Sun Mar 29 04:51:51 2020\n",
            "[xla:5](200) Loss=0.31329 Rate=61.77 GlobalRate=60.76 Time=Sun Mar 29 04:51:51 2020\n",
            "[xla:4](200) Loss=0.31328 Rate=61.76 GlobalRate=60.75 Time=Sun Mar 29 04:51:51 2020\n",
            "[xla:7](200) Loss=0.31346 Rate=61.76 GlobalRate=60.76 Time=Sun Mar 29 04:51:51 2020\n",
            "[xla:0](200) Loss=0.37662 Rate=61.75 GlobalRate=60.74 Time=Sun Mar 29 04:51:51 2020\n",
            "[xla:6](220) Loss=0.43826 Rate=61.72 GlobalRate=60.83 Time=Sun Mar 29 04:51:56 2020\n",
            "[xla:7](220) Loss=0.37254 Rate=61.72 GlobalRate=60.84 Time=Sun Mar 29 04:51:56 2020\n",
            "[xla:1](220) Loss=0.31326 Rate=61.72 GlobalRate=60.80 Time=Sun Mar 29 04:51:56 2020\n",
            "[xla:0](220) Loss=0.37576 Rate=61.72 GlobalRate=60.82 Time=Sun Mar 29 04:51:56 2020\n",
            "[xla:5](220) Loss=0.37553 Rate=61.72 GlobalRate=60.84 Time=Sun Mar 29 04:51:56 2020\n",
            "[xla:3](220) Loss=0.31329 Rate=61.71 GlobalRate=60.86 Time=Sun Mar 29 04:51:56 2020\n",
            "[xla:2](220) Loss=0.31326 Rate=61.61 GlobalRate=60.82 Time=Sun Mar 29 04:51:56 2020\n",
            "[xla:4](220) Loss=0.31327 Rate=61.61 GlobalRate=60.82 Time=Sun Mar 29 04:51:56 2020\n",
            "[xla:6](240) Loss=0.31328 Rate=61.39 GlobalRate=60.85 Time=Sun Mar 29 04:52:01 2020\n",
            "[xla:1](240) Loss=0.37576 Rate=61.38 GlobalRate=60.83 Time=Sun Mar 29 04:52:01 2020\n",
            "[xla:5](240) Loss=0.37579 Rate=61.40 GlobalRate=60.87 Time=Sun Mar 29 04:52:01 2020\n",
            "[xla:4](240) Loss=0.37576 Rate=61.45 GlobalRate=60.86 Time=Sun Mar 29 04:52:01 2020\n",
            "[xla:2](240) Loss=0.31328 Rate=61.45 GlobalRate=60.87 Time=Sun Mar 29 04:52:01 2020\n",
            "[xla:3](240) Loss=0.31326 Rate=61.39 GlobalRate=60.88 Time=Sun Mar 29 04:52:01 2020\n",
            "[xla:7](240) Loss=0.31330 Rate=61.38 GlobalRate=60.87 Time=Sun Mar 29 04:52:01 2020\n",
            "[xla:0](240) Loss=0.31327 Rate=61.38 GlobalRate=60.85 Time=Sun Mar 29 04:52:01 2020\n",
            "[xla:3](260) Loss=0.43827 Rate=61.00 GlobalRate=60.87 Time=Sun Mar 29 04:52:06 2020\n",
            "[xla:1](260) Loss=0.43611 Rate=60.99 GlobalRate=60.82 Time=Sun Mar 29 04:52:06 2020\n",
            "[xla:2](260) Loss=0.31327 Rate=61.02 GlobalRate=60.86 Time=Sun Mar 29 04:52:06 2020\n",
            "[xla:5](260) Loss=0.31331 Rate=60.99 GlobalRate=60.86 Time=Sun Mar 29 04:52:06 2020\n",
            "[xla:0](260) Loss=0.31333 Rate=61.00 GlobalRate=60.84 Time=Sun Mar 29 04:52:06 2020\n",
            "[xla:7](260) Loss=0.37576 Rate=60.99 GlobalRate=60.86 Time=Sun Mar 29 04:52:06 2020\n",
            "[xla:4](260) Loss=0.31327 Rate=61.01 GlobalRate=60.85 Time=Sun Mar 29 04:52:06 2020\n",
            "[xla:6](260) Loss=0.31326 Rate=60.99 GlobalRate=60.84 Time=Sun Mar 29 04:52:06 2020\n",
            "[xla:2](280) Loss=0.37593 Rate=61.11 GlobalRate=60.88 Time=Sun Mar 29 04:52:12 2020\n",
            "[xla:4](280) Loss=0.31343 Rate=61.11 GlobalRate=60.87 Time=Sun Mar 29 04:52:12 2020\n",
            "[xla:1](280) Loss=0.33036 Rate=61.10 GlobalRate=60.85 Time=Sun Mar 29 04:52:12 2020\n",
            "[xla:7](280) Loss=0.37568 Rate=61.10 GlobalRate=60.88 Time=Sun Mar 29 04:52:12 2020\n",
            "[xla:3](280) Loss=0.32410 Rate=61.10 GlobalRate=60.89 Time=Sun Mar 29 04:52:12 2020\n",
            "[xla:6](280) Loss=0.37583 Rate=61.10 GlobalRate=60.87 Time=Sun Mar 29 04:52:12 2020\n",
            "[xla:0](280) Loss=0.31328 Rate=61.10 GlobalRate=60.87 Time=Sun Mar 29 04:52:12 2020\n",
            "[xla:5](280) Loss=0.35498 Rate=61.09 GlobalRate=60.88 Time=Sun Mar 29 04:52:12 2020\n",
            "[xla:1](300) Loss=0.37343 Rate=61.36 GlobalRate=60.89 Time=Sun Mar 29 04:52:17 2020\n",
            "[xla:7](300) Loss=0.49119 Rate=61.36 GlobalRate=60.92 Time=Sun Mar 29 04:52:17 2020\n",
            "[xla:2](300) Loss=0.31563 Rate=61.36 GlobalRate=60.92 Time=Sun Mar 29 04:52:17 2020\n",
            "[xla:5](300) Loss=0.31346 Rate=61.36 GlobalRate=60.92 Time=Sun Mar 29 04:52:17 2020\n",
            "[xla:6](300) Loss=0.31327 Rate=61.36 GlobalRate=60.91 Time=Sun Mar 29 04:52:17 2020\n",
            "[xla:0](300) Loss=0.31326 Rate=61.36 GlobalRate=60.91 Time=Sun Mar 29 04:52:17 2020\n",
            "[xla:3](300) Loss=0.32206 Rate=61.35 GlobalRate=60.93 Time=Sun Mar 29 04:52:17 2020\n",
            "[xla:4](300) Loss=0.48473 Rate=61.35 GlobalRate=60.92 Time=Sun Mar 29 04:52:17 2020\n",
            "[xla:7](320) Loss=0.31327 Rate=60.93 GlobalRate=60.91 Time=Sun Mar 29 04:52:22 2020\n",
            "[xla:5](320) Loss=0.42045 Rate=60.93 GlobalRate=60.91 Time=Sun Mar 29 04:52:22 2020\n",
            "[xla:0](320) Loss=0.31346 Rate=60.93 GlobalRate=60.89 Time=Sun Mar 29 04:52:22 2020\n",
            "[xla:3](320) Loss=0.43830 Rate=60.92 GlobalRate=60.91 Time=Sun Mar 29 04:52:22 2020\n",
            "[xla:4](320) Loss=0.37576 Rate=60.93 GlobalRate=60.90 Time=Sun Mar 29 04:52:22 2020\n",
            "[xla:1](320) Loss=0.31327 Rate=60.91 GlobalRate=60.87 Time=Sun Mar 29 04:52:22 2020\n",
            "[xla:6](320) Loss=0.32133 Rate=60.91 GlobalRate=60.89 Time=Sun Mar 29 04:52:22 2020\n",
            "[xla:2](320) Loss=0.50066 Rate=60.91 GlobalRate=60.90 Time=Sun Mar 29 04:52:22 2020\n",
            "[xla:1](340) Loss=0.41422 Rate=61.74 GlobalRate=60.96 Time=Sun Mar 29 04:52:27 2020\n",
            "[xla:7](340) Loss=0.31327 Rate=61.72 GlobalRate=60.98 Time=Sun Mar 29 04:52:27 2020\n",
            "[xla:6](340) Loss=0.31397 Rate=61.74 GlobalRate=60.97 Time=Sun Mar 29 04:52:27 2020\n",
            "[xla:0](340) Loss=0.45967 Rate=61.73 GlobalRate=60.97 Time=Sun Mar 29 04:52:27 2020\n",
            "[xla:2](340) Loss=0.43814 Rate=61.73 GlobalRate=60.98 Time=Sun Mar 29 04:52:27 2020\n",
            "[xla:3](340) Loss=0.37586 Rate=61.73 GlobalRate=60.99 Time=Sun Mar 29 04:52:27 2020\n",
            "[xla:5](340) Loss=0.31428 Rate=61.72 GlobalRate=60.98 Time=Sun Mar 29 04:52:27 2020\n",
            "[xla:4](340) Loss=0.37576 Rate=61.73 GlobalRate=60.98 Time=Sun Mar 29 04:52:27 2020\n",
            "Finished Training epoch 4\n",
            "Sizes: torch.Size([16, 2]), torch.Size([16, 2])\n",
            "[xla:6] Accuracy=90.06%\n",
            "[xla:3] Accuracy=91.51%\n",
            "[xla:0] Accuracy=91.67%\n",
            "[xla:4] Accuracy=90.38%\n",
            "[xla:2] Accuracy=90.87%\n",
            "[xla:7] Accuracy=89.42%\n",
            "[xla:5] Accuracy=91.99%\n",
            "[xla:1] Accuracy=89.10%\n",
            "[xla:3](0) Loss=0.31326 Rate=20.50 GlobalRate=20.50 Time=Sun Mar 29 04:52:36 2020\n",
            "[xla:6](0) Loss=0.37577 Rate=17.92 GlobalRate=17.91 Time=Sun Mar 29 04:52:36 2020\n",
            "[xla:5](0) Loss=0.50183 Rate=17.67 GlobalRate=17.67 Time=Sun Mar 29 04:52:36 2020\n",
            "[xla:0](0) Loss=0.31335 Rate=15.67 GlobalRate=15.67 Time=Sun Mar 29 04:52:36 2020\n",
            "[xla:4](0) Loss=0.36216 Rate=15.35 GlobalRate=15.35 Time=Sun Mar 29 04:52:36 2020\n",
            "[xla:2](0) Loss=0.43826 Rate=15.36 GlobalRate=15.36 Time=Sun Mar 29 04:52:36 2020\n",
            "[xla:7](0) Loss=0.31326 Rate=14.83 GlobalRate=14.83 Time=Sun Mar 29 04:52:36 2020\n",
            "[xla:1](0) Loss=0.38695 Rate=14.34 GlobalRate=14.34 Time=Sun Mar 29 04:52:36 2020\n",
            "[xla:7](20) Loss=0.32369 Rate=41.94 GlobalRate=52.41 Time=Sun Mar 29 04:52:41 2020\n",
            "[xla:6](20) Loss=0.39373 Rate=41.56 GlobalRate=51.89 Time=Sun Mar 29 04:52:41 2020\n",
            "[xla:2](20) Loss=0.37578 Rate=41.90 GlobalRate=52.40 Time=Sun Mar 29 04:52:41 2020\n",
            "[xla:1](20) Loss=0.31326 Rate=42.08 GlobalRate=52.51 Time=Sun Mar 29 04:52:41 2020\n",
            "[xla:5](20) Loss=0.39597 Rate=42.01 GlobalRate=52.50 Time=Sun Mar 29 04:52:41 2020\n",
            "[xla:0](20) Loss=0.31326 Rate=41.67 GlobalRate=52.14 Time=Sun Mar 29 04:52:41 2020\n",
            "[xla:3](20) Loss=0.44985 Rate=41.88 GlobalRate=51.84 Time=Sun Mar 29 04:52:41 2020\n",
            "[xla:4](20) Loss=0.37583 Rate=41.81 GlobalRate=52.29 Time=Sun Mar 29 04:52:41 2020\n",
            "[xla:6](40) Loss=0.32587 Rate=53.73 GlobalRate=56.31 Time=Sun Mar 29 04:52:46 2020\n",
            "[xla:5](40) Loss=0.36633 Rate=53.91 GlobalRate=56.68 Time=Sun Mar 29 04:52:46 2020\n",
            "[xla:3](40) Loss=0.50078 Rate=53.93 GlobalRate=56.33 Time=Sun Mar 29 04:52:46 2020\n",
            "[xla:2](40) Loss=0.31327 Rate=53.86 GlobalRate=56.61 Time=Sun Mar 29 04:52:46 2020\n",
            "[xla:7](40) Loss=0.32218 Rate=53.86 GlobalRate=56.61 Time=Sun Mar 29 04:52:46 2020\n",
            "[xla:4](40) Loss=0.37576 Rate=53.90 GlobalRate=56.60 Time=Sun Mar 29 04:52:46 2020\n",
            "[xla:0](40) Loss=0.43827 Rate=53.69 GlobalRate=56.40 Time=Sun Mar 29 04:52:46 2020\n",
            "[xla:1](40) Loss=0.43835 Rate=53.84 GlobalRate=56.61 Time=Sun Mar 29 04:52:46 2020\n",
            "[xla:6](60) Loss=0.31327 Rate=58.46 GlobalRate=57.95 Time=Sun Mar 29 04:52:52 2020\n",
            "[xla:5](60) Loss=0.31339 Rate=58.54 GlobalRate=58.21 Time=Sun Mar 29 04:52:52 2020\n",
            "[xla:0](60) Loss=0.43404 Rate=58.55 GlobalRate=58.06 Time=Sun Mar 29 04:52:52 2020\n",
            "[xla:1](60) Loss=0.38031 Rate=58.61 GlobalRate=58.21 Time=Sun Mar 29 04:52:52 2020\n",
            "[xla:4](60) Loss=0.37577 Rate=58.54 GlobalRate=58.16 Time=Sun Mar 29 04:52:52 2020\n",
            "[xla:3](60) Loss=0.31330 Rate=58.54 GlobalRate=57.96 Time=Sun Mar 29 04:52:52 2020\n",
            "[xla:2](60) Loss=0.31327 Rate=58.46 GlobalRate=58.14 Time=Sun Mar 29 04:52:52 2020\n",
            "[xla:7](60) Loss=0.39266 Rate=58.47 GlobalRate=58.14 Time=Sun Mar 29 04:52:52 2020\n",
            "[xla:4](80) Loss=0.37572 Rate=60.33 GlobalRate=58.96 Time=Sun Mar 29 04:52:57 2020\n",
            "[xla:5](80) Loss=0.31327 Rate=60.32 GlobalRate=58.99 Time=Sun Mar 29 04:52:57 2020\n",
            "[xla:6](80) Loss=0.36897 Rate=60.29 GlobalRate=58.79 Time=Sun Mar 29 04:52:57 2020\n",
            "[xla:0](80) Loss=0.35412 Rate=60.33 GlobalRate=58.88 Time=Sun Mar 29 04:52:57 2020\n",
            "[xla:3](80) Loss=0.31329 Rate=60.33 GlobalRate=58.80 Time=Sun Mar 29 04:52:57 2020\n",
            "[xla:7](80) Loss=0.43365 Rate=60.36 GlobalRate=58.96 Time=Sun Mar 29 04:52:57 2020\n",
            "[xla:1](80) Loss=0.31327 Rate=60.35 GlobalRate=58.99 Time=Sun Mar 29 04:52:57 2020\n",
            "[xla:2](80) Loss=0.31327 Rate=60.33 GlobalRate=58.95 Time=Sun Mar 29 04:52:57 2020\n",
            "[xla:5](100) Loss=0.37557 Rate=61.19 GlobalRate=59.52 Time=Sun Mar 29 04:53:02 2020\n",
            "[xla:7](100) Loss=0.45697 Rate=61.21 GlobalRate=59.50 Time=Sun Mar 29 04:53:02 2020\n",
            "[xla:4](100) Loss=0.31326 Rate=61.20 GlobalRate=59.49 Time=Sun Mar 29 04:53:02 2020\n",
            "[xla:6](100) Loss=0.32983 Rate=61.18 GlobalRate=59.35 Time=Sun Mar 29 04:53:02 2020\n",
            "[xla:3](100) Loss=0.31344 Rate=61.19 GlobalRate=59.37 Time=Sun Mar 29 04:53:02 2020\n",
            "[xla:1](100) Loss=0.31326 Rate=61.20 GlobalRate=59.52 Time=Sun Mar 29 04:53:02 2020\n",
            "[xla:0](100) Loss=0.32324 Rate=61.19 GlobalRate=59.43 Time=Sun Mar 29 04:53:02 2020\n",
            "[xla:2](100) Loss=0.37891 Rate=61.21 GlobalRate=59.49 Time=Sun Mar 29 04:53:02 2020\n",
            "[xla:6](120) Loss=0.31327 Rate=61.48 GlobalRate=59.73 Time=Sun Mar 29 04:53:07 2020\n",
            "[xla:3](120) Loss=0.37564 Rate=61.49 GlobalRate=59.74 Time=Sun Mar 29 04:53:07 2020\n",
            "[xla:1](120) Loss=0.37577 Rate=61.49 GlobalRate=59.87 Time=Sun Mar 29 04:53:07 2020\n",
            "[xla:5](120) Loss=0.31327 Rate=61.48 GlobalRate=59.87 Time=Sun Mar 29 04:53:07 2020\n",
            "[xla:7](120) Loss=0.37835 Rate=61.46 GlobalRate=59.84 Time=Sun Mar 29 04:53:07 2020\n",
            "[xla:2](120) Loss=0.31375 Rate=61.47 GlobalRate=59.84 Time=Sun Mar 29 04:53:07 2020\n",
            "[xla:0](120) Loss=0.31327 Rate=61.38 GlobalRate=59.76 Time=Sun Mar 29 04:53:07 2020\n",
            "[xla:4](120) Loss=0.31333 Rate=61.38 GlobalRate=59.82 Time=Sun Mar 29 04:53:07 2020\n",
            "[xla:4](140) Loss=0.37585 Rate=61.37 GlobalRate=60.03 Time=Sun Mar 29 04:53:12 2020\n",
            "[xla:5](140) Loss=0.31335 Rate=61.31 GlobalRate=60.05 Time=Sun Mar 29 04:53:12 2020\n",
            "[xla:3](140) Loss=0.43844 Rate=61.31 GlobalRate=59.94 Time=Sun Mar 29 04:53:12 2020\n",
            "[xla:1](140) Loss=0.43823 Rate=61.31 GlobalRate=60.05 Time=Sun Mar 29 04:53:12 2020\n",
            "[xla:2](140) Loss=0.31327 Rate=61.33 GlobalRate=60.03 Time=Sun Mar 29 04:53:12 2020\n",
            "[xla:0](140) Loss=0.36304 Rate=61.37 GlobalRate=59.98 Time=Sun Mar 29 04:53:12 2020\n",
            "[xla:6](140) Loss=0.31328 Rate=61.30 GlobalRate=59.93 Time=Sun Mar 29 04:53:12 2020\n",
            "[xla:7](140) Loss=0.41158 Rate=61.31 GlobalRate=60.03 Time=Sun Mar 29 04:53:12 2020\n",
            "[xla:7](160) Loss=0.37577 Rate=61.80 GlobalRate=60.28 Time=Sun Mar 29 04:53:18 2020\n",
            "[xla:6](160) Loss=0.32096 Rate=61.79 GlobalRate=60.19 Time=Sun Mar 29 04:53:18 2020\n",
            "[xla:5](160) Loss=0.44011 Rate=61.79 GlobalRate=60.30 Time=Sun Mar 29 04:53:18 2020\n",
            "[xla:2](160) Loss=0.31408 Rate=61.79 GlobalRate=60.28 Time=Sun Mar 29 04:53:18 2020\n",
            "[xla:4](160) Loss=0.31413 Rate=61.81 GlobalRate=60.28 Time=Sun Mar 29 04:53:18 2020\n",
            "[xla:0](160) Loss=0.37571 Rate=61.81 GlobalRate=60.24 Time=Sun Mar 29 04:53:18 2020\n",
            "[xla:3](160) Loss=0.37577 Rate=61.79 GlobalRate=60.20 Time=Sun Mar 29 04:53:18 2020\n",
            "[xla:1](160) Loss=0.33201 Rate=61.78 GlobalRate=60.30 Time=Sun Mar 29 04:53:18 2020\n",
            "[xla:7](180) Loss=0.31328 Rate=61.95 GlobalRate=60.47 Time=Sun Mar 29 04:53:23 2020\n",
            "[xla:2](180) Loss=0.37578 Rate=61.95 GlobalRate=60.47 Time=Sun Mar 29 04:53:23 2020\n",
            "[xla:4](180) Loss=0.36147 Rate=61.95 GlobalRate=60.47 Time=Sun Mar 29 04:53:23 2020\n",
            "[xla:3](180) Loss=0.31329 Rate=61.95 GlobalRate=60.40 Time=Sun Mar 29 04:53:23 2020\n",
            "[xla:6](180) Loss=0.55408 Rate=61.94 GlobalRate=60.39 Time=Sun Mar 29 04:53:23 2020\n",
            "[xla:5](180) Loss=0.31326 Rate=61.94 GlobalRate=60.49 Time=Sun Mar 29 04:53:23 2020\n",
            "[xla:0](180) Loss=0.31327 Rate=61.96 GlobalRate=60.43 Time=Sun Mar 29 04:53:23 2020\n",
            "[xla:1](180) Loss=0.31327 Rate=61.95 GlobalRate=60.49 Time=Sun Mar 29 04:53:23 2020\n",
            "[xla:5](200) Loss=0.31326 Rate=62.11 GlobalRate=60.66 Time=Sun Mar 29 04:53:28 2020\n",
            "[xla:6](200) Loss=0.37572 Rate=62.11 GlobalRate=60.57 Time=Sun Mar 29 04:53:28 2020\n",
            "[xla:3](200) Loss=0.31328 Rate=62.11 GlobalRate=60.57 Time=Sun Mar 29 04:53:28 2020\n",
            "[xla:2](200) Loss=0.31361 Rate=62.11 GlobalRate=60.64 Time=Sun Mar 29 04:53:28 2020\n",
            "[xla:7](200) Loss=0.31326 Rate=62.11 GlobalRate=60.64 Time=Sun Mar 29 04:53:28 2020\n",
            "[xla:0](200) Loss=0.37577 Rate=62.12 GlobalRate=60.61 Time=Sun Mar 29 04:53:28 2020\n",
            "[xla:4](200) Loss=0.31651 Rate=62.11 GlobalRate=60.64 Time=Sun Mar 29 04:53:28 2020\n",
            "[xla:1](200) Loss=0.43826 Rate=62.10 GlobalRate=60.65 Time=Sun Mar 29 04:53:28 2020\n",
            "[xla:1](220) Loss=0.31328 Rate=61.88 GlobalRate=60.75 Time=Sun Mar 29 04:53:33 2020\n",
            "[xla:3](220) Loss=0.31339 Rate=61.87 GlobalRate=60.68 Time=Sun Mar 29 04:53:33 2020\n",
            "[xla:0](220) Loss=0.31328 Rate=61.87 GlobalRate=60.71 Time=Sun Mar 29 04:53:33 2020\n",
            "[xla:5](220) Loss=0.37483 Rate=61.87 GlobalRate=60.75 Time=Sun Mar 29 04:53:33 2020\n",
            "[xla:7](220) Loss=0.31327 Rate=61.87 GlobalRate=60.74 Time=Sun Mar 29 04:53:33 2020\n",
            "[xla:6](220) Loss=0.43828 Rate=61.87 GlobalRate=60.67 Time=Sun Mar 29 04:53:33 2020\n",
            "[xla:4](220) Loss=0.31326 Rate=61.88 GlobalRate=60.74 Time=Sun Mar 29 04:53:33 2020\n",
            "[xla:2](220) Loss=0.32404 Rate=61.87 GlobalRate=60.74 Time=Sun Mar 29 04:53:33 2020\n",
            "[xla:1](240) Loss=0.37576 Rate=61.54 GlobalRate=60.80 Time=Sun Mar 29 04:53:38 2020\n",
            "[xla:4](240) Loss=0.37577 Rate=61.54 GlobalRate=60.78 Time=Sun Mar 29 04:53:38 2020\n",
            "[xla:3](240) Loss=0.31326 Rate=61.54 GlobalRate=60.73 Time=Sun Mar 29 04:53:38 2020\n",
            "[xla:5](240) Loss=0.44233 Rate=61.54 GlobalRate=60.80 Time=Sun Mar 29 04:53:38 2020\n",
            "[xla:0](240) Loss=0.31327 Rate=61.53 GlobalRate=60.76 Time=Sun Mar 29 04:53:38 2020\n",
            "[xla:2](240) Loss=0.31328 Rate=61.54 GlobalRate=60.78 Time=Sun Mar 29 04:53:38 2020\n",
            "[xla:7](240) Loss=0.31342 Rate=61.54 GlobalRate=60.78 Time=Sun Mar 29 04:53:38 2020\n",
            "[xla:6](240) Loss=0.31332 Rate=61.53 GlobalRate=60.72 Time=Sun Mar 29 04:53:38 2020\n",
            "[xla:3](260) Loss=0.43827 Rate=61.50 GlobalRate=60.79 Time=Sun Mar 29 04:53:44 2020\n",
            "[xla:6](260) Loss=0.31326 Rate=61.49 GlobalRate=60.78 Time=Sun Mar 29 04:53:44 2020\n",
            "[xla:0](260) Loss=0.31334 Rate=61.41 GlobalRate=60.80 Time=Sun Mar 29 04:53:44 2020\n",
            "[xla:7](260) Loss=0.37576 Rate=61.41 GlobalRate=60.83 Time=Sun Mar 29 04:53:44 2020\n",
            "[xla:4](260) Loss=0.31327 Rate=61.40 GlobalRate=60.82 Time=Sun Mar 29 04:53:44 2020\n",
            "[xla:2](260) Loss=0.31327 Rate=61.40 GlobalRate=60.82 Time=Sun Mar 29 04:53:44 2020\n",
            "[xla:5](260) Loss=0.31334 Rate=61.40 GlobalRate=60.84 Time=Sun Mar 29 04:53:44 2020\n",
            "[xla:1](260) Loss=0.37669 Rate=61.39 GlobalRate=60.84 Time=Sun Mar 29 04:53:44 2020\n",
            "[xla:1](280) Loss=0.31327 Rate=61.16 GlobalRate=60.85 Time=Sun Mar 29 04:53:49 2020\n",
            "[xla:0](280) Loss=0.31353 Rate=61.16 GlobalRate=60.81 Time=Sun Mar 29 04:53:49 2020\n",
            "[xla:3](280) Loss=0.31327 Rate=61.10 GlobalRate=60.79 Time=Sun Mar 29 04:53:49 2020\n",
            "[xla:6](280) Loss=0.37577 Rate=61.11 GlobalRate=60.78 Time=Sun Mar 29 04:53:49 2020\n",
            "[xla:4](280) Loss=0.31328 Rate=61.15 GlobalRate=60.84 Time=Sun Mar 29 04:53:49 2020\n",
            "[xla:5](280) Loss=0.31684 Rate=61.15 GlobalRate=60.85 Time=Sun Mar 29 04:53:49 2020\n",
            "[xla:2](280) Loss=0.43130 Rate=61.15 GlobalRate=60.83 Time=Sun Mar 29 04:53:49 2020\n",
            "[xla:7](280) Loss=0.37079 Rate=61.14 GlobalRate=60.83 Time=Sun Mar 29 04:53:49 2020\n",
            "[xla:3](300) Loss=0.31327 Rate=60.82 GlobalRate=60.78 Time=Sun Mar 29 04:53:54 2020\n",
            "[xla:5](300) Loss=0.31327 Rate=60.86 GlobalRate=60.83 Time=Sun Mar 29 04:53:54 2020\n",
            "[xla:4](300) Loss=0.41214 Rate=60.85 GlobalRate=60.82 Time=Sun Mar 29 04:53:54 2020\n",
            "[xla:0](300) Loss=0.31326 Rate=60.85 GlobalRate=60.80 Time=Sun Mar 29 04:53:54 2020\n",
            "[xla:1](300) Loss=0.37576 Rate=60.85 GlobalRate=60.83 Time=Sun Mar 29 04:53:54 2020\n",
            "[xla:6](300) Loss=0.31327 Rate=60.82 GlobalRate=60.77 Time=Sun Mar 29 04:53:54 2020\n",
            "[xla:7](300) Loss=0.44356 Rate=60.86 GlobalRate=60.82 Time=Sun Mar 29 04:53:54 2020\n",
            "[xla:2](300) Loss=0.31327 Rate=60.85 GlobalRate=60.82 Time=Sun Mar 29 04:53:54 2020\n",
            "[xla:3](320) Loss=0.43823 Rate=61.29 GlobalRate=60.83 Time=Sun Mar 29 04:53:59 2020\n",
            "[xla:2](320) Loss=0.40732 Rate=61.31 GlobalRate=60.87 Time=Sun Mar 29 04:53:59 2020\n",
            "[xla:7](320) Loss=0.31327 Rate=61.31 GlobalRate=60.87 Time=Sun Mar 29 04:53:59 2020\n",
            "[xla:6](320) Loss=0.37840 Rate=61.30 GlobalRate=60.83 Time=Sun Mar 29 04:53:59 2020\n",
            "[xla:0](320) Loss=0.31610 Rate=61.30 GlobalRate=60.85 Time=Sun Mar 29 04:53:59 2020\n",
            "[xla:4](320) Loss=0.42360 Rate=61.30 GlobalRate=60.87 Time=Sun Mar 29 04:53:59 2020\n",
            "[xla:1](320) Loss=0.31347 Rate=61.29 GlobalRate=60.88 Time=Sun Mar 29 04:53:59 2020\n",
            "[xla:5](320) Loss=0.37864 Rate=61.29 GlobalRate=60.88 Time=Sun Mar 29 04:53:59 2020\n",
            "[xla:4](340) Loss=0.31338 Rate=61.58 GlobalRate=60.92 Time=Sun Mar 29 04:54:04 2020\n",
            "[xla:2](340) Loss=0.43831 Rate=61.59 GlobalRate=60.92 Time=Sun Mar 29 04:54:04 2020\n",
            "[xla:3](340) Loss=0.37621 Rate=61.58 GlobalRate=60.88 Time=Sun Mar 29 04:54:04 2020\n",
            "[xla:1](340) Loss=0.37577 Rate=61.59 GlobalRate=60.93 Time=Sun Mar 29 04:54:04 2020\n",
            "[xla:0](340) Loss=0.37832 Rate=61.58 GlobalRate=60.90 Time=Sun Mar 29 04:54:04 2020\n",
            "[xla:6](340) Loss=0.31418 Rate=61.58 GlobalRate=60.88 Time=Sun Mar 29 04:54:04 2020\n",
            "[xla:5](340) Loss=0.31327 Rate=61.59 GlobalRate=60.93 Time=Sun Mar 29 04:54:04 2020\n",
            "[xla:7](340) Loss=0.31327 Rate=61.58 GlobalRate=60.92 Time=Sun Mar 29 04:54:04 2020\n",
            "Finished Training epoch 5\n",
            "Sizes: torch.Size([16, 2]), torch.Size([16, 2])\n",
            "[xla:6] Accuracy=91.51%\n",
            "[xla:4] Accuracy=90.06%\n",
            "[xla:1] Accuracy=88.94%\n",
            "[xla:0] Accuracy=91.51%\n",
            "[xla:5] Accuracy=91.67%\n",
            "[xla:3] Accuracy=91.51%\n",
            "[xla:7] Accuracy=89.90%\n",
            "[xla:2] Accuracy=91.51%\n",
            "[xla:6](0) Loss=0.37583 Rate=16.85 GlobalRate=16.85 Time=Sun Mar 29 04:54:13 2020\n",
            "[xla:4](0) Loss=0.31924 Rate=18.97 GlobalRate=18.97 Time=Sun Mar 29 04:54:13 2020\n",
            "[xla:1](0) Loss=0.36976 Rate=17.56 GlobalRate=17.56 Time=Sun Mar 29 04:54:13 2020\n",
            "[xla:0](0) Loss=0.31326 Rate=15.47 GlobalRate=15.47 Time=Sun Mar 29 04:54:13 2020\n",
            "[xla:3](0) Loss=0.31327 Rate=14.68 GlobalRate=14.68 Time=Sun Mar 29 04:54:13 2020\n",
            "[xla:5](0) Loss=0.43698 Rate=19.75 GlobalRate=19.75 Time=Sun Mar 29 04:54:13 2020\n",
            "[xla:7](0) Loss=0.31327 Rate=14.80 GlobalRate=14.80 Time=Sun Mar 29 04:54:13 2020\n",
            "[xla:2](0) Loss=0.40763 Rate=17.22 GlobalRate=17.22 Time=Sun Mar 29 04:54:13 2020\n",
            "[xla:3](20) Loss=0.43041 Rate=41.90 GlobalRate=52.34 Time=Sun Mar 29 04:54:18 2020\n",
            "[xla:0](20) Loss=0.31326 Rate=41.78 GlobalRate=52.27 Time=Sun Mar 29 04:54:18 2020\n",
            "[xla:1](20) Loss=0.31326 Rate=41.78 GlobalRate=52.22 Time=Sun Mar 29 04:54:18 2020\n",
            "[xla:4](20) Loss=0.37576 Rate=42.04 GlobalRate=52.36 Time=Sun Mar 29 04:54:18 2020\n",
            "[xla:5](20) Loss=0.32617 Rate=44.02 GlobalRate=54.85 Time=Sun Mar 29 04:54:18 2020\n",
            "[xla:7](20) Loss=0.31326 Rate=42.07 GlobalRate=52.57 Time=Sun Mar 29 04:54:18 2020\n",
            "[xla:6](20) Loss=0.31326 Rate=41.09 GlobalRate=51.38 Time=Sun Mar 29 04:54:18 2020\n",
            "[xla:2](20) Loss=0.35715 Rate=43.05 GlobalRate=53.85 Time=Sun Mar 29 04:54:18 2020\n",
            "[xla:4](40) Loss=0.37576 Rate=53.39 GlobalRate=56.23 Time=Sun Mar 29 04:54:24 2020\n",
            "[xla:7](40) Loss=0.36851 Rate=53.40 GlobalRate=56.35 Time=Sun Mar 29 04:54:24 2020\n",
            "[xla:3](40) Loss=0.43815 Rate=53.33 GlobalRate=56.22 Time=Sun Mar 29 04:54:24 2020\n",
            "[xla:2](40) Loss=0.31326 Rate=53.81 GlobalRate=57.11 Time=Sun Mar 29 04:54:24 2020\n",
            "[xla:5](40) Loss=0.31327 Rate=54.18 GlobalRate=57.67 Time=Sun Mar 29 04:54:24 2020\n",
            "[xla:1](40) Loss=0.37577 Rate=53.29 GlobalRate=56.14 Time=Sun Mar 29 04:54:24 2020\n",
            "[xla:0](40) Loss=0.44353 Rate=53.28 GlobalRate=56.17 Time=Sun Mar 29 04:54:24 2020\n",
            "[xla:6](40) Loss=0.37554 Rate=53.02 GlobalRate=55.65 Time=Sun Mar 29 04:54:24 2020\n",
            "[xla:3](60) Loss=0.31329 Rate=58.25 GlobalRate=57.85 Time=Sun Mar 29 04:54:29 2020\n",
            "[xla:5](60) Loss=0.36444 Rate=58.59 GlobalRate=58.88 Time=Sun Mar 29 04:54:29 2020\n",
            "[xla:0](60) Loss=0.41125 Rate=58.23 GlobalRate=57.82 Time=Sun Mar 29 04:54:29 2020\n",
            "[xla:4](60) Loss=0.37497 Rate=58.27 GlobalRate=57.86 Time=Sun Mar 29 04:54:29 2020\n",
            "[xla:1](60) Loss=0.43865 Rate=58.22 GlobalRate=57.80 Time=Sun Mar 29 04:54:29 2020\n",
            "[xla:2](60) Loss=0.31327 Rate=58.42 GlobalRate=58.48 Time=Sun Mar 29 04:54:29 2020\n",
            "[xla:6](60) Loss=0.31329 Rate=58.05 GlobalRate=57.41 Time=Sun Mar 29 04:54:29 2020\n",
            "[xla:7](60) Loss=0.37695 Rate=58.18 GlobalRate=57.90 Time=Sun Mar 29 04:54:29 2020\n",
            "[xla:3](80) Loss=0.31326 Rate=60.28 GlobalRate=58.74 Time=Sun Mar 29 04:54:34 2020\n",
            "[xla:2](80) Loss=0.31327 Rate=60.37 GlobalRate=59.23 Time=Sun Mar 29 04:54:34 2020\n",
            "[xla:0](80) Loss=0.31328 Rate=60.28 GlobalRate=58.72 Time=Sun Mar 29 04:54:34 2020\n",
            "[xla:5](80) Loss=0.31327 Rate=60.42 GlobalRate=59.54 Time=Sun Mar 29 04:54:34 2020\n",
            "[xla:1](80) Loss=0.31327 Rate=60.28 GlobalRate=58.70 Time=Sun Mar 29 04:54:34 2020\n",
            "[xla:6](80) Loss=0.31870 Rate=60.27 GlobalRate=58.43 Time=Sun Mar 29 04:54:34 2020\n",
            "[xla:7](80) Loss=0.43816 Rate=60.35 GlobalRate=58.82 Time=Sun Mar 29 04:54:34 2020\n",
            "[xla:4](80) Loss=0.36688 Rate=60.29 GlobalRate=58.75 Time=Sun Mar 29 04:54:34 2020\n",
            "[xla:6](100) Loss=0.31326 Rate=60.83 GlobalRate=58.96 Time=Sun Mar 29 04:54:39 2020\n",
            "[xla:1](100) Loss=0.31326 Rate=60.83 GlobalRate=59.18 Time=Sun Mar 29 04:54:39 2020\n",
            "[xla:7](100) Loss=0.37706 Rate=60.86 GlobalRate=59.27 Time=Sun Mar 29 04:54:39 2020\n",
            "[xla:5](100) Loss=0.31408 Rate=60.88 GlobalRate=59.86 Time=Sun Mar 29 04:54:39 2020\n",
            "[xla:2](100) Loss=0.37577 Rate=60.86 GlobalRate=59.61 Time=Sun Mar 29 04:54:39 2020\n",
            "[xla:3](100) Loss=0.31327 Rate=60.83 GlobalRate=59.21 Time=Sun Mar 29 04:54:39 2020\n",
            "[xla:4](100) Loss=0.31326 Rate=60.83 GlobalRate=59.22 Time=Sun Mar 29 04:54:39 2020\n",
            "[xla:0](100) Loss=0.31326 Rate=60.81 GlobalRate=59.19 Time=Sun Mar 29 04:54:39 2020\n",
            "[xla:4](120) Loss=0.37577 Rate=61.41 GlobalRate=59.63 Time=Sun Mar 29 04:54:45 2020\n",
            "[xla:7](120) Loss=0.37577 Rate=61.42 GlobalRate=59.68 Time=Sun Mar 29 04:54:45 2020\n",
            "[xla:5](120) Loss=0.36227 Rate=61.42 GlobalRate=60.17 Time=Sun Mar 29 04:54:45 2020\n",
            "[xla:2](120) Loss=0.31327 Rate=61.41 GlobalRate=59.96 Time=Sun Mar 29 04:54:45 2020\n",
            "[xla:6](120) Loss=0.31326 Rate=61.40 GlobalRate=59.40 Time=Sun Mar 29 04:54:45 2020\n",
            "[xla:0](120) Loss=0.31327 Rate=61.41 GlobalRate=59.61 Time=Sun Mar 29 04:54:45 2020\n",
            "[xla:1](120) Loss=0.37577 Rate=61.35 GlobalRate=59.58 Time=Sun Mar 29 04:54:45 2020\n",
            "[xla:3](120) Loss=0.33050 Rate=61.35 GlobalRate=59.61 Time=Sun Mar 29 04:54:45 2020\n",
            "[xla:6](140) Loss=0.31510 Rate=61.70 GlobalRate=59.75 Time=Sun Mar 29 04:54:50 2020\n",
            "[xla:4](140) Loss=0.37577 Rate=61.70 GlobalRate=59.94 Time=Sun Mar 29 04:54:50 2020\n",
            "[xla:2](140) Loss=0.31439 Rate=61.71 GlobalRate=60.23 Time=Sun Mar 29 04:54:50 2020\n",
            "[xla:1](140) Loss=0.43824 Rate=61.73 GlobalRate=59.91 Time=Sun Mar 29 04:54:50 2020\n",
            "[xla:5](140) Loss=0.31326 Rate=61.71 GlobalRate=60.41 Time=Sun Mar 29 04:54:50 2020\n",
            "[xla:0](140) Loss=0.31327 Rate=61.70 GlobalRate=59.92 Time=Sun Mar 29 04:54:50 2020\n",
            "[xla:7](140) Loss=0.37577 Rate=61.69 GlobalRate=59.98 Time=Sun Mar 29 04:54:50 2020\n",
            "[xla:3](140) Loss=0.43838 Rate=61.71 GlobalRate=59.93 Time=Sun Mar 29 04:54:50 2020\n",
            "[xla:2](160) Loss=0.31327 Rate=61.53 GlobalRate=60.37 Time=Sun Mar 29 04:54:55 2020\n",
            "[xla:6](160) Loss=0.31339 Rate=61.53 GlobalRate=59.95 Time=Sun Mar 29 04:54:55 2020\n",
            "[xla:0](160) Loss=0.42924 Rate=61.53 GlobalRate=60.10 Time=Sun Mar 29 04:54:55 2020\n",
            "[xla:5](160) Loss=0.43223 Rate=61.53 GlobalRate=60.53 Time=Sun Mar 29 04:54:55 2020\n",
            "[xla:7](160) Loss=0.37577 Rate=61.53 GlobalRate=60.15 Time=Sun Mar 29 04:54:55 2020\n",
            "[xla:4](160) Loss=0.31341 Rate=61.52 GlobalRate=60.12 Time=Sun Mar 29 04:54:55 2020\n",
            "[xla:1](160) Loss=0.31328 Rate=61.44 GlobalRate=60.07 Time=Sun Mar 29 04:54:55 2020\n",
            "[xla:3](160) Loss=0.37575 Rate=61.44 GlobalRate=60.09 Time=Sun Mar 29 04:54:55 2020\n",
            "[xla:4](180) Loss=0.31327 Rate=61.49 GlobalRate=60.26 Time=Sun Mar 29 04:55:00 2020\n",
            "[xla:7](180) Loss=0.31327 Rate=61.49 GlobalRate=60.29 Time=Sun Mar 29 04:55:00 2020\n",
            "[xla:2](180) Loss=0.39024 Rate=61.48 GlobalRate=60.49 Time=Sun Mar 29 04:55:00 2020\n",
            "[xla:5](180) Loss=0.31326 Rate=61.48 GlobalRate=60.63 Time=Sun Mar 29 04:55:00 2020\n",
            "[xla:3](180) Loss=0.31328 Rate=61.55 GlobalRate=60.26 Time=Sun Mar 29 04:55:00 2020\n",
            "[xla:6](180) Loss=0.50076 Rate=61.47 GlobalRate=60.11 Time=Sun Mar 29 04:55:00 2020\n",
            "[xla:1](180) Loss=0.31330 Rate=61.54 GlobalRate=60.24 Time=Sun Mar 29 04:55:00 2020\n",
            "[xla:0](180) Loss=0.31327 Rate=61.47 GlobalRate=60.25 Time=Sun Mar 29 04:55:00 2020\n",
            "[xla:0](200) Loss=0.37573 Rate=61.53 GlobalRate=60.38 Time=Sun Mar 29 04:55:05 2020\n",
            "[xla:7](200) Loss=0.31326 Rate=61.52 GlobalRate=60.42 Time=Sun Mar 29 04:55:05 2020\n",
            "[xla:3](200) Loss=0.31331 Rate=61.55 GlobalRate=60.39 Time=Sun Mar 29 04:55:05 2020\n",
            "[xla:1](200) Loss=0.43826 Rate=61.55 GlobalRate=60.37 Time=Sun Mar 29 04:55:05 2020\n",
            "[xla:6](200) Loss=0.37576 Rate=61.52 GlobalRate=60.25 Time=Sun Mar 29 04:55:05 2020\n",
            "[xla:2](200) Loss=0.31328 Rate=61.52 GlobalRate=60.59 Time=Sun Mar 29 04:55:05 2020\n",
            "[xla:4](200) Loss=0.31326 Rate=61.43 GlobalRate=60.37 Time=Sun Mar 29 04:55:05 2020\n",
            "[xla:5](200) Loss=0.31340 Rate=61.43 GlobalRate=60.71 Time=Sun Mar 29 04:55:05 2020\n",
            "[xla:5](220) Loss=0.37316 Rate=61.57 GlobalRate=60.79 Time=Sun Mar 29 04:55:11 2020\n",
            "[xla:4](220) Loss=0.31327 Rate=61.56 GlobalRate=60.49 Time=Sun Mar 29 04:55:11 2020\n",
            "[xla:3](220) Loss=0.31327 Rate=61.52 GlobalRate=60.48 Time=Sun Mar 29 04:55:11 2020\n",
            "[xla:0](220) Loss=0.31334 Rate=61.50 GlobalRate=60.47 Time=Sun Mar 29 04:55:11 2020\n",
            "[xla:6](220) Loss=0.43827 Rate=61.50 GlobalRate=60.36 Time=Sun Mar 29 04:55:11 2020\n",
            "[xla:2](220) Loss=0.31343 Rate=61.44 GlobalRate=60.66 Time=Sun Mar 29 04:55:11 2020\n",
            "[xla:1](220) Loss=0.31328 Rate=61.45 GlobalRate=60.46 Time=Sun Mar 29 04:55:11 2020\n",
            "[xla:7](220) Loss=0.31327 Rate=61.43 GlobalRate=60.50 Time=Sun Mar 29 04:55:11 2020\n",
            "[xla:6](240) Loss=0.32761 Rate=61.47 GlobalRate=60.45 Time=Sun Mar 29 04:55:16 2020\n",
            "[xla:0](240) Loss=0.31326 Rate=61.47 GlobalRate=60.55 Time=Sun Mar 29 04:55:16 2020\n",
            "[xla:1](240) Loss=0.37576 Rate=61.51 GlobalRate=60.55 Time=Sun Mar 29 04:55:16 2020\n",
            "[xla:3](240) Loss=0.31327 Rate=61.47 GlobalRate=60.56 Time=Sun Mar 29 04:55:16 2020\n",
            "[xla:5](240) Loss=0.37580 Rate=61.48 GlobalRate=60.84 Time=Sun Mar 29 04:55:16 2020\n",
            "[xla:4](240) Loss=0.43140 Rate=61.48 GlobalRate=60.56 Time=Sun Mar 29 04:55:16 2020\n",
            "[xla:7](240) Loss=0.31326 Rate=61.40 GlobalRate=60.57 Time=Sun Mar 29 04:55:16 2020\n",
            "[xla:2](240) Loss=0.31326 Rate=61.40 GlobalRate=60.72 Time=Sun Mar 29 04:55:16 2020\n",
            "[xla:1](260) Loss=0.37920 Rate=61.00 GlobalRate=60.56 Time=Sun Mar 29 04:55:21 2020\n",
            "[xla:2](260) Loss=0.31326 Rate=61.06 GlobalRate=60.73 Time=Sun Mar 29 04:55:21 2020\n",
            "[xla:3](260) Loss=0.43827 Rate=60.98 GlobalRate=60.57 Time=Sun Mar 29 04:55:21 2020\n",
            "[xla:4](260) Loss=0.31327 Rate=60.99 GlobalRate=60.57 Time=Sun Mar 29 04:55:21 2020\n",
            "[xla:5](260) Loss=0.31340 Rate=60.99 GlobalRate=60.83 Time=Sun Mar 29 04:55:21 2020\n",
            "[xla:6](260) Loss=0.31327 Rate=60.97 GlobalRate=60.46 Time=Sun Mar 29 04:55:21 2020\n",
            "[xla:7](260) Loss=0.37576 Rate=60.95 GlobalRate=60.58 Time=Sun Mar 29 04:55:21 2020\n",
            "[xla:0](260) Loss=0.31345 Rate=60.87 GlobalRate=60.55 Time=Sun Mar 29 04:55:21 2020\n",
            "[xla:6](280) Loss=0.37576 Rate=60.85 GlobalRate=60.49 Time=Sun Mar 29 04:55:26 2020\n",
            "[xla:1](280) Loss=0.31327 Rate=60.85 GlobalRate=60.57 Time=Sun Mar 29 04:55:26 2020\n",
            "[xla:0](280) Loss=0.31329 Rate=60.91 GlobalRate=60.57 Time=Sun Mar 29 04:55:26 2020\n",
            "[xla:4](280) Loss=0.31327 Rate=60.85 GlobalRate=60.58 Time=Sun Mar 29 04:55:26 2020\n",
            "[xla:2](280) Loss=0.37608 Rate=60.87 GlobalRate=60.73 Time=Sun Mar 29 04:55:26 2020\n",
            "[xla:3](280) Loss=0.33742 Rate=60.84 GlobalRate=60.58 Time=Sun Mar 29 04:55:26 2020\n",
            "[xla:5](280) Loss=0.31330 Rate=60.85 GlobalRate=60.82 Time=Sun Mar 29 04:55:26 2020\n",
            "[xla:7](280) Loss=0.31326 Rate=60.93 GlobalRate=60.60 Time=Sun Mar 29 04:55:26 2020\n",
            "[xla:1](300) Loss=0.37576 Rate=61.17 GlobalRate=60.62 Time=Sun Mar 29 04:55:31 2020\n",
            "[xla:4](300) Loss=0.37576 Rate=61.17 GlobalRate=60.64 Time=Sun Mar 29 04:55:31 2020\n",
            "[xla:0](300) Loss=0.31326 Rate=61.19 GlobalRate=60.63 Time=Sun Mar 29 04:55:31 2020\n",
            "[xla:5](300) Loss=0.31326 Rate=61.16 GlobalRate=60.86 Time=Sun Mar 29 04:55:31 2020\n",
            "[xla:2](300) Loss=0.31327 Rate=61.17 GlobalRate=60.77 Time=Sun Mar 29 04:55:31 2020\n",
            "[xla:3](300) Loss=0.31335 Rate=61.16 GlobalRate=60.63 Time=Sun Mar 29 04:55:31 2020\n",
            "[xla:6](300) Loss=0.31326 Rate=61.06 GlobalRate=60.53 Time=Sun Mar 29 04:55:31 2020\n",
            "[xla:7](300) Loss=0.43826 Rate=61.09 GlobalRate=60.64 Time=Sun Mar 29 04:55:31 2020\n",
            "[xla:1](320) Loss=0.32198 Rate=61.05 GlobalRate=60.64 Time=Sun Mar 29 04:55:37 2020\n",
            "[xla:5](320) Loss=0.37596 Rate=61.05 GlobalRate=60.87 Time=Sun Mar 29 04:55:37 2020\n",
            "[xla:7](320) Loss=0.31327 Rate=61.13 GlobalRate=60.68 Time=Sun Mar 29 04:55:37 2020\n",
            "[xla:4](320) Loss=0.37577 Rate=61.05 GlobalRate=60.66 Time=Sun Mar 29 04:55:37 2020\n",
            "[xla:3](320) Loss=0.37644 Rate=61.06 GlobalRate=60.66 Time=Sun Mar 29 04:55:37 2020\n",
            "[xla:6](320) Loss=0.37458 Rate=61.10 GlobalRate=60.57 Time=Sun Mar 29 04:55:37 2020\n",
            "[xla:2](320) Loss=0.37577 Rate=61.05 GlobalRate=60.78 Time=Sun Mar 29 04:55:37 2020\n",
            "[xla:0](320) Loss=0.32559 Rate=61.04 GlobalRate=60.65 Time=Sun Mar 29 04:55:37 2020\n",
            "[xla:2](340) Loss=0.43820 Rate=61.73 GlobalRate=60.87 Time=Sun Mar 29 04:55:42 2020\n",
            "[xla:1](340) Loss=0.37576 Rate=61.72 GlobalRate=60.73 Time=Sun Mar 29 04:55:42 2020\n",
            "[xla:4](340) Loss=0.31328 Rate=61.72 GlobalRate=60.74 Time=Sun Mar 29 04:55:42 2020\n",
            "[xla:6](340) Loss=0.31384 Rate=61.75 GlobalRate=60.66 Time=Sun Mar 29 04:55:42 2020\n",
            "[xla:7](340) Loss=0.31327 Rate=61.75 GlobalRate=60.76 Time=Sun Mar 29 04:55:42 2020\n",
            "[xla:3](340) Loss=0.37628 Rate=61.72 GlobalRate=60.74 Time=Sun Mar 29 04:55:42 2020\n",
            "[xla:0](340) Loss=0.37576 Rate=61.73 GlobalRate=60.74 Time=Sun Mar 29 04:55:42 2020\n",
            "[xla:5](340) Loss=0.31329 Rate=61.72 GlobalRate=60.94 Time=Sun Mar 29 04:55:42 2020\n",
            "Finished Training epoch 6\n",
            "Sizes: torch.Size([16, 2]), torch.Size([16, 2])\n",
            "[xla:3] Accuracy=91.51%\n",
            "[xla:6] Accuracy=89.90%\n",
            "[xla:2] Accuracy=89.74%\n",
            "[xla:0] Accuracy=90.54%\n",
            "[xla:7] Accuracy=89.58%\n",
            "[xla:4] Accuracy=90.87%\n",
            "[xla:1] Accuracy=89.42%\n",
            "[xla:5] Accuracy=90.54%\n",
            "[xla:0](0) Loss=0.31686 Rate=18.50 GlobalRate=18.50 Time=Sun Mar 29 04:55:50 2020\n",
            "[xla:2](0) Loss=0.37576 Rate=17.79 GlobalRate=17.79 Time=Sun Mar 29 04:55:50 2020\n",
            "[xla:3](0) Loss=0.31326 Rate=16.11 GlobalRate=16.11 Time=Sun Mar 29 04:55:50 2020\n",
            "[xla:6](0) Loss=0.37620 Rate=16.44 GlobalRate=16.44 Time=Sun Mar 29 04:55:50 2020\n",
            "[xla:1](0) Loss=0.31327 Rate=15.07 GlobalRate=15.07 Time=Sun Mar 29 04:55:51 2020\n",
            "[xla:5](0) Loss=0.42027 Rate=19.49 GlobalRate=19.49 Time=Sun Mar 29 04:55:51 2020\n",
            "[xla:4](0) Loss=0.33396 Rate=14.76 GlobalRate=14.76 Time=Sun Mar 29 04:55:51 2020\n",
            "[xla:7](0) Loss=0.31326 Rate=14.02 GlobalRate=14.02 Time=Sun Mar 29 04:55:51 2020\n",
            "[xla:3](20) Loss=0.37576 Rate=41.61 GlobalRate=52.07 Time=Sun Mar 29 04:55:56 2020\n",
            "[xla:4](20) Loss=0.37576 Rate=42.27 GlobalRate=52.80 Time=Sun Mar 29 04:55:56 2020\n",
            "[xla:7](20) Loss=0.31326 Rate=42.54 GlobalRate=53.00 Time=Sun Mar 29 04:55:56 2020\n",
            "[xla:2](20) Loss=0.31326 Rate=41.96 GlobalRate=52.42 Time=Sun Mar 29 04:55:56 2020\n",
            "[xla:5](20) Loss=0.31326 Rate=44.09 GlobalRate=54.98 Time=Sun Mar 29 04:55:56 2020\n",
            "[xla:0](20) Loss=0.31326 Rate=42.06 GlobalRate=52.47 Time=Sun Mar 29 04:55:56 2020\n",
            "[xla:6](20) Loss=0.31326 Rate=41.83 GlobalRate=52.34 Time=Sun Mar 29 04:55:56 2020\n",
            "[xla:1](20) Loss=0.31326 Rate=42.24 GlobalRate=52.80 Time=Sun Mar 29 04:55:56 2020\n",
            "[xla:7](40) Loss=0.31326 Rate=53.52 GlobalRate=56.55 Time=Sun Mar 29 04:56:01 2020\n",
            "[xla:1](40) Loss=0.37601 Rate=53.40 GlobalRate=56.44 Time=Sun Mar 29 04:56:01 2020\n",
            "[xla:4](40) Loss=0.37872 Rate=53.41 GlobalRate=56.44 Time=Sun Mar 29 04:56:01 2020\n",
            "[xla:6](40) Loss=0.37689 Rate=53.23 GlobalRate=56.16 Time=Sun Mar 29 04:56:01 2020\n",
            "[xla:3](40) Loss=0.49985 Rate=53.14 GlobalRate=56.01 Time=Sun Mar 29 04:56:01 2020\n",
            "[xla:5](40) Loss=0.31326 Rate=54.13 GlobalRate=57.68 Time=Sun Mar 29 04:56:01 2020\n",
            "[xla:0](40) Loss=0.37576 Rate=53.32 GlobalRate=56.24 Time=Sun Mar 29 04:56:01 2020\n",
            "[xla:2](40) Loss=0.31326 Rate=53.28 GlobalRate=56.21 Time=Sun Mar 29 04:56:01 2020\n",
            "[xla:1](60) Loss=0.43860 Rate=58.10 GlobalRate=57.92 Time=Sun Mar 29 04:56:06 2020\n",
            "[xla:5](60) Loss=0.31327 Rate=58.39 GlobalRate=58.80 Time=Sun Mar 29 04:56:06 2020\n",
            "[xla:4](60) Loss=0.31405 Rate=58.10 GlobalRate=57.92 Time=Sun Mar 29 04:56:06 2020\n",
            "[xla:7](60) Loss=0.37577 Rate=58.14 GlobalRate=58.00 Time=Sun Mar 29 04:56:06 2020\n",
            "[xla:2](60) Loss=0.31326 Rate=58.05 GlobalRate=57.76 Time=Sun Mar 29 04:56:06 2020\n",
            "[xla:3](60) Loss=0.35225 Rate=57.99 GlobalRate=57.61 Time=Sun Mar 29 04:56:06 2020\n",
            "[xla:0](60) Loss=0.37577 Rate=58.06 GlobalRate=57.78 Time=Sun Mar 29 04:56:06 2020\n",
            "[xla:6](60) Loss=0.31327 Rate=58.02 GlobalRate=57.72 Time=Sun Mar 29 04:56:06 2020\n",
            "[xla:3](80) Loss=0.31326 Rate=60.28 GlobalRate=58.60 Time=Sun Mar 29 04:56:12 2020\n",
            "[xla:1](80) Loss=0.31326 Rate=60.31 GlobalRate=58.83 Time=Sun Mar 29 04:56:12 2020\n",
            "[xla:2](80) Loss=0.31622 Rate=60.30 GlobalRate=58.71 Time=Sun Mar 29 04:56:12 2020\n",
            "[xla:4](80) Loss=0.31330 Rate=60.31 GlobalRate=58.83 Time=Sun Mar 29 04:56:12 2020\n",
            "[xla:7](80) Loss=0.39499 Rate=60.32 GlobalRate=58.89 Time=Sun Mar 29 04:56:12 2020\n",
            "[xla:5](80) Loss=0.31326 Rate=60.42 GlobalRate=59.51 Time=Sun Mar 29 04:56:12 2020\n",
            "[xla:6](80) Loss=0.31327 Rate=60.19 GlobalRate=58.64 Time=Sun Mar 29 04:56:12 2020\n",
            "[xla:0](80) Loss=0.31327 Rate=60.20 GlobalRate=58.68 Time=Sun Mar 29 04:56:12 2020\n",
            "[xla:3](100) Loss=0.31370 Rate=60.28 GlobalRate=58.92 Time=Sun Mar 29 04:56:17 2020\n",
            "[xla:6](100) Loss=0.31326 Rate=60.34 GlobalRate=58.99 Time=Sun Mar 29 04:56:17 2020\n",
            "[xla:5](100) Loss=0.37522 Rate=60.34 GlobalRate=59.66 Time=Sun Mar 29 04:56:17 2020\n",
            "[xla:1](100) Loss=0.31326 Rate=60.28 GlobalRate=59.11 Time=Sun Mar 29 04:56:17 2020\n",
            "[xla:4](100) Loss=0.31326 Rate=60.29 GlobalRate=59.11 Time=Sun Mar 29 04:56:17 2020\n",
            "[xla:0](100) Loss=0.31327 Rate=60.34 GlobalRate=59.02 Time=Sun Mar 29 04:56:17 2020\n",
            "[xla:2](100) Loss=0.37579 Rate=60.28 GlobalRate=59.01 Time=Sun Mar 29 04:56:17 2020\n",
            "[xla:7](100) Loss=0.37576 Rate=60.29 GlobalRate=59.16 Time=Sun Mar 29 04:56:17 2020\n",
            "[xla:4](120) Loss=0.35831 Rate=60.99 GlobalRate=59.49 Time=Sun Mar 29 04:56:22 2020\n",
            "[xla:3](120) Loss=0.31326 Rate=60.99 GlobalRate=59.33 Time=Sun Mar 29 04:56:22 2020\n",
            "[xla:5](120) Loss=0.31329 Rate=61.01 GlobalRate=59.95 Time=Sun Mar 29 04:56:22 2020\n",
            "[xla:6](120) Loss=0.31469 Rate=61.01 GlobalRate=59.38 Time=Sun Mar 29 04:56:22 2020\n",
            "[xla:2](120) Loss=0.31326 Rate=60.98 GlobalRate=59.40 Time=Sun Mar 29 04:56:22 2020\n",
            "[xla:0](120) Loss=0.31326 Rate=61.00 GlobalRate=59.41 Time=Sun Mar 29 04:56:22 2020\n",
            "[xla:7](120) Loss=0.37576 Rate=60.99 GlobalRate=59.53 Time=Sun Mar 29 04:56:22 2020\n",
            "[xla:1](120) Loss=0.37608 Rate=60.98 GlobalRate=59.48 Time=Sun Mar 29 04:56:22 2020\n",
            "[xla:0](140) Loss=0.34218 Rate=61.46 GlobalRate=59.73 Time=Sun Mar 29 04:56:27 2020\n",
            "[xla:1](140) Loss=0.43826 Rate=61.45 GlobalRate=59.80 Time=Sun Mar 29 04:56:27 2020\n",
            "[xla:5](140) Loss=0.31327 Rate=61.45 GlobalRate=60.20 Time=Sun Mar 29 04:56:27 2020\n",
            "[xla:4](140) Loss=0.37576 Rate=61.44 GlobalRate=59.80 Time=Sun Mar 29 04:56:27 2020\n",
            "[xla:6](140) Loss=0.31326 Rate=61.45 GlobalRate=59.71 Time=Sun Mar 29 04:56:27 2020\n",
            "[xla:2](140) Loss=0.31343 Rate=61.44 GlobalRate=59.72 Time=Sun Mar 29 04:56:27 2020\n",
            "[xla:3](140) Loss=0.50075 Rate=61.42 GlobalRate=59.65 Time=Sun Mar 29 04:56:27 2020\n",
            "[xla:7](140) Loss=0.43829 Rate=61.44 GlobalRate=59.83 Time=Sun Mar 29 04:56:27 2020\n",
            "[xla:6](160) Loss=0.31326 Rate=61.60 GlobalRate=59.95 Time=Sun Mar 29 04:56:32 2020\n",
            "[xla:3](160) Loss=0.37565 Rate=61.60 GlobalRate=59.90 Time=Sun Mar 29 04:56:32 2020\n",
            "[xla:5](160) Loss=0.37578 Rate=61.60 GlobalRate=60.38 Time=Sun Mar 29 04:56:32 2020\n",
            "[xla:0](160) Loss=0.37576 Rate=61.59 GlobalRate=59.97 Time=Sun Mar 29 04:56:32 2020\n",
            "[xla:7](160) Loss=0.37577 Rate=61.61 GlobalRate=60.06 Time=Sun Mar 29 04:56:32 2020\n",
            "[xla:1](160) Loss=0.31326 Rate=61.59 GlobalRate=60.03 Time=Sun Mar 29 04:56:32 2020\n",
            "[xla:4](160) Loss=0.32007 Rate=61.49 GlobalRate=60.01 Time=Sun Mar 29 04:56:32 2020\n",
            "[xla:2](160) Loss=0.31326 Rate=61.49 GlobalRate=59.94 Time=Sun Mar 29 04:56:32 2020\n",
            "[xla:5](180) Loss=0.31326 Rate=61.64 GlobalRate=60.52 Time=Sun Mar 29 04:56:38 2020\n",
            "[xla:6](180) Loss=0.50076 Rate=61.64 GlobalRate=60.13 Time=Sun Mar 29 04:56:38 2020\n",
            "[xla:1](180) Loss=0.31327 Rate=61.64 GlobalRate=60.20 Time=Sun Mar 29 04:56:38 2020\n",
            "[xla:4](180) Loss=0.31326 Rate=61.70 GlobalRate=60.20 Time=Sun Mar 29 04:56:38 2020\n",
            "[xla:3](180) Loss=0.31327 Rate=61.64 GlobalRate=60.09 Time=Sun Mar 29 04:56:38 2020\n",
            "[xla:0](180) Loss=0.31326 Rate=61.63 GlobalRate=60.15 Time=Sun Mar 29 04:56:38 2020\n",
            "[xla:7](180) Loss=0.31462 Rate=61.54 GlobalRate=60.22 Time=Sun Mar 29 04:56:38 2020\n",
            "[xla:2](180) Loss=0.37576 Rate=61.60 GlobalRate=60.13 Time=Sun Mar 29 04:56:38 2020\n",
            "[xla:4](200) Loss=0.31326 Rate=61.24 GlobalRate=60.28 Time=Sun Mar 29 04:56:43 2020\n",
            "[xla:5](200) Loss=0.31326 Rate=61.22 GlobalRate=60.56 Time=Sun Mar 29 04:56:43 2020\n",
            "[xla:3](200) Loss=0.31327 Rate=61.22 GlobalRate=60.17 Time=Sun Mar 29 04:56:43 2020\n",
            "[xla:7](200) Loss=0.31326 Rate=61.28 GlobalRate=60.30 Time=Sun Mar 29 04:56:43 2020\n",
            "[xla:1](200) Loss=0.43826 Rate=61.22 GlobalRate=60.28 Time=Sun Mar 29 04:56:43 2020\n",
            "[xla:6](200) Loss=0.37576 Rate=61.21 GlobalRate=60.21 Time=Sun Mar 29 04:56:43 2020\n",
            "[xla:0](200) Loss=0.37577 Rate=61.22 GlobalRate=60.23 Time=Sun Mar 29 04:56:43 2020\n",
            "[xla:2](200) Loss=0.31326 Rate=61.30 GlobalRate=60.22 Time=Sun Mar 29 04:56:43 2020\n",
            "[xla:4](220) Loss=0.31326 Rate=61.76 GlobalRate=60.44 Time=Sun Mar 29 04:56:48 2020\n",
            "[xla:5](220) Loss=0.36974 Rate=61.76 GlobalRate=60.70 Time=Sun Mar 29 04:56:48 2020\n",
            "[xla:0](220) Loss=0.36292 Rate=61.76 GlobalRate=60.40 Time=Sun Mar 29 04:56:48 2020\n",
            "[xla:6](220) Loss=0.43827 Rate=61.75 GlobalRate=60.38 Time=Sun Mar 29 04:56:48 2020\n",
            "[xla:3](220) Loss=0.31327 Rate=61.75 GlobalRate=60.34 Time=Sun Mar 29 04:56:48 2020\n",
            "[xla:2](220) Loss=0.31326 Rate=61.77 GlobalRate=60.39 Time=Sun Mar 29 04:56:48 2020\n",
            "[xla:7](220) Loss=0.31326 Rate=61.68 GlobalRate=60.45 Time=Sun Mar 29 04:56:48 2020\n",
            "[xla:1](220) Loss=0.31399 Rate=61.65 GlobalRate=60.42 Time=Sun Mar 29 04:56:48 2020\n",
            "[xla:2](240) Loss=0.32144 Rate=61.30 GlobalRate=60.44 Time=Sun Mar 29 04:56:53 2020\n",
            "[xla:3](240) Loss=0.31326 Rate=61.27 GlobalRate=60.40 Time=Sun Mar 29 04:56:53 2020\n",
            "[xla:1](240) Loss=0.37660 Rate=61.33 GlobalRate=60.48 Time=Sun Mar 29 04:56:53 2020\n",
            "[xla:5](240) Loss=0.46583 Rate=61.27 GlobalRate=60.72 Time=Sun Mar 29 04:56:53 2020\n",
            "[xla:6](240) Loss=0.31326 Rate=61.28 GlobalRate=60.43 Time=Sun Mar 29 04:56:53 2020\n",
            "[xla:4](240) Loss=0.37576 Rate=61.27 GlobalRate=60.48 Time=Sun Mar 29 04:56:53 2020\n",
            "[xla:7](240) Loss=0.31363 Rate=61.24 GlobalRate=60.49 Time=Sun Mar 29 04:56:53 2020\n",
            "[xla:0](240) Loss=0.31400 Rate=61.17 GlobalRate=60.43 Time=Sun Mar 29 04:56:53 2020\n",
            "[xla:4](260) Loss=0.37421 Rate=61.45 GlobalRate=60.56 Time=Sun Mar 29 04:56:58 2020\n",
            "[xla:1](260) Loss=0.37609 Rate=61.46 GlobalRate=60.56 Time=Sun Mar 29 04:56:58 2020\n",
            "[xla:2](260) Loss=0.31327 Rate=61.43 GlobalRate=60.52 Time=Sun Mar 29 04:56:58 2020\n",
            "[xla:3](260) Loss=0.43855 Rate=61.43 GlobalRate=60.48 Time=Sun Mar 29 04:56:58 2020\n",
            "[xla:5](260) Loss=0.31345 Rate=61.43 GlobalRate=60.78 Time=Sun Mar 29 04:56:58 2020\n",
            "[xla:7](260) Loss=0.37576 Rate=61.52 GlobalRate=60.58 Time=Sun Mar 29 04:56:58 2020\n",
            "[xla:6](260) Loss=0.31326 Rate=61.43 GlobalRate=60.51 Time=Sun Mar 29 04:56:58 2020\n",
            "[xla:0](260) Loss=0.36936 Rate=61.49 GlobalRate=60.52 Time=Sun Mar 29 04:56:58 2020\n",
            "[xla:4](280) Loss=0.31327 Rate=61.73 GlobalRate=60.66 Time=Sun Mar 29 04:57:04 2020\n",
            "[xla:7](280) Loss=0.31326 Rate=61.77 GlobalRate=60.67 Time=Sun Mar 29 04:57:04 2020\n",
            "[xla:5](280) Loss=0.31337 Rate=61.73 GlobalRate=60.86 Time=Sun Mar 29 04:57:04 2020\n",
            "[xla:6](280) Loss=0.37576 Rate=61.73 GlobalRate=60.61 Time=Sun Mar 29 04:57:04 2020\n",
            "[xla:1](280) Loss=0.31327 Rate=61.74 GlobalRate=60.66 Time=Sun Mar 29 04:57:04 2020\n",
            "[xla:3](280) Loss=0.31326 Rate=61.73 GlobalRate=60.58 Time=Sun Mar 29 04:57:04 2020\n",
            "[xla:2](280) Loss=0.37576 Rate=61.63 GlobalRate=60.61 Time=Sun Mar 29 04:57:04 2020\n",
            "[xla:0](280) Loss=0.31374 Rate=61.66 GlobalRate=60.61 Time=Sun Mar 29 04:57:04 2020\n",
            "[xla:1](300) Loss=0.37576 Rate=61.61 GlobalRate=60.71 Time=Sun Mar 29 04:57:09 2020\n",
            "[xla:7](300) Loss=0.43826 Rate=61.62 GlobalRate=60.73 Time=Sun Mar 29 04:57:09 2020\n",
            "[xla:6](300) Loss=0.31326 Rate=61.61 GlobalRate=60.67 Time=Sun Mar 29 04:57:09 2020\n",
            "[xla:4](300) Loss=0.37576 Rate=61.60 GlobalRate=60.71 Time=Sun Mar 29 04:57:09 2020\n",
            "[xla:2](300) Loss=0.31327 Rate=61.65 GlobalRate=60.67 Time=Sun Mar 29 04:57:09 2020\n",
            "[xla:5](300) Loss=0.31326 Rate=61.59 GlobalRate=60.90 Time=Sun Mar 29 04:57:09 2020\n",
            "[xla:3](300) Loss=0.32066 Rate=61.50 GlobalRate=60.63 Time=Sun Mar 29 04:57:09 2020\n",
            "[xla:0](300) Loss=0.31326 Rate=61.57 GlobalRate=60.67 Time=Sun Mar 29 04:57:09 2020\n",
            "[xla:2](320) Loss=0.37615 Rate=61.11 GlobalRate=60.68 Time=Sun Mar 29 04:57:14 2020\n",
            "[xla:5](320) Loss=0.37577 Rate=61.08 GlobalRate=60.89 Time=Sun Mar 29 04:57:14 2020\n",
            "[xla:1](320) Loss=0.31326 Rate=61.08 GlobalRate=60.71 Time=Sun Mar 29 04:57:14 2020\n",
            "[xla:4](320) Loss=0.37576 Rate=61.07 GlobalRate=60.71 Time=Sun Mar 29 04:57:14 2020\n",
            "[xla:0](320) Loss=0.32588 Rate=61.16 GlobalRate=60.68 Time=Sun Mar 29 04:57:14 2020\n",
            "[xla:6](320) Loss=0.31499 Rate=61.07 GlobalRate=60.67 Time=Sun Mar 29 04:57:14 2020\n",
            "[xla:7](320) Loss=0.31330 Rate=61.07 GlobalRate=60.73 Time=Sun Mar 29 04:57:14 2020\n",
            "[xla:3](320) Loss=0.43591 Rate=61.12 GlobalRate=60.65 Time=Sun Mar 29 04:57:14 2020\n",
            "[xla:6](340) Loss=0.31328 Rate=60.98 GlobalRate=60.69 Time=Sun Mar 29 04:57:19 2020\n",
            "[xla:1](340) Loss=0.37576 Rate=60.98 GlobalRate=60.72 Time=Sun Mar 29 04:57:19 2020\n",
            "[xla:0](340) Loss=0.37576 Rate=61.02 GlobalRate=60.70 Time=Sun Mar 29 04:57:19 2020\n",
            "[xla:4](340) Loss=0.31326 Rate=60.98 GlobalRate=60.72 Time=Sun Mar 29 04:57:19 2020\n",
            "[xla:5](340) Loss=0.37565 Rate=60.98 GlobalRate=60.89 Time=Sun Mar 29 04:57:19 2020\n",
            "[xla:3](340) Loss=0.43822 Rate=61.00 GlobalRate=60.66 Time=Sun Mar 29 04:57:19 2020\n",
            "[xla:7](340) Loss=0.31373 Rate=60.88 GlobalRate=60.73 Time=Sun Mar 29 04:57:19 2020\n",
            "[xla:2](340) Loss=0.43827 Rate=60.89 GlobalRate=60.68 Time=Sun Mar 29 04:57:19 2020\n",
            "Finished Training epoch 7\n",
            "[xla:6] Accuracy=90.87%\n",
            "[xla:4] Accuracy=90.38%\n",
            "[xla:5] Accuracy=90.71%\n",
            "[xla:3] Accuracy=92.31%\n",
            "Sizes: torch.Size([16, 2]), torch.Size([16, 2])\n",
            "[xla:1] Accuracy=89.58%\n",
            "[xla:2] Accuracy=90.06%\n",
            "[xla:7] Accuracy=89.26%\n",
            "[xla:0] Accuracy=90.22%\n",
            "[xla:6](0) Loss=0.37577 Rate=16.53 GlobalRate=16.53 Time=Sun Mar 29 04:57:28 2020\n",
            "[xla:4](0) Loss=0.31326 Rate=16.90 GlobalRate=16.90 Time=Sun Mar 29 04:57:28 2020\n",
            "[xla:1](0) Loss=0.31378 Rate=16.95 GlobalRate=16.95 Time=Sun Mar 29 04:57:28 2020\n",
            "[xla:5](0) Loss=0.37596 Rate=16.54 GlobalRate=16.54 Time=Sun Mar 29 04:57:28 2020\n",
            "[xla:3](0) Loss=0.31326 Rate=16.55 GlobalRate=16.55 Time=Sun Mar 29 04:57:28 2020\n",
            "[xla:2](0) Loss=0.37579 Rate=16.51 GlobalRate=16.51 Time=Sun Mar 29 04:57:28 2020\n",
            "[xla:7](0) Loss=0.31332 Rate=16.13 GlobalRate=16.13 Time=Sun Mar 29 04:57:28 2020\n",
            "[xla:0](0) Loss=0.31326 Rate=16.28 GlobalRate=16.28 Time=Sun Mar 29 04:57:28 2020\n",
            "[xla:1](20) Loss=0.31326 Rate=41.20 GlobalRate=51.52 Time=Sun Mar 29 04:57:33 2020\n",
            "[xla:6](20) Loss=0.31326 Rate=40.87 GlobalRate=51.12 Time=Sun Mar 29 04:57:33 2020\n",
            "[xla:4](20) Loss=0.37576 Rate=41.06 GlobalRate=51.34 Time=Sun Mar 29 04:57:33 2020\n",
            "[xla:3](20) Loss=0.37598 Rate=41.05 GlobalRate=51.35 Time=Sun Mar 29 04:57:33 2020\n",
            "[xla:5](20) Loss=0.37456 Rate=41.04 GlobalRate=51.33 Time=Sun Mar 29 04:57:33 2020\n",
            "[xla:7](20) Loss=0.31326 Rate=41.33 GlobalRate=51.72 Time=Sun Mar 29 04:57:33 2020\n",
            "[xla:2](20) Loss=0.31330 Rate=41.27 GlobalRate=51.63 Time=Sun Mar 29 04:57:33 2020\n",
            "[xla:0](20) Loss=0.31326 Rate=42.68 GlobalRate=53.40 Time=Sun Mar 29 04:57:33 2020\n",
            "[xla:0](40) Loss=0.38041 Rate=53.59 GlobalRate=56.80 Time=Sun Mar 29 04:57:39 2020\n",
            "[xla:2](40) Loss=0.31326 Rate=53.03 GlobalRate=55.76 Time=Sun Mar 29 04:57:39 2020\n",
            "[xla:5](40) Loss=0.31326 Rate=52.92 GlobalRate=55.57 Time=Sun Mar 29 04:57:39 2020\n",
            "[xla:3](40) Loss=0.43887 Rate=52.93 GlobalRate=55.58 Time=Sun Mar 29 04:57:39 2020\n",
            "[xla:7](40) Loss=0.31327 Rate=53.05 GlobalRate=55.81 Time=Sun Mar 29 04:57:39 2020\n",
            "[xla:6](40) Loss=0.37578 Rate=52.85 GlobalRate=55.44 Time=Sun Mar 29 04:57:39 2020\n",
            "[xla:4](40) Loss=0.37576 Rate=52.82 GlobalRate=55.50 Time=Sun Mar 29 04:57:39 2020\n",
            "[xla:1](40) Loss=0.37577 Rate=52.88 GlobalRate=55.61 Time=Sun Mar 29 04:57:39 2020\n",
            "[xla:2](60) Loss=0.31326 Rate=58.05 GlobalRate=57.49 Time=Sun Mar 29 04:57:44 2020\n",
            "[xla:0](60) Loss=0.37576 Rate=58.27 GlobalRate=58.23 Time=Sun Mar 29 04:57:44 2020\n",
            "[xla:7](60) Loss=0.37577 Rate=58.05 GlobalRate=57.52 Time=Sun Mar 29 04:57:44 2020\n",
            "[xla:4](60) Loss=0.37460 Rate=58.07 GlobalRate=57.35 Time=Sun Mar 29 04:57:44 2020\n",
            "[xla:5](60) Loss=0.31326 Rate=58.00 GlobalRate=57.35 Time=Sun Mar 29 04:57:44 2020\n",
            "[xla:3](60) Loss=0.31343 Rate=58.00 GlobalRate=57.36 Time=Sun Mar 29 04:57:44 2020\n",
            "[xla:6](60) Loss=0.31327 Rate=57.98 GlobalRate=57.26 Time=Sun Mar 29 04:57:44 2020\n",
            "[xla:1](60) Loss=0.43955 Rate=58.09 GlobalRate=57.43 Time=Sun Mar 29 04:57:44 2020\n",
            "[xla:2](80) Loss=0.31326 Rate=59.95 GlobalRate=58.37 Time=Sun Mar 29 04:57:49 2020\n",
            "[xla:3](80) Loss=0.31326 Rate=59.95 GlobalRate=58.27 Time=Sun Mar 29 04:57:49 2020\n",
            "[xla:1](80) Loss=0.31327 Rate=59.98 GlobalRate=58.33 Time=Sun Mar 29 04:57:49 2020\n",
            "[xla:0](80) Loss=0.31859 Rate=60.05 GlobalRate=58.94 Time=Sun Mar 29 04:57:49 2020\n",
            "[xla:5](80) Loss=0.36200 Rate=59.94 GlobalRate=58.27 Time=Sun Mar 29 04:57:49 2020\n",
            "[xla:6](80) Loss=0.37338 Rate=59.93 GlobalRate=58.19 Time=Sun Mar 29 04:57:49 2020\n",
            "[xla:7](80) Loss=0.43829 Rate=59.96 GlobalRate=58.40 Time=Sun Mar 29 04:57:49 2020\n",
            "[xla:4](80) Loss=0.31326 Rate=59.96 GlobalRate=58.26 Time=Sun Mar 29 04:57:49 2020\n",
            "[xla:3](100) Loss=0.31326 Rate=60.78 GlobalRate=58.85 Time=Sun Mar 29 04:57:54 2020\n",
            "[xla:1](100) Loss=0.31326 Rate=60.79 GlobalRate=58.90 Time=Sun Mar 29 04:57:54 2020\n",
            "[xla:0](100) Loss=0.31326 Rate=60.82 GlobalRate=59.40 Time=Sun Mar 29 04:57:54 2020\n",
            "[xla:4](100) Loss=0.31326 Rate=60.79 GlobalRate=58.85 Time=Sun Mar 29 04:57:54 2020\n",
            "[xla:5](100) Loss=0.31327 Rate=60.78 GlobalRate=58.85 Time=Sun Mar 29 04:57:54 2020\n",
            "[xla:7](100) Loss=0.31327 Rate=60.78 GlobalRate=58.95 Time=Sun Mar 29 04:57:54 2020\n",
            "[xla:6](100) Loss=0.31326 Rate=60.77 GlobalRate=58.79 Time=Sun Mar 29 04:57:54 2020\n",
            "[xla:2](100) Loss=0.37587 Rate=60.77 GlobalRate=58.93 Time=Sun Mar 29 04:57:54 2020\n",
            "[xla:5](120) Loss=0.31326 Rate=61.24 GlobalRate=59.28 Time=Sun Mar 29 04:58:00 2020\n",
            "[xla:4](120) Loss=0.31629 Rate=61.24 GlobalRate=59.28 Time=Sun Mar 29 04:58:00 2020\n",
            "[xla:0](120) Loss=0.31326 Rate=61.25 GlobalRate=59.74 Time=Sun Mar 29 04:58:00 2020\n",
            "[xla:1](120) Loss=0.37576 Rate=61.24 GlobalRate=59.32 Time=Sun Mar 29 04:58:00 2020\n",
            "[xla:3](120) Loss=0.31327 Rate=61.23 GlobalRate=59.28 Time=Sun Mar 29 04:58:00 2020\n",
            "[xla:2](120) Loss=0.31331 Rate=61.24 GlobalRate=59.35 Time=Sun Mar 29 04:58:00 2020\n",
            "[xla:6](120) Loss=0.31326 Rate=61.22 GlobalRate=59.22 Time=Sun Mar 29 04:58:00 2020\n",
            "[xla:7](120) Loss=0.37577 Rate=61.23 GlobalRate=59.36 Time=Sun Mar 29 04:58:00 2020\n",
            "[xla:1](140) Loss=0.43826 Rate=61.45 GlobalRate=59.63 Time=Sun Mar 29 04:58:05 2020\n",
            "[xla:4](140) Loss=0.37576 Rate=61.45 GlobalRate=59.59 Time=Sun Mar 29 04:58:05 2020\n",
            "[xla:3](140) Loss=0.50006 Rate=61.45 GlobalRate=59.60 Time=Sun Mar 29 04:58:05 2020\n",
            "[xla:2](140) Loss=0.31327 Rate=61.45 GlobalRate=59.66 Time=Sun Mar 29 04:58:05 2020\n",
            "[xla:5](140) Loss=0.31326 Rate=61.45 GlobalRate=59.59 Time=Sun Mar 29 04:58:05 2020\n",
            "[xla:6](140) Loss=0.31327 Rate=61.45 GlobalRate=59.55 Time=Sun Mar 29 04:58:05 2020\n",
            "[xla:7](140) Loss=0.37577 Rate=61.44 GlobalRate=59.67 Time=Sun Mar 29 04:58:05 2020\n",
            "[xla:0](140) Loss=0.31326 Rate=61.44 GlobalRate=60.00 Time=Sun Mar 29 04:58:05 2020\n",
            "[xla:0](160) Loss=0.37576 Rate=61.87 GlobalRate=60.26 Time=Sun Mar 29 04:58:10 2020\n",
            "[xla:4](160) Loss=0.32930 Rate=61.86 GlobalRate=59.90 Time=Sun Mar 29 04:58:10 2020\n",
            "[xla:5](160) Loss=0.37671 Rate=61.86 GlobalRate=59.90 Time=Sun Mar 29 04:58:10 2020\n",
            "[xla:3](160) Loss=0.32352 Rate=61.85 GlobalRate=59.90 Time=Sun Mar 29 04:58:10 2020\n",
            "[xla:6](160) Loss=0.31342 Rate=61.86 GlobalRate=59.86 Time=Sun Mar 29 04:58:10 2020\n",
            "[xla:1](160) Loss=0.31328 Rate=61.85 GlobalRate=59.93 Time=Sun Mar 29 04:58:10 2020\n",
            "[xla:7](160) Loss=0.37576 Rate=61.85 GlobalRate=59.96 Time=Sun Mar 29 04:58:10 2020\n",
            "[xla:2](160) Loss=0.31326 Rate=61.84 GlobalRate=59.95 Time=Sun Mar 29 04:58:10 2020\n",
            "[xla:5](180) Loss=0.31326 Rate=60.78 GlobalRate=59.92 Time=Sun Mar 29 04:58:15 2020\n",
            "[xla:0](180) Loss=0.31327 Rate=60.79 GlobalRate=60.23 Time=Sun Mar 29 04:58:15 2020\n",
            "[xla:6](180) Loss=0.50076 Rate=60.79 GlobalRate=59.88 Time=Sun Mar 29 04:58:15 2020\n",
            "[xla:2](180) Loss=0.31335 Rate=60.79 GlobalRate=59.97 Time=Sun Mar 29 04:58:15 2020\n",
            "[xla:7](180) Loss=0.31326 Rate=60.80 GlobalRate=59.98 Time=Sun Mar 29 04:58:15 2020\n",
            "[xla:4](180) Loss=0.34715 Rate=60.78 GlobalRate=59.92 Time=Sun Mar 29 04:58:15 2020\n",
            "[xla:1](180) Loss=0.31326 Rate=60.78 GlobalRate=59.95 Time=Sun Mar 29 04:58:15 2020\n",
            "[xla:3](180) Loss=0.37529 Rate=60.78 GlobalRate=59.92 Time=Sun Mar 29 04:58:15 2020\n",
            "[xla:1](200) Loss=0.43826 Rate=60.98 GlobalRate=60.06 Time=Sun Mar 29 04:58:21 2020\n",
            "[xla:3](200) Loss=0.36242 Rate=60.98 GlobalRate=60.04 Time=Sun Mar 29 04:58:21 2020\n",
            "[xla:4](200) Loss=0.31326 Rate=60.98 GlobalRate=60.03 Time=Sun Mar 29 04:58:21 2020\n",
            "[xla:2](200) Loss=0.31326 Rate=60.98 GlobalRate=60.08 Time=Sun Mar 29 04:58:21 2020\n",
            "[xla:7](200) Loss=0.31326 Rate=60.88 GlobalRate=60.07 Time=Sun Mar 29 04:58:21 2020\n",
            "[xla:6](200) Loss=0.37576 Rate=60.87 GlobalRate=59.98 Time=Sun Mar 29 04:58:21 2020\n",
            "[xla:0](200) Loss=0.37578 Rate=60.87 GlobalRate=60.30 Time=Sun Mar 29 04:58:21 2020\n",
            "[xla:5](200) Loss=0.31327 Rate=60.86 GlobalRate=60.01 Time=Sun Mar 29 04:58:21 2020\n",
            "[xla:4](220) Loss=0.31326 Rate=61.10 GlobalRate=60.13 Time=Sun Mar 29 04:58:26 2020\n",
            "[xla:6](220) Loss=0.43826 Rate=61.16 GlobalRate=60.11 Time=Sun Mar 29 04:58:26 2020\n",
            "[xla:2](220) Loss=0.31326 Rate=61.10 GlobalRate=60.17 Time=Sun Mar 29 04:58:26 2020\n",
            "[xla:7](220) Loss=0.31326 Rate=61.16 GlobalRate=60.18 Time=Sun Mar 29 04:58:26 2020\n",
            "[xla:1](220) Loss=0.31392 Rate=61.09 GlobalRate=60.16 Time=Sun Mar 29 04:58:26 2020\n",
            "[xla:5](220) Loss=0.31795 Rate=61.15 GlobalRate=60.13 Time=Sun Mar 29 04:58:26 2020\n",
            "[xla:0](220) Loss=0.31327 Rate=61.09 GlobalRate=60.39 Time=Sun Mar 29 04:58:26 2020\n",
            "[xla:3](220) Loss=0.31326 Rate=61.01 GlobalRate=60.12 Time=Sun Mar 29 04:58:26 2020\n",
            "[xla:4](240) Loss=0.37576 Rate=60.93 GlobalRate=60.19 Time=Sun Mar 29 04:58:31 2020\n",
            "[xla:0](240) Loss=0.31326 Rate=60.99 GlobalRate=60.43 Time=Sun Mar 29 04:58:31 2020\n",
            "[xla:1](240) Loss=0.37576 Rate=60.93 GlobalRate=60.21 Time=Sun Mar 29 04:58:31 2020\n",
            "[xla:6](240) Loss=0.31326 Rate=60.95 GlobalRate=60.16 Time=Sun Mar 29 04:58:31 2020\n",
            "[xla:5](240) Loss=0.37576 Rate=60.96 GlobalRate=60.19 Time=Sun Mar 29 04:58:31 2020\n",
            "[xla:3](240) Loss=0.31326 Rate=60.97 GlobalRate=60.19 Time=Sun Mar 29 04:58:31 2020\n",
            "[xla:2](240) Loss=0.31326 Rate=60.86 GlobalRate=60.22 Time=Sun Mar 29 04:58:31 2020\n",
            "[xla:7](240) Loss=0.31328 Rate=60.79 GlobalRate=60.21 Time=Sun Mar 29 04:58:31 2020\n",
            "[xla:4](260) Loss=0.31326 Rate=60.99 GlobalRate=60.25 Time=Sun Mar 29 04:58:36 2020\n",
            "[xla:3](260) Loss=0.43826 Rate=61.02 GlobalRate=60.26 Time=Sun Mar 29 04:58:36 2020\n",
            "[xla:2](260) Loss=0.31326 Rate=61.03 GlobalRate=60.29 Time=Sun Mar 29 04:58:36 2020\n",
            "[xla:1](260) Loss=0.37577 Rate=60.99 GlobalRate=60.27 Time=Sun Mar 29 04:58:36 2020\n",
            "[xla:6](260) Loss=0.31326 Rate=61.00 GlobalRate=60.23 Time=Sun Mar 29 04:58:36 2020\n",
            "[xla:0](260) Loss=0.31344 Rate=61.02 GlobalRate=60.48 Time=Sun Mar 29 04:58:36 2020\n",
            "[xla:7](260) Loss=0.37587 Rate=61.10 GlobalRate=60.30 Time=Sun Mar 29 04:58:36 2020\n",
            "[xla:5](260) Loss=0.37581 Rate=61.00 GlobalRate=60.25 Time=Sun Mar 29 04:58:36 2020\n",
            "[xla:5](280) Loss=0.36054 Rate=61.10 GlobalRate=60.32 Time=Sun Mar 29 04:58:41 2020\n",
            "[xla:6](280) Loss=0.37576 Rate=61.10 GlobalRate=60.30 Time=Sun Mar 29 04:58:41 2020\n",
            "[xla:3](280) Loss=0.31326 Rate=61.10 GlobalRate=60.32 Time=Sun Mar 29 04:58:41 2020\n",
            "[xla:2](280) Loss=0.37577 Rate=61.11 GlobalRate=60.35 Time=Sun Mar 29 04:58:41 2020\n",
            "[xla:1](280) Loss=0.31326 Rate=61.08 GlobalRate=60.34 Time=Sun Mar 29 04:58:41 2020\n",
            "[xla:4](280) Loss=0.34401 Rate=61.08 GlobalRate=60.32 Time=Sun Mar 29 04:58:41 2020\n",
            "[xla:7](280) Loss=0.31326 Rate=61.13 GlobalRate=60.36 Time=Sun Mar 29 04:58:41 2020\n",
            "[xla:0](280) Loss=0.31326 Rate=61.09 GlobalRate=60.52 Time=Sun Mar 29 04:58:41 2020\n",
            "[xla:4](300) Loss=0.37576 Rate=61.31 GlobalRate=60.39 Time=Sun Mar 29 04:58:47 2020\n",
            "[xla:0](300) Loss=0.31326 Rate=61.32 GlobalRate=60.58 Time=Sun Mar 29 04:58:47 2020\n",
            "[xla:1](300) Loss=0.31338 Rate=61.30 GlobalRate=60.41 Time=Sun Mar 29 04:58:47 2020\n",
            "[xla:2](300) Loss=0.31326 Rate=61.31 GlobalRate=60.42 Time=Sun Mar 29 04:58:47 2020\n",
            "[xla:5](300) Loss=0.31326 Rate=61.30 GlobalRate=60.39 Time=Sun Mar 29 04:58:47 2020\n",
            "[xla:6](300) Loss=0.31326 Rate=61.30 GlobalRate=60.37 Time=Sun Mar 29 04:58:47 2020\n",
            "[xla:3](300) Loss=0.31326 Rate=61.30 GlobalRate=60.39 Time=Sun Mar 29 04:58:47 2020\n",
            "[xla:7](300) Loss=0.43826 Rate=61.32 GlobalRate=60.43 Time=Sun Mar 29 04:58:47 2020\n",
            "[xla:0](320) Loss=0.31341 Rate=61.26 GlobalRate=60.62 Time=Sun Mar 29 04:58:52 2020\n",
            "[xla:7](320) Loss=0.31333 Rate=61.26 GlobalRate=60.48 Time=Sun Mar 29 04:58:52 2020\n",
            "[xla:6](320) Loss=0.31328 Rate=61.25 GlobalRate=60.42 Time=Sun Mar 29 04:58:52 2020\n",
            "[xla:3](320) Loss=0.37577 Rate=61.25 GlobalRate=60.44 Time=Sun Mar 29 04:58:52 2020\n",
            "[xla:1](320) Loss=0.31345 Rate=61.26 GlobalRate=60.46 Time=Sun Mar 29 04:58:52 2020\n",
            "[xla:2](320) Loss=0.37576 Rate=61.25 GlobalRate=60.47 Time=Sun Mar 29 04:58:52 2020\n",
            "[xla:5](320) Loss=0.37902 Rate=61.24 GlobalRate=60.44 Time=Sun Mar 29 04:58:52 2020\n",
            "[xla:4](320) Loss=0.43738 Rate=61.25 GlobalRate=60.44 Time=Sun Mar 29 04:58:52 2020\n",
            "[xla:2](340) Loss=0.43823 Rate=61.78 GlobalRate=60.56 Time=Sun Mar 29 04:58:57 2020\n",
            "[xla:4](340) Loss=0.31327 Rate=61.77 GlobalRate=60.54 Time=Sun Mar 29 04:58:57 2020\n",
            "[xla:0](340) Loss=0.37576 Rate=61.77 GlobalRate=60.71 Time=Sun Mar 29 04:58:57 2020\n",
            "[xla:5](340) Loss=0.31326 Rate=61.78 GlobalRate=60.54 Time=Sun Mar 29 04:58:57 2020\n",
            "[xla:6](340) Loss=0.31327 Rate=61.78 GlobalRate=60.52 Time=Sun Mar 29 04:58:57 2020\n",
            "[xla:3](340) Loss=0.37581 Rate=61.77 GlobalRate=60.54 Time=Sun Mar 29 04:58:57 2020\n",
            "[xla:1](340) Loss=0.37576 Rate=61.77 GlobalRate=60.55 Time=Sun Mar 29 04:58:57 2020\n",
            "[xla:7](340) Loss=0.34866 Rate=61.77 GlobalRate=60.57 Time=Sun Mar 29 04:58:57 2020\n",
            "Finished Training epoch 8\n",
            "Sizes: torch.Size([16, 2]), torch.Size([16, 2])\n",
            "[xla:2] Accuracy=90.87%\n",
            "[xla:5] Accuracy=89.74%\n",
            "[xla:3] Accuracy=91.35%\n",
            "[xla:1] Accuracy=88.94%\n",
            "[xla:4] Accuracy=90.38%\n",
            "[xla:7] Accuracy=89.10%\n",
            "[xla:6] Accuracy=89.90%\n",
            "[xla:0] Accuracy=89.58%\n",
            "[xla:2](0) Loss=0.37581 Rate=17.93 GlobalRate=17.93 Time=Sun Mar 29 04:59:05 2020\n",
            "[xla:5](0) Loss=0.37640 Rate=17.12 GlobalRate=17.12 Time=Sun Mar 29 04:59:06 2020\n",
            "[xla:4](0) Loss=0.31326 Rate=17.38 GlobalRate=17.38 Time=Sun Mar 29 04:59:06 2020\n",
            "[xla:6](0) Loss=0.37576 Rate=15.95 GlobalRate=15.95 Time=Sun Mar 29 04:59:06 2020\n",
            "[xla:3](0) Loss=0.31326 Rate=15.05 GlobalRate=15.05 Time=Sun Mar 29 04:59:06 2020\n",
            "[xla:0](0) Loss=0.31326 Rate=16.64 GlobalRate=16.64 Time=Sun Mar 29 04:59:06 2020\n",
            "[xla:7](0) Loss=0.31326 Rate=13.88 GlobalRate=13.88 Time=Sun Mar 29 04:59:06 2020\n",
            "[xla:1](0) Loss=0.31511 Rate=14.47 GlobalRate=14.47 Time=Sun Mar 29 04:59:06 2020\n",
            "[xla:3](20) Loss=0.37584 Rate=41.82 GlobalRate=52.29 Time=Sun Mar 29 04:59:11 2020\n",
            "[xla:6](20) Loss=0.31326 Rate=41.86 GlobalRate=52.38 Time=Sun Mar 29 04:59:11 2020\n",
            "[xla:5](20) Loss=0.37576 Rate=41.34 GlobalRate=51.69 Time=Sun Mar 29 04:59:11 2020\n",
            "[xla:1](20) Loss=0.31326 Rate=42.36 GlobalRate=52.87 Time=Sun Mar 29 04:59:11 2020\n",
            "[xla:0](20) Loss=0.37576 Rate=43.02 GlobalRate=53.83 Time=Sun Mar 29 04:59:11 2020\n",
            "[xla:7](20) Loss=0.31326 Rate=42.01 GlobalRate=52.34 Time=Sun Mar 29 04:59:11 2020\n",
            "[xla:4](20) Loss=0.37576 Rate=42.26 GlobalRate=52.85 Time=Sun Mar 29 04:59:11 2020\n",
            "[xla:2](20) Loss=0.31524 Rate=41.25 GlobalRate=51.48 Time=Sun Mar 29 04:59:11 2020\n",
            "[xla:3](40) Loss=0.59866 Rate=53.32 GlobalRate=56.19 Time=Sun Mar 29 04:59:16 2020\n",
            "[xla:5](40) Loss=0.31326 Rate=53.13 GlobalRate=55.84 Time=Sun Mar 29 04:59:16 2020\n",
            "[xla:1](40) Loss=0.43025 Rate=53.53 GlobalRate=56.54 Time=Sun Mar 29 04:59:16 2020\n",
            "[xla:2](40) Loss=0.31326 Rate=53.19 GlobalRate=55.79 Time=Sun Mar 29 04:59:16 2020\n",
            "[xla:6](40) Loss=0.37653 Rate=53.33 GlobalRate=56.25 Time=Sun Mar 29 04:59:16 2020\n",
            "[xla:4](40) Loss=0.37576 Rate=53.59 GlobalRate=56.59 Time=Sun Mar 29 04:59:16 2020\n",
            "[xla:7](40) Loss=0.31327 Rate=53.38 GlobalRate=56.22 Time=Sun Mar 29 04:59:16 2020\n",
            "[xla:0](40) Loss=0.37576 Rate=53.78 GlobalRate=57.09 Time=Sun Mar 29 04:59:16 2020\n",
            "[xla:7](60) Loss=0.37576 Rate=58.19 GlobalRate=57.82 Time=Sun Mar 29 04:59:22 2020\n",
            "[xla:4](60) Loss=0.31327 Rate=58.26 GlobalRate=58.08 Time=Sun Mar 29 04:59:22 2020\n",
            "[xla:5](60) Loss=0.31326 Rate=58.07 GlobalRate=57.54 Time=Sun Mar 29 04:59:22 2020\n",
            "[xla:1](60) Loss=0.37576 Rate=58.23 GlobalRate=58.03 Time=Sun Mar 29 04:59:22 2020\n",
            "[xla:6](60) Loss=0.31326 Rate=58.15 GlobalRate=57.83 Time=Sun Mar 29 04:59:22 2020\n",
            "[xla:0](60) Loss=0.43597 Rate=58.35 GlobalRate=58.43 Time=Sun Mar 29 04:59:22 2020\n",
            "[xla:3](60) Loss=0.31328 Rate=58.13 GlobalRate=57.78 Time=Sun Mar 29 04:59:22 2020\n",
            "[xla:2](60) Loss=0.31328 Rate=58.08 GlobalRate=57.49 Time=Sun Mar 29 04:59:22 2020\n",
            "[xla:4](80) Loss=0.31326 Rate=59.91 GlobalRate=58.77 Time=Sun Mar 29 04:59:27 2020\n",
            "[xla:1](80) Loss=0.31326 Rate=59.90 GlobalRate=58.74 Time=Sun Mar 29 04:59:27 2020\n",
            "[xla:7](80) Loss=0.37660 Rate=59.88 GlobalRate=58.57 Time=Sun Mar 29 04:59:27 2020\n",
            "[xla:2](80) Loss=0.32654 Rate=59.85 GlobalRate=58.33 Time=Sun Mar 29 04:59:27 2020\n",
            "[xla:6](80) Loss=0.31327 Rate=59.86 GlobalRate=58.58 Time=Sun Mar 29 04:59:27 2020\n",
            "[xla:0](80) Loss=0.31326 Rate=59.94 GlobalRate=59.04 Time=Sun Mar 29 04:59:27 2020\n",
            "[xla:3](80) Loss=0.31326 Rate=59.76 GlobalRate=58.51 Time=Sun Mar 29 04:59:27 2020\n",
            "[xla:5](80) Loss=0.31326 Rate=59.72 GlobalRate=58.31 Time=Sun Mar 29 04:59:27 2020\n",
            "[xla:1](100) Loss=0.31326 Rate=60.59 GlobalRate=59.18 Time=Sun Mar 29 04:59:32 2020\n",
            "[xla:3](100) Loss=0.31326 Rate=60.64 GlobalRate=59.03 Time=Sun Mar 29 04:59:32 2020\n",
            "[xla:6](100) Loss=0.31326 Rate=60.58 GlobalRate=59.06 Time=Sun Mar 29 04:59:32 2020\n",
            "[xla:2](100) Loss=0.37581 Rate=60.57 GlobalRate=58.85 Time=Sun Mar 29 04:59:32 2020\n",
            "[xla:0](100) Loss=0.31326 Rate=60.61 GlobalRate=59.43 Time=Sun Mar 29 04:59:32 2020\n",
            "[xla:5](100) Loss=0.31326 Rate=60.63 GlobalRate=58.87 Time=Sun Mar 29 04:59:32 2020\n",
            "[xla:4](100) Loss=0.31326 Rate=60.59 GlobalRate=59.21 Time=Sun Mar 29 04:59:32 2020\n",
            "[xla:7](100) Loss=0.32305 Rate=60.58 GlobalRate=59.05 Time=Sun Mar 29 04:59:32 2020\n",
            "[xla:2](120) Loss=0.31327 Rate=61.20 GlobalRate=59.29 Time=Sun Mar 29 04:59:37 2020\n",
            "[xla:3](120) Loss=0.31327 Rate=61.22 GlobalRate=59.44 Time=Sun Mar 29 04:59:37 2020\n",
            "[xla:5](120) Loss=0.31327 Rate=61.22 GlobalRate=59.31 Time=Sun Mar 29 04:59:37 2020\n",
            "[xla:1](120) Loss=0.37581 Rate=61.20 GlobalRate=59.57 Time=Sun Mar 29 04:59:37 2020\n",
            "[xla:0](120) Loss=0.31326 Rate=61.21 GlobalRate=59.78 Time=Sun Mar 29 04:59:37 2020\n",
            "[xla:4](120) Loss=0.31326 Rate=61.19 GlobalRate=59.59 Time=Sun Mar 29 04:59:37 2020\n",
            "[xla:6](120) Loss=0.31326 Rate=61.18 GlobalRate=59.46 Time=Sun Mar 29 04:59:37 2020\n",
            "[xla:7](120) Loss=0.37583 Rate=61.19 GlobalRate=59.45 Time=Sun Mar 29 04:59:37 2020\n",
            "[xla:5](140) Loss=0.31326 Rate=61.63 GlobalRate=59.66 Time=Sun Mar 29 04:59:42 2020\n",
            "[xla:7](140) Loss=0.38402 Rate=61.63 GlobalRate=59.79 Time=Sun Mar 29 04:59:42 2020\n",
            "[xla:4](140) Loss=0.37576 Rate=61.63 GlobalRate=59.91 Time=Sun Mar 29 04:59:42 2020\n",
            "[xla:2](140) Loss=0.31327 Rate=61.62 GlobalRate=59.64 Time=Sun Mar 29 04:59:42 2020\n",
            "[xla:3](140) Loss=0.43855 Rate=61.63 GlobalRate=59.78 Time=Sun Mar 29 04:59:42 2020\n",
            "[xla:0](140) Loss=0.31326 Rate=61.62 GlobalRate=60.07 Time=Sun Mar 29 04:59:42 2020\n",
            "[xla:6](140) Loss=0.31326 Rate=61.63 GlobalRate=59.80 Time=Sun Mar 29 04:59:42 2020\n",
            "[xla:1](140) Loss=0.43687 Rate=61.61 GlobalRate=59.89 Time=Sun Mar 29 04:59:42 2020\n",
            "[xla:1](160) Loss=0.31326 Rate=61.56 GlobalRate=60.09 Time=Sun Mar 29 04:59:48 2020\n",
            "[xla:3](160) Loss=0.31347 Rate=61.56 GlobalRate=59.99 Time=Sun Mar 29 04:59:48 2020\n",
            "[xla:6](160) Loss=0.31332 Rate=61.56 GlobalRate=60.01 Time=Sun Mar 29 04:59:48 2020\n",
            "[xla:4](160) Loss=0.34705 Rate=61.56 GlobalRate=60.11 Time=Sun Mar 29 04:59:48 2020\n",
            "[xla:0](160) Loss=0.37576 Rate=61.56 GlobalRate=60.25 Time=Sun Mar 29 04:59:48 2020\n",
            "[xla:5](160) Loss=0.37578 Rate=61.56 GlobalRate=59.89 Time=Sun Mar 29 04:59:48 2020\n",
            "[xla:7](160) Loss=0.39365 Rate=61.56 GlobalRate=60.00 Time=Sun Mar 29 04:59:48 2020\n",
            "[xla:2](160) Loss=0.31326 Rate=61.53 GlobalRate=59.86 Time=Sun Mar 29 04:59:48 2020\n",
            "[xla:1](180) Loss=0.37570 Rate=61.43 GlobalRate=60.22 Time=Sun Mar 29 04:59:53 2020\n",
            "[xla:2](180) Loss=0.37230 Rate=61.44 GlobalRate=60.03 Time=Sun Mar 29 04:59:53 2020\n",
            "[xla:5](180) Loss=0.31326 Rate=61.42 GlobalRate=60.04 Time=Sun Mar 29 04:59:53 2020\n",
            "[xla:0](180) Loss=0.31327 Rate=61.42 GlobalRate=60.37 Time=Sun Mar 29 04:59:53 2020\n",
            "[xla:6](180) Loss=0.50090 Rate=61.41 GlobalRate=60.15 Time=Sun Mar 29 04:59:53 2020\n",
            "[xla:7](180) Loss=0.31876 Rate=61.41 GlobalRate=60.14 Time=Sun Mar 29 04:59:53 2020\n",
            "[xla:3](180) Loss=0.43799 Rate=61.40 GlobalRate=60.13 Time=Sun Mar 29 04:59:53 2020\n",
            "[xla:4](180) Loss=0.31877 Rate=61.41 GlobalRate=60.24 Time=Sun Mar 29 04:59:53 2020\n",
            "[xla:0](200) Loss=0.37577 Rate=60.54 GlobalRate=60.32 Time=Sun Mar 29 04:59:58 2020\n",
            "[xla:1](200) Loss=0.43857 Rate=60.52 GlobalRate=60.19 Time=Sun Mar 29 04:59:58 2020\n",
            "[xla:5](200) Loss=0.31326 Rate=60.53 GlobalRate=60.03 Time=Sun Mar 29 04:59:58 2020\n",
            "[xla:6](200) Loss=0.37576 Rate=60.54 GlobalRate=60.13 Time=Sun Mar 29 04:59:58 2020\n",
            "[xla:7](200) Loss=0.31326 Rate=60.53 GlobalRate=60.12 Time=Sun Mar 29 04:59:58 2020\n",
            "[xla:3](200) Loss=0.31326 Rate=60.54 GlobalRate=60.11 Time=Sun Mar 29 04:59:58 2020\n",
            "[xla:2](200) Loss=0.34021 Rate=60.44 GlobalRate=60.00 Time=Sun Mar 29 04:59:58 2020\n",
            "[xla:4](200) Loss=0.31326 Rate=60.44 GlobalRate=60.19 Time=Sun Mar 29 04:59:58 2020\n",
            "[xla:6](220) Loss=0.43826 Rate=60.73 GlobalRate=60.19 Time=Sun Mar 29 05:00:03 2020\n",
            "[xla:3](220) Loss=0.37576 Rate=60.73 GlobalRate=60.18 Time=Sun Mar 29 05:00:03 2020\n",
            "[xla:1](220) Loss=0.31326 Rate=60.72 GlobalRate=60.25 Time=Sun Mar 29 05:00:03 2020\n",
            "[xla:5](220) Loss=0.31326 Rate=60.72 GlobalRate=60.10 Time=Sun Mar 29 05:00:03 2020\n",
            "[xla:0](220) Loss=0.36816 Rate=60.72 GlobalRate=60.37 Time=Sun Mar 29 05:00:03 2020\n",
            "[xla:4](220) Loss=0.31326 Rate=60.78 GlobalRate=60.26 Time=Sun Mar 29 05:00:03 2020\n",
            "[xla:7](220) Loss=0.31326 Rate=60.72 GlobalRate=60.19 Time=Sun Mar 29 05:00:03 2020\n",
            "[xla:2](220) Loss=0.31326 Rate=60.78 GlobalRate=60.09 Time=Sun Mar 29 05:00:03 2020\n",
            "[xla:5](240) Loss=0.37576 Rate=61.25 GlobalRate=60.23 Time=Sun Mar 29 05:00:09 2020\n",
            "[xla:2](240) Loss=0.31326 Rate=61.28 GlobalRate=60.22 Time=Sun Mar 29 05:00:09 2020\n",
            "[xla:1](240) Loss=0.37577 Rate=61.25 GlobalRate=60.36 Time=Sun Mar 29 05:00:09 2020\n",
            "[xla:0](240) Loss=0.31326 Rate=61.24 GlobalRate=60.47 Time=Sun Mar 29 05:00:09 2020\n",
            "[xla:3](240) Loss=0.31356 Rate=61.24 GlobalRate=60.29 Time=Sun Mar 29 05:00:09 2020\n",
            "[xla:4](240) Loss=0.43826 Rate=61.27 GlobalRate=60.37 Time=Sun Mar 29 05:00:09 2020\n",
            "[xla:6](240) Loss=0.31326 Rate=61.24 GlobalRate=60.31 Time=Sun Mar 29 05:00:09 2020\n",
            "[xla:7](240) Loss=0.31327 Rate=61.24 GlobalRate=60.30 Time=Sun Mar 29 05:00:09 2020\n",
            "[xla:3](260) Loss=0.43751 Rate=61.11 GlobalRate=60.35 Time=Sun Mar 29 05:00:14 2020\n",
            "[xla:1](260) Loss=0.37013 Rate=61.11 GlobalRate=60.41 Time=Sun Mar 29 05:00:14 2020\n",
            "[xla:6](260) Loss=0.31326 Rate=61.11 GlobalRate=60.36 Time=Sun Mar 29 05:00:14 2020\n",
            "[xla:5](260) Loss=0.43726 Rate=61.11 GlobalRate=60.29 Time=Sun Mar 29 05:00:14 2020\n",
            "[xla:2](260) Loss=0.31326 Rate=61.12 GlobalRate=60.28 Time=Sun Mar 29 05:00:14 2020\n",
            "[xla:7](260) Loss=0.37578 Rate=61.12 GlobalRate=60.36 Time=Sun Mar 29 05:00:14 2020\n",
            "[xla:4](260) Loss=0.31326 Rate=61.13 GlobalRate=60.42 Time=Sun Mar 29 05:00:14 2020\n",
            "[xla:0](260) Loss=0.43582 Rate=61.10 GlobalRate=60.51 Time=Sun Mar 29 05:00:14 2020\n",
            "[xla:7](280) Loss=0.31326 Rate=61.38 GlobalRate=60.44 Time=Sun Mar 29 05:00:19 2020\n",
            "[xla:0](280) Loss=0.31326 Rate=61.38 GlobalRate=60.59 Time=Sun Mar 29 05:00:19 2020\n",
            "[xla:4](280) Loss=0.31326 Rate=61.39 GlobalRate=60.50 Time=Sun Mar 29 05:00:19 2020\n",
            "[xla:2](280) Loss=0.37576 Rate=61.38 GlobalRate=60.37 Time=Sun Mar 29 05:00:19 2020\n",
            "[xla:1](280) Loss=0.31326 Rate=61.38 GlobalRate=60.49 Time=Sun Mar 29 05:00:19 2020\n",
            "[xla:5](280) Loss=0.31326 Rate=61.38 GlobalRate=60.37 Time=Sun Mar 29 05:00:19 2020\n",
            "[xla:6](280) Loss=0.43826 Rate=61.28 GlobalRate=60.43 Time=Sun Mar 29 05:00:19 2020\n",
            "[xla:3](280) Loss=0.31328 Rate=61.27 GlobalRate=60.42 Time=Sun Mar 29 05:00:19 2020\n",
            "[xla:4](300) Loss=0.37577 Rate=61.25 GlobalRate=60.55 Time=Sun Mar 29 05:00:24 2020\n",
            "[xla:3](300) Loss=0.31327 Rate=61.31 GlobalRate=60.48 Time=Sun Mar 29 05:00:24 2020\n",
            "[xla:7](300) Loss=0.43826 Rate=61.24 GlobalRate=60.49 Time=Sun Mar 29 05:00:24 2020\n",
            "[xla:5](300) Loss=0.31326 Rate=61.24 GlobalRate=60.43 Time=Sun Mar 29 05:00:24 2020\n",
            "[xla:1](300) Loss=0.43819 Rate=61.24 GlobalRate=60.53 Time=Sun Mar 29 05:00:24 2020\n",
            "[xla:0](300) Loss=0.31326 Rate=61.24 GlobalRate=60.62 Time=Sun Mar 29 05:00:24 2020\n",
            "[xla:2](300) Loss=0.31423 Rate=61.24 GlobalRate=60.42 Time=Sun Mar 29 05:00:24 2020\n",
            "[xla:6](300) Loss=0.31326 Rate=61.30 GlobalRate=60.49 Time=Sun Mar 29 05:00:24 2020\n",
            "[xla:3](320) Loss=0.44875 Rate=61.02 GlobalRate=60.50 Time=Sun Mar 29 05:00:30 2020\n",
            "[xla:2](320) Loss=0.37576 Rate=61.00 GlobalRate=60.44 Time=Sun Mar 29 05:00:30 2020\n",
            "[xla:6](320) Loss=0.31327 Rate=61.02 GlobalRate=60.51 Time=Sun Mar 29 05:00:30 2020\n",
            "[xla:5](320) Loss=0.37576 Rate=61.00 GlobalRate=60.45 Time=Sun Mar 29 05:00:30 2020\n",
            "[xla:1](320) Loss=0.31326 Rate=60.98 GlobalRate=60.55 Time=Sun Mar 29 05:00:30 2020\n",
            "[xla:7](320) Loss=0.31628 Rate=60.98 GlobalRate=60.51 Time=Sun Mar 29 05:00:30 2020\n",
            "[xla:4](320) Loss=0.37575 Rate=60.92 GlobalRate=60.56 Time=Sun Mar 29 05:00:30 2020\n",
            "[xla:0](320) Loss=0.31327 Rate=60.91 GlobalRate=60.63 Time=Sun Mar 29 05:00:30 2020\n",
            "[xla:3](340) Loss=0.43812 Rate=61.53 GlobalRate=60.58 Time=Sun Mar 29 05:00:35 2020\n",
            "[xla:6](340) Loss=0.31328 Rate=61.53 GlobalRate=60.59 Time=Sun Mar 29 05:00:35 2020\n",
            "[xla:4](340) Loss=0.31354 Rate=61.56 GlobalRate=60.64 Time=Sun Mar 29 05:00:35 2020\n",
            "[xla:2](340) Loss=0.43826 Rate=61.52 GlobalRate=60.52 Time=Sun Mar 29 05:00:35 2020\n",
            "[xla:5](340) Loss=0.37527 Rate=61.52 GlobalRate=60.53 Time=Sun Mar 29 05:00:35 2020\n",
            "[xla:1](340) Loss=0.37576 Rate=61.52 GlobalRate=60.63 Time=Sun Mar 29 05:00:35 2020\n",
            "[xla:7](340) Loss=0.31327 Rate=61.51 GlobalRate=60.59 Time=Sun Mar 29 05:00:35 2020\n",
            "[xla:0](340) Loss=0.37576 Rate=61.56 GlobalRate=60.71 Time=Sun Mar 29 05:00:35 2020\n",
            "Finished Training epoch 9\n",
            "Sizes: torch.Size([16, 2]), torch.Size([16, 2])\n",
            "[xla:6] Accuracy=91.19%\n",
            "[xla:2] Accuracy=91.03%\n",
            "[xla:4] Accuracy=92.15%\n",
            "[xla:1] Accuracy=89.58%\n",
            "[xla:5] Accuracy=91.83%\n",
            "[xla:3] Accuracy=91.83%\n",
            "[xla:0] Accuracy=89.90%\n",
            "[xla:7] Accuracy=88.94%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuH0whCOE6C1",
        "colab_type": "code",
        "outputId": "af33dc37-239c-465f-e04e-5f9c1d326cf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "model_evaluate = BertForSequenceClassification(2)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:pytorch_pretrained_bert.modeling:loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
            "INFO:pytorch_pretrained_bert.modeling:extracting archive file /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpnvbyvs6g\n",
            "INFO:pytorch_pretrained_bert.modeling:Model config {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKxcaIMaGIjP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e51af3f7-3e12-45a0-de13-f5fb26cc44d6"
      },
      "source": [
        "model_evaluate.load_state_dict(torch.load('checkpoint-1'))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jisecn1Jllkq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b5e9e3c0-8911-4adb-8b00-1ea073168a74"
      },
      "source": [
        "model_evaluate"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): BertLayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    }
  ]
}